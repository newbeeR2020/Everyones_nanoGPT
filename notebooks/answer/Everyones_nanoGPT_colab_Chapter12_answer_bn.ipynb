{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj6PNj59iqJ8"
      },
      "source": [
        "# **Colab ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ï‡¶æ‡¶∞‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¶‡ßç‡¶∞‡¶∑‡ßç‡¶ü‡¶¨‡ßç‡¶Ø**\n",
        "\n",
        "# **‡¶è‡¶á ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶≤‡¶ø‡¶ñ‡¶¨‡ßá‡¶® ‡¶®‡¶æ‚Äî‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶ú ‡¶π‡¶æ‡¶∞‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ø‡ßá‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá!**\n",
        "\n",
        "# **‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶Ü‡¶ó‡ßá ‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ï‡¶™‡¶ø ‡¶¨‡¶æ‡¶®‡¶æ‡¶®‡•§**\n",
        "\n",
        "‡¶ï‡¶™‡¶ø ‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá ‡¶ï‡¶∞‡¶¨‡ßá‡¶®\n",
        "\n",
        "1. ‡¶â‡¶™‡¶∞‡ßá‡¶∞ ‡¶¨‡¶æ‡¶Æ ‡¶¶‡¶ø‡¶ï‡ßá‡¶∞ ‚ÄúFile‚Äù-‡¶è ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®‡•§  \n",
        "> *‚ÄúFile‚Äù ‡¶¨‡¶æ \"Runtime\" ‡¶Æ‡¶§‡ßã ‡¶π‡ßá‡¶°‡¶æ‡¶∞ ‡¶®‡¶æ ‡¶¶‡ßá‡¶ñ‡¶≤‡ßá, ‡¶â‡¶™‡¶∞‡ßá‡¶∞ ‡¶°‡¶æ‡¶® ‡¶™‡¶æ‡¶∂‡ßá ‚Äúv‚Äù ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡ßá ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡ßá ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®‡•§*\n",
        "\n",
        "2. \"Save a copy in Drive\" ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶ö‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "\n",
        "3. ‡¶ï‡¶™‡¶ø‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶ï‡¶∞‡ßá ‡¶¶‡¶ø‡¶® ‚ÄúYOURNAMEs_FileName.ipynb‚Äù ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá‡•§  \n",
        "> ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£: ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶Ø‡¶¶‡¶ø Olivia ‡¶π‡¶Ø‡¶º: Olivias_FileName.ipynb\n",
        "\n",
        "4. ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ runtime **CPU** ‡¶§‡ßá ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ T4 GPU CPU ‡¶è‡¶∞ ‡¶ö‡ßá‡¶Ø‡¶º‡ßá ‡¶Ö‡¶®‡ßá‡¶ï ‡¶¨‡ßá‡¶∂‡¶ø ‡¶∏‡ßá‡¶∂‡¶® ‡¶∞‡¶ø‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßá‡•§<br>  \n",
        "   ‡¶§‡¶æ‡¶á ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç‡¶Ø‡¶º‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶®‡¶æ ‡¶≤‡¶æ‡¶ó‡¶≤‡ßá CPU runtime ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ‡¶á ‡¶≠‡¶æ‡¶≤‡ßã‡•§<br>  \n",
        "   ‡¶è‡¶á [Video](https://youtu.be/XRmI-qRiFFw) ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®‡•§<br>\n",
        "\n",
        "> ‡¶Ø‡¶¶‡¶ø ‡¶Æ‡¶æ‡¶ù‡¶™‡¶•‡ßá runtime ‡¶¨‡¶¶‡¶≤‡¶æ‡¶®, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶•‡ßá‡¶ï‡ßá ‡¶∏‡¶¨ ‡¶∏‡ßá‡¶≤ ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡¶æ‡¶≤‡¶æ‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§<br>  \n",
        "> ‡¶∂‡ßÅ‡¶∞‡ßÅ‡¶§‡ßá‡¶á runtime ‡¶†‡¶ø‡¶ï ‡¶ï‡¶∞‡ßá ‡¶®‡¶ø‡¶®‡•§<br>  \n",
        "> *‡¶∏‡ßá‡¶≤ ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡ßã‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø: ‚ÄúRuntime‚Äù (‡¶â‡¶™‡¶∞‡ßá ‡¶¨‡¶æ‡¶Æ) ‚Üí ‚ÄúRun before‚Äù ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®‡•§*<br>\n",
        "\n",
        "---\n",
        "\n",
        "* ‡¶ö‡ßá‡¶ï ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï (‚úÖ) ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶π‡¶Ø‡¶º ‡¶®‡¶æ‡•§ Chrome-‡¶è‡¶∞ refresh ‡¶¨‡¶æ‡¶ü‡¶®‡ßá ‡¶™‡ßá‡¶ú ‡¶∞‡¶ø‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶≤‡ßá ‡¶§‡¶æ‡¶∞‡¶æ ‡¶â‡¶ß‡¶æ‡¶ì ‡¶π‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶Ø‡¶º‡•§<br>  \n",
        "  ‡¶™‡¶∞‡ßá ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡¶æ‡¶≤‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ø‡ßá‡¶§‡ßá ‡¶ö‡¶æ‡¶á‡¶≤‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶∏‡ßá‡¶≤ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßá ‚ÄúSO FAR DONE‚Äù ‡¶≤‡¶ø‡¶ñ‡ßá ‡¶∞‡ßá‡¶ñ‡ßá ‡¶¶‡¶ø‡¶®‡•§\n",
        "\n",
        "---\n",
        "\n",
        "* Colab-‡¶è **‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶Ü‡¶ó‡ßá‡¶∞ ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡ß©‡ß¶ ‡¶•‡ßá‡¶ï‡ßá ‡ßØ‡ß¶ ‡¶Æ‡¶ø‡¶®‡¶ø‡¶ü‡ßá ‡¶∞‡¶ø‡¶∏‡ßá‡¶ü ‡¶π‡¶Ø‡¶º**‡•§<br>  \n",
        "  ‡¶è‡¶ú‡¶®‡ßç‡¶Ø `~~ is not defined` ‡¶ß‡¶∞‡¶®‡ßá‡¶∞ ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶∞ ‡¶¶‡ßá‡¶ñ‡¶æ ‡¶¶‡ßá‡¶Ø‡¶º‡•§\n",
        "\n",
        "  üîÅ `~~ is not defined` ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø ‡¶™‡ßá‡¶≤‡ßá ‡¶ï‡¶∞‡¶£‡ßÄ‡¶Ø‡¶º  \n",
        "  1. ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶≠‡ßá‡¶∞‡¶ø‡¶Ø‡¶º‡ßá‡¶¨‡¶≤‡ßá‡¶∞ ‡¶¨‡¶æ‡¶®‡¶æ‡¶® ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®‡•§<br>  \n",
        "  2. ‡¶¨‡¶æ‡¶®‡¶æ‡¶® ‡¶†‡¶ø‡¶ï ‡¶π‡¶≤‡ßá‡¶ì ‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶•‡¶æ‡¶ï‡¶≤‡ßá, **‡¶Ø‡ßá ‡¶∏‡ßá‡¶≤‡¶ü‡¶ø ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡¶æ‡¶≤‡¶æ‡¶§‡ßá ‡¶ö‡¶æ‡¶® ‡¶∏‡ßá‡¶ü‡¶æ‡¶§‡ßá ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®**‡•§<br>  \n",
        "  3. ‚ÄúRuntime‚Äù (‡¶â‡¶™‡¶∞‡ßá ‡¶¨‡¶æ‡¶Æ) ‚Üí ‚ÄúRun before‚Äù ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®‡•§<br>  \n",
        "     ‚Üí ‡¶è‡¶§‡ßá **‡¶Ü‡¶ó‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶∏‡ßá‡¶≤ ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡¶æ‡¶≤‡ßÅ ‡¶π‡¶¨‡ßá**‡•§  \n",
        "  4. ‡¶è‡¶¨‡¶æ‡¶∞ ‡¶∏‡ßá‡¶≤‡¶ü‡¶ø ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶∞‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "\n",
        "  ‡¶§‡¶¨‡ßÅ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶•‡¶æ‡¶ï‡¶≤‡ßá, ‡¶Ü‡¶ó‡ßá‡¶∞ ‡¶∏‡ßá‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã‡¶§‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ TODO ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶ó‡ßÅ‡¶≤‡ßã‡¶§‡ßá ‡¶≠‡ßÅ‡¶≤ ‡¶•‡¶æ‡¶ï‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§<br>  \n",
        "  ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶ó‡ßÅ‡¶≤‡ßã ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ï‡¶∞‡ßá ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®‡•§<br>  \n",
        "  ‡¶Ö‡¶•‡¶¨‡¶æ ChatGPT ‡¶¨‡¶æ ‡¶Ö‡¶®‡ßç‡¶Ø ‡¶ï‡ßã‡¶®‡ßã ‡¶ï‡ßã‡¶°‡¶ø‡¶Ç ‡¶∏‡¶π‡¶ï‡¶æ‡¶∞‡ßÄ ‡¶•‡ßá‡¶ï‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶®‡¶ø‡¶®‡•§"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXZzMLzXiseX"
      },
      "source": [
        "# **Preparation**\n",
        "\n",
        "‡¶è‡¶á ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶Ü‡¶ó‡ßá ‡¶•‡ßá‡¶ï‡ßá‡¶á ‡¶Ö‡¶ß‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶ó‡ßÅ‡¶≤‡ßã‡¶∞ ‡¶â‡¶™‡¶æ‡¶¶‡¶æ‡¶® ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ ‡¶π‡¶¨‡ßá‡•§<br>\n",
        "‡¶ï‡ßã‡¶° ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®, ‡¶™‡¶°‡¶º‡¶æ‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ ‡¶®‡ßá‡¶á‡•§<br>\n",
        "‡¶ö‡¶ø‡¶®‡ßç‡¶§‡¶æ ‡¶õ‡¶æ‡¶°‡¶º‡¶æ ‡¶∏‡¶æ‡¶Æ‡¶®‡ßá ‡¶è‡¶ó‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶®‡•§<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s04g6yFiuHE",
        "outputId": "a62bb238-1185-4194-d97f-8cbdcdd1f733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-07-08 11:25:56--  https://raw.githubusercontent.com/HayatoHongo/nanoGPT_todo/main/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‚Äòinput.txt‚Äô\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-07-08 11:25:56 (31.2 MB/s) - ‚Äòinput.txt‚Äô saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ‡¶´‡¶æ‡¶á‡¶≤ ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "!wget https://raw.githubusercontent.com/HayatoHongo/Everyones_nanoGPT/main/input.txt -O input.txt\n",
        "# ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá input.text ‡¶´‡¶æ‡¶á‡¶≤‡¶ü‡¶ø ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßá‡¶õ‡ßá‡¶® ‡¶§‡¶æ utf-8 ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü‡ßá ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "with open(\"input.txt\", 'r', encoding = 'utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# ‡¶ü‡ßá‡¶®‡¶∏‡¶∞ ‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡ßç‡¶∞‡¶¶‡¶∞‡ßç‡¶∂‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶´‡¶æ‡¶Ç‡¶∂‡¶® (‡¶™‡¶°‡¶º‡¶§‡ßá ‡¶®‡¶æ ‡¶ö‡¶æ‡¶á‡¶≤‡ßá ‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶ø‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶®)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def print_formatted_tensor(*args, width=6, decimals=2):\n",
        "    \"\"\"\n",
        "    A function that neatly formats and displays a PyTorch Tensor, and also prints its size.\n",
        "\n",
        "    Example usage:\n",
        "        print_formatted_tensor(\"name\", tensor)\n",
        "        print_formatted_tensor(tensor)\n",
        "\n",
        "    Args:\n",
        "        *args: If given 1 argument, it is treated as a tensor.\n",
        "               If given 2 arguments, the first is treated as the name, the second as the tensor.\n",
        "        width (int): Display width for each number (default: 6)\n",
        "        decimals (int): Number of decimal places to show (default: 2)\n",
        "    \"\"\"\n",
        "\n",
        "    # Determine tensor and name from arguments\n",
        "    if not args:\n",
        "        raise ValueError(\"At least one argument is required.\")\n",
        "    if isinstance(args[0], str):\n",
        "        if len(args) < 2:\n",
        "            raise ValueError(\"Tensor is not specified.\")\n",
        "        name, tensor = args[0], args[1]\n",
        "    else:\n",
        "        name, tensor = None, args[0]\n",
        "\n",
        "    # Convert Tensor to List\n",
        "    tensor_list = tensor.detach().cpu().tolist()\n",
        "\n",
        "    def format_list(lst, indent):\n",
        "        \"\"\"Formatting a recursively nested list and returning a string\"\"\"\n",
        "        # If the contents are lists, then re-return\n",
        "        if isinstance(lst, list) and lst and isinstance(lst[0], list):\n",
        "            inner = \",\\n\".join(\" \" * indent + format_list(sub, indent + 2) for sub in lst)\n",
        "            return \"[\\n\" + inner + \"\\n\" + \" \" * (indent - 2) + \"]\"\n",
        "        # For numerical lists\n",
        "        return \"[\" + \", \".join(f\"{v:{width}.{decimals}f}\" for v in lst) + \"]\"\n",
        "\n",
        "    # Formatted string (bar brackets on outermost frames are removed)\n",
        "    formatted = format_list(tensor_list, indent=9)\n",
        "    inner_formatted = formatted[1:-1].strip()\n",
        "\n",
        "    # Result output\n",
        "    if name:\n",
        "        print(name)\n",
        "    print(f\"Tensor Size: {list(tensor.size())}\")\n",
        "    print(\"tensor([\")\n",
        "    print(\" \" * 9 + inner_formatted)\n",
        "    print(\" \" * 7 + \"])\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh_2Ls8tn2rk"
      },
      "source": [
        "# Chapter 12 Trainer Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEl9A_wk33Pa"
      },
      "source": [
        "### Section 1: Class Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnILkem04RSW"
      },
      "source": [
        "üîò **Options**: ‡¶•‡¶æ‡¶ï‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞‡ßá‡¶∞ ‡¶¨‡¶æ‡¶á‡¶∞‡ßá ‡¶Ö‡¶§‡¶ø‡¶∞‡¶ø‡¶ï‡ßç‡¶§ ‡¶Ö‡¶™‡¶∂‡¶®‡•§  \n",
        "\n",
        "`self.model`„ÄÄ`self.optimizer`„ÄÄ`self.data_loader`„ÄÄ`self.config`„ÄÄ`split_data`„ÄÄ`get_batch`„ÄÄ`'train'`, `'val'`„ÄÄ`input_batch`„ÄÄ`target_batch`„ÄÄ`logits`„ÄÄ`self.config.total_training_steps`„ÄÄ`self.config.evaluation_loops`  \n",
        "`loss`„ÄÄ`backward()`„ÄÄ`self.train_step()`„ÄÄ`self.evaluate()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRi90bRasayV"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, data_loader, config):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.data_loader = data_loader\n",
        "        self.config = config\n",
        "\n",
        "    def train_step(self):\n",
        "        # ‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶®‡¶ø‡¶®‡•§\n",
        "        input_batch, target_batch = self.data_loader.get_batch('train')\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # ‡¶Æ‡¶°‡ßá‡¶≤‡ßá‡¶∞ ‡¶´‡¶∞‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶° ‡¶™‡¶æ‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶≤‡¶∏ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨\n",
        "        logits, loss = self.model(input_batch, target_batch)\n",
        "        loss.backward()  # ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶™‡ßç‡¶∞‡ßã‡¶™‡¶æ‡¶ó‡ßá‡¶∂‡¶® (‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶™‡ßç‡¶∞‡ßã‡¶™‡¶æ‡¶ó‡ßá‡¶∂‡¶®)\n",
        "        self.optimizer.step()  # ‡¶™‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶Æ‡¶ø‡¶ü‡¶æ‡¶∞ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "\n",
        "        return loss.item() # ‡¶π‡¶æ‡¶∞‡¶æ‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶® ‡¶´‡ßá‡¶∞‡¶§ ‡¶¶‡ßá‡¶Ø‡¶º\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()  # ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶æ‡ßü‡¶® ‡¶Æ‡ßã‡¶°‡ßá ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        losses = {\"train\": [], \"val\": []} # ‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶ì ‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á‡¶ï‡¶∞‡¶£ ‡¶§‡¶•‡ßç‡¶Ø‡ßá‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶ï‡ßç‡¶∑‡¶§‡¶ø ‡¶ó‡¶£‡¶®‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        with torch.no_grad():\n",
        "            for split in ['train', 'val']:\n",
        "                for _ in range(self.config.evaluation_loops):\n",
        "                    input_batch, target_batch = self.data_loader.get_batch(split)\n",
        "                    _, loss = self.model(input_batch, target_batch)\n",
        "                    losses[split].append(loss.item())\n",
        "        self.model.train()  # ‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶Æ‡ßã‡¶°‡ßá ‡¶´‡¶ø‡¶∞‡ßá ‡¶Ø‡¶æ‡¶®\n",
        "\n",
        "        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶∏‡ßç‡¶™‡ßç‡¶≤‡¶ø‡¶ü‡ßá‡¶∞ (train, val) ‡¶ó‡¶°‡¶º ‡¶ï‡ßç‡¶∑‡¶§‡¶ø ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        return {split: sum(values) / len(values) for split, values in losses.items()}\n",
        "\n",
        "    def train(self):\n",
        "        # config ‡¶è ‡¶®‡¶ø‡¶∞‡ßç‡¶ß‡¶æ‡¶∞‡¶ø‡¶§ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶ï ‡¶¨‡¶æ‡¶∞ train_step ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡•§\n",
        "        for step in range(self.config.total_training_steps):\n",
        "\n",
        "            # ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ßß‡ß¶‡ß¶ ‡¶á‡¶ü‡¶æ‡¶∞‡ßá‡¶∂‡¶®‡ßá ‡¶Ö‡¶•‡¶¨‡¶æ ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶∂‡ßá‡¶∑ ‡¶ß‡¶æ‡¶™‡ßá ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\n",
        "                eval_loss = self.evaluate()\n",
        "                print(f\"Step {step}: Train Loss {eval_loss['train']:.4f}, Validation Loss {eval_loss['val']:.4f}\")\n",
        "\n",
        "            # ‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£‡ßá‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™ (‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶¨‡¶æ‡¶∞ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá ‡¶Æ‡ßÇ‡¶≤ ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶ü‡¶ø ‡¶ï‡¶∞‡ßá‡¶®)\n",
        "            train_loss = self.train_step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "mi8-y1ak4VOS",
        "outputId": "ec0f1c70-6f55-4cf2-fb9f-e5b56297691b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nclass Trainer:\\n    def __init__(self, model, optimizer, data_loader, config):\\n        self.model = model\\n        self.optimizer = optimizer\\n        self.data_loader = data_loader\\n        self.config = config\\n\\n    def train_step(self):\\n        # Get a batch for training.\\n        input_batch, target_batch = ___________._______(_____)\\n        self.optimizer.zero_grad()\\n\\n        # Model forward pass and loss calculation\\n        logits, loss = _______(_________, __________)\\n        _____.__________  # Backpropagation (Error backpropagation)\\n        self.optimizer.step()  # Update parameters\\n\\n        return loss.item() # Returns the value of the loss\\n\\n    def evaluate(self):\\n        self.model.eval()  # Set to evaluation mode\\n        losses = {\"train\": [], \"val\": []} # Calculate losses on both training and validation data\\n        with torch.no_grad():\\n            for split in [\\'train\\', \\'val\\']:\\n                for _ in range(self.config.evaluation_loops):\\n                    input_batch, target_batch = self.data_loader.get_batch(split)\\n                    _, loss = self.model(input_batch, target_batch)\\n                    losses[split].append(loss.item())\\n        self.model.train()  # Return to training mode\\n\\n        # Calculate the average losses for each split (train, val)\\n        return {split: sum(values) / len(values) for split, values in losses.items()}\\n\\n    def train(self):\\n        # Run train_step the number of times specified in config.\\n        for step in range(_________________________):\\n\\n            # Evaluate every 100 iterations or just at the final step.\\n            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\\n                eval_loss = self.evaluate()\\n                print(f\"Step {step}: Train Loss {eval_loss[\\'train\\']:.4f}, Validation Loss {eval_loss[\\'val\\']:.4f}\")\\n\\n            # One step of training (the main process that you do every time)\\n            train_loss = _____________\\n'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, data_loader, config):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.data_loader = data_loader\n",
        "        self.config = config\n",
        "\n",
        "    def train_step(self):\n",
        "        # ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç‡¶Ø‡¶º‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶®‡¶ø‡¶®‡•§\n",
        "        input_batch, target_batch = ___________._______(_____)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶´‡¶∞‡ßã‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶° ‡¶™‡¶æ‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶≤‡¶∏ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨\n",
        "        logits, loss = _______(_________, __________)\n",
        "        _____.__________  # ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶™‡ßç‡¶∞‡¶™‡¶æ‡¶ó‡ßá‡¶∂‡¶® (‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶™‡ßç‡¶∞‡¶™‡¶æ‡¶ó‡ßá‡¶∂‡¶®)\n",
        "        self.optimizer.step()  # ‡¶™‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶Æ‡¶ø‡¶ü‡¶æ‡¶∞ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "\n",
        "        return loss.item() # ‡¶≤‡¶∏‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶® ‡¶´‡ßá‡¶∞‡¶§ ‡¶¶‡ßá‡¶Ø‡¶º\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()  # ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶æ‡ßü‡¶® ‡¶Æ‡ßã‡¶°‡ßá ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        losses = {\"train\": [], \"val\": []} # ‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶ì ‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á‡¶ï‡¶∞‡¶£ ‡¶°‡ßá‡¶ü‡¶æ‡¶Ø‡¶º ‡¶ï‡ßç‡¶∑‡¶§‡¶ø ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        with torch.no_grad():\n",
        "            for split in ['train', 'val']:\n",
        "                for _ in range(self.config.evaluation_loops):\n",
        "                    input_batch, target_batch = self.data_loader.get_batch(split)\n",
        "                    _, loss = self.model(input_batch, target_batch)\n",
        "                    losses[split].append(loss.item())\n",
        "        self.model.train()  # ‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶Æ‡ßã‡¶°‡ßá ‡¶´‡¶ø‡¶∞‡ßÅ‡¶®\n",
        "\n",
        "        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶∏‡ßç‡¶™‡ßç‡¶≤‡¶ø‡¶ü‡ßá‡¶∞ (train, val) ‡¶ó‡¶°‡¶º ‡¶ï‡ßç‡¶∑‡¶§‡¶ø ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        return {split: sum(values) / len(values) for split, values in losses.items()}\n",
        "\n",
        "    def train(self):\n",
        "        # config-‡¶è ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶ï train_step ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡•§\n",
        "        for step in range(_________________________):\n",
        "\n",
        "            # ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ßß‡ß¶‡ß¶ ‡¶á‡¶ü‡¶æ‡¶∞‡ßá‡¶∂‡¶®‡ßá ‡¶¨‡¶æ ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ß‡¶æ‡¶™‡ßá ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\n",
        "                eval_loss = self.evaluate()\n",
        "                print(f\"Step {step}: Train Loss {eval_loss['train']:.4f}, Validation Loss {eval_loss['val']:.4f}\")\n",
        "\n",
        "            # ‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£‡ßá‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™ (‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶¨‡¶æ‡¶∞ ‡¶Ø‡ßá ‡¶Æ‡ßÇ‡¶≤ ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶ü‡¶ø ‡¶ï‡¶∞‡ßá‡¶®)\n",
        "            train_loss = _____________\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KUW7ceEA4ek"
      },
      "source": [
        "<details>\n",
        "<summary>‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡ßá‡¶ñ‡¶æ‡¶§‡ßá/‡¶≤‡ßÅ‡¶ï‡¶æ‡¶§‡ßá ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®</summary>\n",
        "\n",
        "```python\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, data_loader, config):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.data_loader = data_loader\n",
        "        self.config = config\n",
        "\n",
        "    def train_step(self):\n",
        "        # ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç‡¶Ø‡¶º‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶®‡¶ø‡¶®‡•§\n",
        "        input_batch, target_batch = self.data_loader.get_batch('train')\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # ‡¶Æ‡¶°‡ßá‡¶≤‡ßá‡¶∞ ‡¶´‡¶∞‡ßã‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶° ‡¶™‡¶æ‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶≤‡¶∏ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨\n",
        "        logits, loss = self.model(input_batch, target_batch)\n",
        "        loss.backward()  # ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶™‡ßç‡¶∞‡ßã‡¶™‡¶æ‡¶ó‡ßá‡¶∂‡¶® (‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø ‡¶´‡¶ø‡¶∞‡ßá ‡¶Ø‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ)\n",
        "        self.optimizer.step()  # ‡¶™‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶Æ‡¶ø‡¶ü‡¶æ‡¶∞ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü\n",
        "\n",
        "        return loss.item() # ‡¶≤‡¶∏ ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶® ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶ï‡¶∞‡ßá\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()  # ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶® ‡¶Æ‡ßã‡¶°‡ßá ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        losses = {\"train\": [], \"val\": []} # ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶ì ‡¶≠‡ßç‡¶Ø‡¶æ‡¶≤‡¶ø‡¶°‡ßá‡¶∂‡¶® ‡¶â‡¶≠‡¶Ø‡¶º ‡¶°‡ßá‡¶ü‡¶æ‡¶Ø‡¶º ‡¶≤‡¶∏ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        with torch.no_grad():\n",
        "            for split in ['train', 'val']:\n",
        "                for _ in range(self.config.evaluation_loops):\n",
        "                    input_batch, target_batch = self.data_loader.get_batch(split)\n",
        "                    _, loss = self.model(input_batch, target_batch)\n",
        "                    losses[split].append(loss.item())\n",
        "        self.model.train()  # ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶Æ‡ßã‡¶°‡ßá ‡¶´‡¶ø‡¶∞‡ßÅ‡¶®\n",
        "\n",
        "        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶≠‡¶æ‡¶ó‡ßá‡¶∞ ‡¶ó‡¶°‡¶º ‡¶≤‡¶∏ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ï‡¶∞‡ßÅ‡¶® (train, val)\n",
        "        return {split: sum(values) / len(values) for split, values in losses.items()}\n",
        "\n",
        "    def train(self):\n",
        "        # config-‡¶è ‡¶¶‡ßá‡¶Ø‡¶º‡¶æ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ‡¶∞ ‡¶Æ‡¶§ train_step ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡•§\n",
        "        for step in range(self.config.total_training_steps):\n",
        "\n",
        "            # ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ßß‡ß¶‡ß¶ ‡¶ß‡¶æ‡¶™ ‡¶™‡¶∞ ‡¶™‡¶∞ ‡¶¨‡¶æ ‡¶∂‡ßá‡¶∑ ‡¶ß‡¶æ‡¶™‡ßá ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\n",
        "                eval_loss = self.evaluate()\n",
        "                print(f\"Step {step}: Train Loss {eval_loss['train']:.4f}, Validation Loss {eval_loss['val']:.4f}\")\n",
        "\n",
        "            # ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç‡¶Ø‡¶º‡ßá‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™ (‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶¨‡¶æ‡¶∞ ‡¶Ø‡¶æ ‡¶ï‡¶∞‡¶¨‡ßá‡¶®)\n",
        "            train_loss = self.train_step()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPN1h-k_xejG"
      },
      "source": [
        "**Chapter 11: Trainer Class: Section 1: Class Definition** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU53fOfBPA_s"
      },
      "source": [
        "### Section 2: Class Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NcZr_SN-Ufm"
      },
      "source": [
        "Chapter 1 ‡¶•‡ßá‡¶ï‡ßá Chapter 11 ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶∏‡¶¨ ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶™‡ßá‡¶∏‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®‡•§<br>\n",
        "**DeterministicDropout ‡¶ï‡ßá nn.Dropout ‡¶¶‡¶ø‡ßü‡ßá ‡¶∞‡¶ø‡¶™‡ßç‡¶≤‡ßá‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§**\n",
        "\n",
        "[Watch the video!](https://youtu.be/j2ErzvlslKA)  \n",
        "- ‡¶ï‡ßã‡¶®‡ßã ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶®‡ßá‡¶á  \n",
        "- ‡ß™ ‡¶Æ‡¶ø‡¶®‡¶ø‡¶ü  \n",
        "\n",
        "‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶ü‡¶ø‡¶§‡ßá ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ answer_colab, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶∏‡ßá‡¶ü‡¶æ ‡¶Æ‡¶æ‡¶•‡¶æ‡¶Ø‡¶º ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§  \n",
        "\n",
        "```python\n",
        "AttentionHead: dropout = nn.Dropout(config.dropout_rate)\n",
        "MultiHeadAttention: dropout = nn.Dropout(config.dropout_rate)\n",
        "FeedForward:  nn.Dropout(config.dropout_rate)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnLnj31rPTLC"
      },
      "outputs": [],
      "source": [
        "class DataLoader:\n",
        "    def __init__(self, text, config):\n",
        "        self.config = config  # ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶Ö‡¶¨‡¶ú‡ßá‡¶ï‡ßç‡¶ü\n",
        "        chars = sorted(list(set(text)))  # ‡¶Ö‡¶®‡¶®‡ßç‡¶Ø ‡¶Ö‡¶ï‡ßç‡¶∑‡¶∞ ‡¶∏‡¶æ‡¶ú‡¶æ‡¶®‡ßã ‡¶π‡¶ö‡ßç‡¶õ‡ßá\n",
        "        self.ctoi = {char: index for index, char in enumerate(chars)}\n",
        "        self.itoc = {index: char for index, char in enumerate(chars)}\n",
        "        self.vocab_size = len(chars)\n",
        "\n",
        "        # ‡¶è‡¶®‡¶ï‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶ü‡ßá‡¶®‡¶∏‡¶∞‡ßá ‡¶∞‡ßÇ‡¶™‡¶æ‡¶®‡ßç‡¶§‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "        # ‡¶è‡¶á `__init__` ‡¶Æ‡ßá‡¶•‡¶°‡ßá‡¶∞ ‡¶¨‡¶æ‡¶á‡¶∞‡ßá ‡¶Ö‡¶®‡ßç‡¶Ø ‡¶Æ‡ßá‡¶•‡¶° ‡¶¨‡¶æ ‡¶Ü‡¶∞‡ßç‡¶ó‡ßÅ‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶ï‡¶≤ ‡¶ï‡¶∞‡¶§‡ßá `self.` ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡•§\n",
        "        self.data = torch.tensor(self.encode(text), dtype=torch.long)\n",
        "\n",
        "        # ‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£/‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á‡¶ï‡¶∞‡¶£ ‡¶°‡ßá‡¶ü‡¶æ‡¶Ø‡¶º ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "        # `self.data` ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡ßÉ‡¶§ ‡¶π‡¶Ø‡¶º ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶®‡ßã ‡¶Ü‡¶∞‡ßç‡¶ó‡ßÅ‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶®‡¶æ ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ ‡¶π‡¶Ø‡¶º‡•§\n",
        "        self.train_data, self.val_data = self.split_data()\n",
        "\n",
        "    def encode(self, text):\n",
        "        # ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶Ç‡¶ï‡ßá ‡¶á‡¶®‡¶°‡ßá‡¶ï‡ßç‡¶∏ ‡¶ï‡¶≤‡¶æ‡¶Æ‡ßá ‡¶∞‡ßÇ‡¶™‡¶æ‡¶®‡ßç‡¶§‡¶∞ ‡¶ï‡¶∞‡ßá‡•§ ‡¶Ö‡¶®‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶Ø ‡¶Æ‡ßá‡¶•‡¶° ‡¶¨‡¶æ ‡¶Ü‡¶∞‡ßç‡¶ó‡ßÅ‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶ï‡¶≤ ‡¶ï‡¶∞‡¶§‡ßá `self.` ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡•§\n",
        "        return [self.ctoi[c] for c in text]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        return ''.join([self.itoc[i] for i in indices])\n",
        "\n",
        "    def split_data(self):\n",
        "        split_index = int(0.9 * len(self.data))  # 90% ‡¶°‡ßá‡¶ü‡¶æ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç‡¶Ø‡¶º‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶™‡¶Ø‡¶º‡ßá‡¶®‡ßç‡¶ü‡•§\n",
        "        return self.data[:split_index], self.data[split_index:]\n",
        "\n",
        "    def get_batch(self, split):\n",
        "        data = self.train_data if split == 'train' else self.val_data\n",
        "        start_indices = torch.randint(len(data) - self.config.input_sequence_length, (self.config.batch_size,)) # ‡¶â‡ßé‡¶™‡¶®‡ßç‡¶® ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶ï‡ßç‡¶∏‡¶ü‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶ü ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶∏‡ßÇ‡¶ö‡¶ï\n",
        "\n",
        "        input_sequences = torch.stack([\n",
        "            data[start_index:start_index + self.config.input_sequence_length]\n",
        "            for start_index in start_indices\n",
        "        ])\n",
        "        target_sequences = torch.stack([\n",
        "            data[start_index + 1:start_index + self.config.input_sequence_length + 1]\n",
        "            for start_index in start_indices\n",
        "        ])\n",
        "        return input_sequences.to(self.config.device_type), target_sequences.to(self.config.device_type)\n",
        "\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        # vocabulary ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ x embedding ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶è‡¶Æ‡¶¨‡ßá‡¶°‡ßá‡¶° ‡¶ü‡ßá‡¶¨‡¶ø‡¶≤ ‡¶∏‡¶Ç‡¶ú‡ßç‡¶û‡¶æ‡¶Ø‡¶º‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def embed(self, input_indices):\n",
        "        # ‡¶á‡¶®‡¶™‡ßÅ‡¶ü ‡¶á‡¶®‡¶°‡ßá‡¶ï‡ßç‡¶∏‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡¶ø‡¶§ ‡¶è‡¶Æ‡¶¨‡ßá‡¶°‡ßá‡¶° ‡¶≠‡ßá‡¶ï‡ßç‡¶ü‡¶∞ ‡¶™‡¶æ‡¶®\n",
        "        return self.token_embedding_table.forward(input_indices)\n",
        "\n",
        "class PositionEmbedding(nn.Module):\n",
        "    def __init__(self, input_sequence_length = 8, embedding_dim = 8):\n",
        "        super().__init__()\n",
        "        # ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶® ‡¶è‡¶Æ‡¶¨‡ßá‡¶°‡¶ø‡¶Ç ‡¶∏‡ßç‡¶§‡¶∞\n",
        "        self.position_embedding_layer = nn.Embedding(input_sequence_length, embedding_dim)\n",
        "\n",
        "    def forward(self, input_indices):\n",
        "        # ‡¶á‡¶®‡¶™‡ßÅ‡¶ü ‡¶ü‡ßá‡¶®‡¶∏‡¶∞ input_indices ‡¶è‡¶∞ ‡¶Ü‡¶ï‡ßÉ‡¶§‡¶ø: [‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶æ‡¶á‡¶ú, ‡¶∏‡¶ø‡¶ï‡ßã‡¶Ø‡¶º‡ßá‡¶®‡ßç‡¶∏ ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø].\n",
        "        sequence_length = input_indices.shape[1]\n",
        "\n",
        "        # ‡¶ï‡ßç‡¶∞‡¶Æ‡ßá‡¶∞ ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶® ‡¶∏‡ßÇ‡¶ö‡¶ï ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶Ø‡ßá‡¶Æ‡¶® [0, 1, 2, ..., sequence_length-1])\n",
        "        position_indices = torch.arange(sequence_length, device=input_indices.device)\n",
        "\n",
        "        # ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶® ‡¶∏‡ßÇ‡¶ö‡¶ï‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶Æ‡ßç‡¶¨‡ßá‡¶°‡ßá‡¶° ‡¶≠‡ßá‡¶ï‡ßç‡¶ü‡¶∞ ‡¶®‡¶ø‡¶®\n",
        "        position_embeddings = self.position_embedding_layer.forward(position_indices)\n",
        "\n",
        "        return position_embeddings\n",
        "\n",
        "class EmbeddingModule(nn.Module):\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ü‡ßã‡¶ï‡ßá‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶Æ‡¶¨‡ßá‡¶°‡ßá‡¶° ‡¶≤‡ßá‡¶Ø‡¶º‡¶æ‡¶∞\n",
        "        self.token_embedding_layer = TokenEmbedding(vocab_size = vocab_size, embedding_dim = config.embedding_dim)  # ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶è‡¶Æ‡ßç‡¶¨‡ßá‡¶°‡¶ø‡¶Ç ‡¶∏‡ßç‡¶§‡¶∞\n",
        "        self.position_embedding_layer = PositionEmbedding(input_sequence_length = config.input_sequence_length, embedding_dim = config.embedding_dim)  # ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶® ‡¶§‡¶•‡ßç‡¶Ø ‡¶è‡¶Æ‡ßç‡¶¨‡ßá‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "\n",
        "    def forward(self, input_indices):\n",
        "        # ‡¶ü‡ßã‡¶ï‡ßá‡¶® ‡¶è‡¶Æ‡¶¨‡ßá‡¶°‡¶ø‡¶Ç ‡¶®‡¶ø‡¶®\n",
        "        token_embeddings = self.token_embedding_layer.embed(input_indices)\n",
        "\n",
        "        # ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶® ‡¶è‡¶Æ‡¶¨‡ßá‡¶°‡¶ø‡¶Ç ‡¶®‡¶ø‡¶®\n",
        "        position_embeddings = self.position_embedding_layer.forward(input_indices)\n",
        "\n",
        "        # ‡¶ü‡ßã‡¶ï‡ßá‡¶® ‡¶è‡¶Æ‡¶¨‡ßá‡¶°‡¶ø‡¶Ç ‡¶è‡¶¨‡¶Ç ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶® ‡¶è‡¶Æ‡¶¨‡ßá‡¶°‡¶ø‡¶Ç ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá\n",
        "        embeddings = position_embeddings + token_embeddings\n",
        "        return embeddings\n",
        "\n",
        "class LayerNorm(nn.Module):  # ‡¶è‡¶ñ‡¶æ‡¶®‡ßá nn.Module ‡¶•‡ßá‡¶ï‡ßá ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶æ‡¶ß‡¶ø‡¶ï‡¶æ‡¶∞ ‡¶ó‡ßç‡¶∞‡¶π‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "    def __init__(self, token_length, eps=1e-5, norm_dim=-1):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.norm_dim = norm_dim\n",
        "\n",
        "        # gamma ‡¶ì beta ‡¶ï‡ßá nn.Parameter ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶®‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡¶® ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡¶æ‡¶§‡ßá CPU ‡¶ì CUDA ‡¶â‡¶≠‡¶Ø‡¶º‡ßá‡¶á ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º‡•§\n",
        "        self.gamma = nn.Parameter(torch.ones(token_length))\n",
        "        self.beta = nn.Parameter(torch.zeros(token_length))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=self.norm_dim, keepdim=True)\n",
        "        var = torch.var(x, dim=self.norm_dim, keepdim=True, unbiased=False)\n",
        "        hat = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        output =  self.gamma * hat + self.beta\n",
        "        return output\n",
        "\n",
        "\n",
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, head_size, config):\n",
        "        super().__init__()\n",
        "        self.key_fc= nn.Linear(config.embedding_dim, head_size, bias=False)\n",
        "        self.query_fc = nn.Linear(config.embedding_dim, head_size, bias=False)\n",
        "        self.value_fc = nn.Linear(config.embedding_dim, head_size, bias=False)\n",
        "\n",
        "        # ‡¶Æ‡¶æ‡¶∏‡ßç‡¶ï ‡¶®‡¶ø‡¶ö‡ßÅ ‡¶§‡ßç‡¶∞‡¶ø‡¶≠‡ßÅ‡¶ú‡¶æ‡¶ï‡ßÉ‡¶§‡¶ø‡¶∞ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü‡ßç‡¶∞‡¶ø‡¶ï‡ßç‡¶∏ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º (self-attention-‡¶è‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£‡¶ø‡¶ï‡¶§‡¶æ ‡¶¨‡¶ú‡¶æ‡¶Ø‡¶º ‡¶∞‡ßá‡¶ñ‡ßá)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.input_sequence_length, config.input_sequence_length)))\n",
        "\n",
        "        # ‡¶°‡ßç‡¶∞‡¶™‡¶Ü‡¶â‡¶ü (‡¶®‡¶ø‡¶∞‡ßç‡¶ß‡¶æ‡¶∞‡¶ø‡¶§ ‡¶∏‡¶Ç‡¶∏‡ßç‡¶ï‡¶∞‡¶£ ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡¶Ç‡¶ú‡ßç‡¶û‡¶æ‡¶Ø‡¶º‡¶ø‡¶§)\n",
        "        self.dropout = nn.Dropout(config.dropout_rate)\n",
        "\n",
        "        self.head_size = head_size\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        B, T, C = input_tensor.shape  # ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö, ‡¶ü‡ßã‡¶ï‡ßá‡¶® ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø, ‡¶è‡¶Æ‡ßç‡¶¨‡ßá‡¶°‡¶ø‡¶Ç ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤\n",
        "\n",
        "        Key = self.key_fc.forward(input_tensor)     # (‡¶¨‡¶ø, ‡¶ü‡¶ø, ‡¶π‡ßá‡¶°_‡¶∏‡¶æ‡¶á‡¶ú)\n",
        "        Query = self.query_fc.forward(input_tensor)   # (‡¶¨‡¶ø, ‡¶ü‡¶ø, ‡¶π‡ßá‡¶°_‡¶∏‡¶æ‡¶á‡¶ú)\n",
        "        Value = self.value_fc.forward(input_tensor)   # (‡¶¨‡¶ø, ‡¶ü‡¶ø, ‡¶π‡ßá‡¶°_‡¶∏‡¶æ‡¶á‡¶ú)\n",
        "\n",
        "        # ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶ü‡ßá‡¶®‡¶∂‡¶® ‡¶∏‡ßç‡¶ï‡ßã‡¶∞ ‡¶ó‡¶£‡¶®‡¶æ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá (QK^T) / sqrt(embedding_dim)\n",
        "        attention_weights_before_mask = Query @ Key.transpose(-2, -1) * self.head_size**(-0.5)\n",
        "\n",
        "        # ‡¶Æ‡¶æ‡¶∏‡ßç‡¶ï ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá\n",
        "        mask = torch.triu(torch.ones(T, T), diagonal=1).to(input_tensor.device)\n",
        "        masked_attention_weights = attention_weights_before_mask.masked_fill(mask == 1, float('-inf'))\n",
        "\n",
        "        # ‡¶∏‡¶´‡¶ü‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶∏ ‚Üí ‡¶°‡ßç‡¶∞‡¶™‡¶Ü‡¶â‡¶ü ‚Üí ‡¶ì‡¶ú‡¶®‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶Ø‡ßã‡¶ó‡¶´‡¶≤\n",
        "        attention_weights = F.softmax(masked_attention_weights, dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "\n",
        "        out = attention_weights @ Value  # (‡¶¨‡¶ø, ‡¶ü‡¶ø, ‡¶π‡ßá‡¶°_‡¶∏‡¶æ‡¶á‡¶ú)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.embedding_dim = config.embedding_dim\n",
        "        self.head_size = int(self.embedding_dim / self.num_attention_heads)\n",
        "\n",
        "        # ModuleList ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶è‡¶ï‡¶æ‡¶ß‡¶ø‡¶ï ‡¶π‡ßá‡¶° ‡¶™‡¶∞‡¶ø‡¶ö‡¶æ‡¶≤‡¶®‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        self.attention_heads = nn.ModuleList([\n",
        "            AttentionHead(self.head_size, config)\n",
        "            for _ in range(self.num_attention_heads)\n",
        "        ])\n",
        "\n",
        "        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶π‡ßá‡¶°‡ßá‡¶∞ ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶Æ‡¶ø‡¶∂‡ßç‡¶∞‡¶£‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶≤‡¶ø‡¶®‡¶ø‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶≤‡ßá‡¶Ø‡¶º‡¶æ‡¶∞\n",
        "        self.output_projection = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
        "\n",
        "        # ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶°‡ßç‡¶∞‡¶™‡¶Ü‡¶â‡¶ü\n",
        "        self.dropout = nn.Dropout(config.dropout_rate)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        # ‡¶™‡ßç‡¶∞‡¶§‡ßç‡¶Ø‡ßá‡¶ï ‡¶π‡ßá‡¶° ‡¶•‡ßá‡¶ï‡ßá ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶®‡¶ø‡¶®\n",
        "        # (B, T, head_size) ‡¶è‡¶∞ ‡¶§‡¶æ‡¶≤‡¶ø‡¶ï‡¶æ\n",
        "        head_outputs_list = [head.forward(input_tensor) for head in self.attention_heads]\n",
        "\n",
        "        # ‡¶∏‡¶¨ ‡¶π‡ßá‡¶°‡ßá‡¶∞ ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶è‡¶ï‡¶§‡ßç‡¶∞‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶® ‚Üí (B, T, embedding_dim)\n",
        "        concatenated = torch.cat(head_outputs_list, dim=-1)\n",
        "\n",
        "        # ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü‡¶ï‡ßá ‡¶≤‡¶ø‡¶®‡¶ø‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶ü‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶∏‡¶´‡¶∞‡¶Æ‡ßá‡¶∂‡¶®‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶Æ‡ßá‡¶∂‡¶æ‡¶®‡ßã\n",
        "        projected = self.output_projection.forward(concatenated)\n",
        "\n",
        "        # ‡¶ö‡ßÇ‡¶°‡¶º‡¶æ‡¶®‡ßç‡¶§ ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü‡ßá ‡¶°‡ßç‡¶∞‡¶™‡¶Ü‡¶â‡¶ü ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        output = self.dropout.forward(projected)\n",
        "\n",
        "        return output\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(config.embedding_dim, config.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.hidden_dim, config.embedding_dim),\n",
        "            nn.Dropout(config.dropout_rate),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        return self.net(input_tensor)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø LayerNorm ‡¶Ö‡¶¨‡¶ú‡ßá‡¶ï‡ßç‡¶ü ‡¶§‡¶æ‡¶∞ ‡¶®‡¶ø‡¶ú‡¶∏‡ßç‡¶¨ ‡¶∏‡ßç‡¶ï‡ßá‡¶≤‡¶ø‡¶Ç ‡¶™‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶Æ‡¶ø‡¶ü‡¶æ‡¶∞ beta ‡¶è‡¶¨‡¶Ç gamma ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡ßá‡•§\n",
        "        self.layer_norm1 = nn.LayerNorm(config.embedding_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(config.embedding_dim)\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(config=config)\n",
        "        self.feed_forward = FeedForward(config=config)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        # forward ‡¶Æ‡ßá‡¶•‡¶° ‡¶¨‡¶æ‡¶¶ ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§\n",
        "        normed_input = self.layer_norm1(input_tensor) # ‡¶á‡¶®‡¶™‡ßÅ‡¶ü‡ßá Layer Norm ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        attention_output = self.multihead_attention(normed_input) # ‡¶Æ‡¶æ‡¶≤‡ßç‡¶ü‡¶ø-‡¶π‡ßá‡¶° ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶ü‡ßá‡¶®‡¶∂‡¶® ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        residual_attention = attention_output + input_tensor # \"before! layernorm1 ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        normed_attention = self.layer_norm2(residual_attention) # ‡¶∞‡ßá‡¶∏‡¶ø‡¶°‡ßÅ‡¶Ø‡¶º‡¶æ‡¶≤ ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü‡ßá ‡¶Ü‡¶¨‡¶æ‡¶∞ LayerNorm ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        feedforward_output = self.feed_forward(normed_attention) # ‡¶´‡¶ø‡¶°‡¶´‡¶∞‡ßã‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶° ‡¶®‡ßá‡¶ü‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶ï (FFN) ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        final_output = feedforward_output + residual_attention # \"before\" layernorm2 ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®!\n",
        "\n",
        "        return final_output\n",
        "\n",
        "class VocabularyLogits(nn.Module):\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        # ‡¶≤‡ßá‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶®‡¶∞‡¶Æ‡¶æ‡¶≤‡¶æ‡¶á‡¶ú‡ßá‡¶∂‡¶®\n",
        "        self.output_norm = nn.LayerNorm(config.embedding_dim)\n",
        "        # ‡¶∂‡¶¨‡ßç‡¶¶‡¶≠‡¶æ‡¶£‡ßç‡¶°‡¶æ‡¶∞‡ßá‡¶∞ ‡¶Ü‡¶ï‡¶æ‡¶∞‡ßá ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∑‡ßá‡¶™‡¶£\n",
        "        self.vocab_projection = nn.Linear(config.embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, transformer_block_output):\n",
        "        # Transformer ‡¶¨‡ßç‡¶≤‡¶ï ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶æ‡¶™‡ßç‡¶§ ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü‡ßá Layer normalization ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "        normalized_output = self.output_norm.forward(transformer_block_output)  # (‡¶¨‡¶ø, ‡¶ü‡¶ø, ‡¶∏‡¶ø)\n",
        "\n",
        "        # ‡¶∏‡ßç‡¶ï‡ßã‡¶∞‡¶ó‡ßÅ‡¶≤‡ßã‡¶ï‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶≤‡¶ø‡¶®‡¶ø‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶≤‡ßá‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶∂‡¶¨‡ßç‡¶¶‡¶≠‡¶æ‡¶£‡ßç‡¶°‡¶æ‡¶∞‡ßá‡¶∞ ‡¶Ü‡¶ï‡¶æ‡¶∞‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ‡¶Ø‡¶º ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∑‡ßá‡¶™‡¶£ ‡¶ï‡¶∞‡ßá‡•§\n",
        "        vocab_logits = self.vocab_projection.forward(normalized_output)  # (‡¶¨‡¶ø, ‡¶ü‡¶ø, ‡¶≠‡¶ø)\n",
        "\n",
        "        return vocab_logits\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        self.config = config  # ‡¶è‡¶ü‡¶ø ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º‡¶ì ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡ßÉ‡¶§ ‡¶π‡¶Ø‡¶º, ‡¶§‡¶æ‡¶á ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá‡¶®‡•§\n",
        "        self.embedding = EmbeddingModule(vocab_size, config=config)\n",
        "        self.blocks = nn.Sequential(*[TransformerBlock(config=config) for _ in range(config.layer_count)])\n",
        "        self.vocab_projection = VocabularyLogits(vocab_size=vocab_size, config=config)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "    def generate(self, input_indices, max_new_tokens):\n",
        "        # ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶ï ‡¶ü‡ßã‡¶ï‡ßá‡¶® `max_new_tokens` ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "        for _ in range(max_new_tokens):\n",
        "            input_conditioned = input_indices[:, -self.config.input_sequence_length:] # ‡¶á‡¶®‡¶™‡ßÅ‡¶ü ‡¶ï‡ßç‡¶≤‡¶ø‡¶™ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "\n",
        "            # ‡¶´‡¶∞‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶° ‡¶™‡¶æ‡¶∏ `(likelihood, loss)` ‡¶´‡ßá‡¶∞‡¶§ ‡¶¶‡ßá‡¶Ø‡¶º‚Äî‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ `likelihood` ‡¶ï‡ßá `logits` ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "            logits, _ = self.forward(input_conditioned, target_indices=None)\n",
        "            last_logits = logits[:, -1, :] # ‡¶∂‡ßá‡¶∑ ‡¶ü‡ßã‡¶ï‡ßá‡¶® ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶≤‡¶ó‡¶ø‡¶ü ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "            probs = F.softmax(last_logits, dim=-1) # Softmax ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡¶®‡¶æ ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "\n",
        "            # ‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ ‡¶ü‡ßã‡¶ï‡ßá‡¶® ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶ö‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "            next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # ‡¶®‡¶§‡ßÅ‡¶® ‡¶ü‡ßã‡¶ï‡ßá‡¶®‡¶ó‡ßÅ‡¶≤‡ßã ‡¶è‡¶ï‡¶§‡ßç‡¶∞‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶®, `input_indices` ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
        "            input_indices = torch.cat((input_indices, next_token), dim=1)\n",
        "\n",
        "        # ‡¶Æ‡ßÇ‡¶≤ `input_indices` ‡¶è‡¶¨‡¶Ç `max_new_tokens` ‡¶Ø‡ßã‡¶ó‡¶´‡¶≤ ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø‡ßá‡¶∞ ‡¶∂‡ßá‡¶∑ `input_indices` ‡¶´‡ßá‡¶∞‡¶§ ‡¶¶‡ßá‡¶Ø‡¶º‡•§\n",
        "        return input_indices\n",
        "\n",
        "    # ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡¶®‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶ï‡ßç‡¶∑‡¶§‡¶ø ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "    def forward(self, input_indices, target_indices):\n",
        "        embeddings = self.embedding(input_indices)\n",
        "        blocks_output = self.blocks(embeddings)\n",
        "        logits = self.vocab_projection(blocks_output)\n",
        "\n",
        "        # ‡¶á‡¶®‡¶´‡¶æ‡¶∞‡ßá‡¶®‡ßç‡¶∏‡ßá ‡¶ï‡ßã‡¶®‡ßã ‡¶ü‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶ü ‡¶•‡¶æ‡¶ï‡ßá ‡¶®‡¶æ, ‡¶§‡¶æ‡¶á ‡¶≤‡¶∏ `None` ‡¶π‡¶Ø‡¶º‡•§\n",
        "        # ‚Äî‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡¶®‡¶æ (logits) ‡¶´‡ßá‡¶∞‡¶§ ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ ‡¶π‡¶Ø‡¶º‡•§\n",
        "        if target_indices is None:\n",
        "            return logits, None\n",
        "\n",
        "        batch_size, token_len, vocab_size = logits.shape\n",
        "        logits = logits.view(batch_size * token_len, vocab_size)\n",
        "        targets = target_indices.view(batch_size * token_len)\n",
        "        loss = self.criterion(logits, targets)\n",
        "\n",
        "        return logits, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0vcUT2kwwR5"
      },
      "source": [
        "**DeterministicDropout-‡¶è‡¶∞ ‡¶ú‡¶æ‡ßü‡¶ó‡¶æ‡ßü nn.Dropout ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®**\n",
        "```python\n",
        "AttentionHead: dropout = nn.Dropout(config.dropout_rate)\n",
        "MultiHeadAttention: dropout = nn.Dropout(config.dropout_rate)\n",
        "FeedForward:  nn.Dropout(config.dropout_rate)\n",
        "```\n",
        "<label><input type=\"checkbox\"> Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAqEd0cywV56"
      },
      "source": [
        "**Chapter 12: Trainer Class: Section 2: ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶∏‡¶æ‡¶∞‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡ßá‡¶™** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IGG8rZJT9fx"
      },
      "source": [
        "### Section 3: Training and Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pdT24q93vOX"
      },
      "source": [
        "‡¶è‡¶ñ‡¶® ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§, embedding dimension ‡¶õ‡¶ø‡¶≤ 8, ‡¶¶‡ßÅ‡¶ü‡¶ø attention heads ‡¶∏‡¶π, ‡¶è‡¶¨‡¶Ç FeedForward Network-‡¶è 16-dim hidden layers ‡¶õ‡¶ø‡¶≤‡•§<br>\n",
        "‡¶è‡¶ü‡¶æ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶™‡ßç‡¶∞‡¶ï‡¶æ‡¶∂‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ñ‡ßÅ‡¶¨ ‡¶∏‡ßÄ‡¶Æ‡¶ø‡¶§‡•§<br>\n",
        "‡¶è‡¶ñ‡¶®, embedding dimension 64 ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®, 4 attention heads ‡¶∏‡¶π ‡¶è‡¶¨‡¶Ç FeedForward Network-‡¶è 256-dim hidden layers ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®‡•§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ooeKTSmYOdn",
        "outputId": "505d4f44-f337-48eb-dde3-e5e4198a9b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Each setting for the ModelConfig class:\n",
            "Batch size: 16\n",
            "Input sequence length: 32\n",
            "Total training steps: 5000\n",
            "Evaluation frequency (in steps): 100\n",
            "Learning rate: 0.001\n",
            "Device in use: cuda\n",
            "Number of evaluation loops: 10\n",
            "Embedding vector dimension: 64\n",
            "Hidden layer dimension of the feedforward network: 256\n",
            "Number of attention heads: 4\n",
            "Number of model layers: 4\n",
            "Dropout rate: 0.1\n",
            "Random seed value: 1337\n"
          ]
        }
      ],
      "source": [
        "# ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡ßá‡¶ü‡¶ø‡¶Ç‡¶∏ ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£‡¶ï‡¶æ‡¶∞‡ßÄ ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏\n",
        "class ModelConfig:\n",
        "    batch_size = 16  # ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞‡ßá ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶ú‡¶æ‡¶§ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶°‡ßá‡¶ü‡¶æ‡¶∞ ‡¶™‡¶∞‡¶ø‡¶Æ‡¶æ‡¶£ (‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶æ‡¶á‡¶ú)\n",
        "    input_sequence_length = 32  # ‡¶á‡¶®‡¶™‡ßÅ‡¶ü ‡¶°‡ßá‡¶ü‡¶æ‡¶∞ ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø (‡¶∏‡¶ø‡¶ï‡ßÅ‡¶Ø‡¶º‡ßá‡¶®‡ßç‡¶∏ ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø)\n",
        "    total_training_steps = 5000  # ‡¶∏‡¶∞‡ßç‡¶¨‡ßã‡¶ö‡ßç‡¶ö ‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ (‡¶ß‡¶æ‡¶™‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ)\n",
        "    evaluation_frequency = 100  # ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ï‡¶∞‡ßç‡¶Æ‡¶ï‡ßç‡¶∑‡¶Æ‡¶§‡¶æ ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶®‡ßá‡¶∞ ‡¶´‡ßç‡¶∞‡¶ø‡¶ï‡ßã‡¶Ø‡¶º‡ßá‡¶®‡ßç‡¶∏‡¶ø\n",
        "    learning_rate = 0.001  # ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶π‡¶æ‡¶∞\n",
        "    device_type = 'cuda' if torch.cuda.is_available() else 'cpu'  # ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡ßá‡¶∞ ‡¶°‡¶ø‡¶≠‡¶æ‡¶á‡¶∏ (GPU ‡¶¨‡¶æ CPU)\n",
        "    evaluation_loops = 10  # ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶®‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶™‡ßÅ‡¶®‡¶∞‡¶æ‡¶¨‡ßÉ‡¶§‡ßç‡¶§‡¶ø‡¶∞ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ\n",
        "    embedding_dim = 64  # ‡¶è‡¶Æ‡ßç‡¶¨‡ßá‡¶°‡ßá‡¶° ‡¶≤‡ßá‡¶Ø‡¶º‡¶æ‡¶∞‡ßá‡¶∞ ‡¶Ü‡¶ï‡¶æ‡¶∞ (‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶≠‡ßá‡¶ï‡ßç‡¶ü‡¶∞‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ‡¶∞ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ)\n",
        "    hidden_dim = 256\n",
        "    num_attention_heads = 4  # ‡¶®‡ßã‡¶ü ‡¶Æ‡ßá‡¶ï‡¶æ‡¶®‡¶ø‡¶ú‡¶Æ ‡¶π‡ßá‡¶° ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞\n",
        "    layer_count = 4  # ‡¶Æ‡¶°‡ßá‡¶≤‡ßá‡¶∞ ‡¶∏‡ßç‡¶§‡¶∞‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ\n",
        "    dropout_rate = 0.1  # ‡¶°‡ßç‡¶∞‡¶™‡¶Ü‡¶â‡¶ü ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡¶®‡¶æ\n",
        "    random_seed_value = 1337  # ‡¶™‡ßÅ‡¶®‡¶∞‡ßÅ‡¶§‡ßç‡¶™‡¶æ‡¶¶‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∞‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡¶Æ ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶∏‡ßÄ‡¶°‡¶∏‡¶Æ‡ßÇ‡¶π\n",
        "\n",
        "# ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶∏‡ßá‡¶ü‡¶ø‡¶Ç‡¶∏ ‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "config = ModelConfig()\n",
        "\n",
        "print(\"ModelConfig ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶∏‡ßá‡¶ü‡¶ø‡¶Ç:\")\n",
        "print(f\"Batch size: {config.batch_size}\")\n",
        "print(f\"Input sequence length: {config.input_sequence_length}\")\n",
        "print(f\"Total training steps: {config.total_training_steps}\")\n",
        "print(f\"Evaluation frequency (in steps): {config.evaluation_frequency}\")\n",
        "print(f\"Learning rate: {config.learning_rate}\")\n",
        "print(f\"Device in use: {config.device_type}\")\n",
        "print(f\"Number of evaluation loops: {config.evaluation_loops}\")\n",
        "print(f\"Embedding vector dimension: {config.embedding_dim}\")\n",
        "print(f\"Hidden layer dimension of the feedforward network: {config.hidden_dim}\")\n",
        "print(f\"Number of attention heads: {config.num_attention_heads}\")\n",
        "print(f\"Number of model layers: {config.layer_count}\")\n",
        "print(f\"Dropout rate: {config.dropout_rate}\")\n",
        "print(f\"Random seed value: {config.random_seed_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwvOpyQPm5Jl"
      },
      "source": [
        "**`Check Point`**\n",
        "<label><input type=\"checkbox\"> ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶® Config ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶∏‡ßá‡¶ü‡¶ø‡¶Ç ‡¶∏‡¶†‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá ‡¶¶‡ßá‡¶ñ‡¶æ‡¶ö‡ßç‡¶õ‡ßá<br></label>\n",
        "- ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶æ‡¶á‡¶ú: 16<br>\n",
        "- ‡¶¨‡ßç‡¶≤‡¶ï ‡¶∏‡¶æ‡¶á‡¶ú: 32<br>\n",
        "- ‡¶∏‡¶∞‡ßç‡¶¨‡ßã‡¶ö‡ßç‡¶ö ‡¶á‡¶®‡¶ü‡¶æ‡¶∞‡ßá‡¶∂‡¶®: 5000<br>\n",
        "- ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶® ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶≠‡ßç‡¶Ø‡¶æ‡¶≤: 100<br>\n",
        "- ‡¶≤‡¶æ‡¶∞‡ßç‡¶®‡¶ø‡¶Ç ‡¶∞‡ßá‡¶ü: 0.001<br>\n",
        "- ‡¶á‡¶â‡¶ú‡¶° ‡¶°‡¶ø‡¶≠‡¶æ‡¶á‡¶∏: cuda ‡¶¨‡¶æ cpu<br>\n",
        "- ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶® ‡¶á‡¶®‡¶ü‡¶æ‡¶∞‡ßá‡¶∂‡¶®‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ: 10<br>\n",
        "- ‡¶è‡¶Æ‡ßç‡¶¨‡ßá‡¶°‡¶ø‡¶Ç ‡¶≤‡ßá‡¶Ø‡¶º‡¶æ‡¶∞‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ: 64<br>\n",
        "- ‡¶´‡¶ø‡¶°‡¶´‡¶∞‡ßã‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶° ‡¶π‡¶ø‡¶°‡ßá‡¶® ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ: 256<br>\n",
        "- ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶ü‡ßá‡¶®‡¶∂‡¶® ‡¶π‡ßá‡¶°‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ: 4<br>\n",
        "- ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßá‡¶Ø‡¶º‡¶æ‡¶∞‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ: 4<br>\n",
        "- ‡¶°‡ßç‡¶∞‡¶™‡¶Ü‡¶â‡¶ü ‡¶∞‡ßá‡¶ü: 0.1<br>\n",
        "- ‡¶∏‡ßÄ‡¶° ‡¶≠‡ßç‡¶Ø‡¶æ‡¶≤‡ßÅ: 1337<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EctA8L49Tsc0",
        "outputId": "d7dfe830-e4bb-4f40-8b15-8cda7e56de12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x782b68401490>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶ø‡¶° ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "config = ModelConfig()\n",
        "torch.manual_seed(config.random_seed_value)  # ‡¶™‡ßÅ‡¶®‡¶∞‡ßÅ‡¶§‡ßç‡¶™‡¶æ‡¶¶‡¶® ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡¶∞‡¶§‡ßá ‡¶∞‚Äç‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡¶Æ ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶∏‡ßÄ‡¶° ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXBa9z1ogsUw"
      },
      "outputs": [],
      "source": [
        "# ‡¶°‡ßá‡¶ü‡¶æ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "with open(\"input.txt\", 'r', encoding = 'utf-8') as f:\n",
        "    text_data = f.read()\n",
        "data_loader = DataLoader(text_data, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtyVxmwiTotc",
        "outputId": "c124075e-6a3d-413a-f0f9-ef56415b2dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.209729 M parameters\n"
          ]
        }
      ],
      "source": [
        "# ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ì ‡¶Ö‡¶™‡ßç‡¶ü‡¶ø‡¶Æ‡¶æ‡¶á‡¶ú‡¶æ‡¶∞ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "model = BigramLanguageModel(vocab_size = data_loader.vocab_size, config = config).to(config.device_type)  # ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá ‡¶°‡¶ø‡¶≠‡¶æ‡¶á‡¶∏‡¶ü‡¶ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá‡¶® ‡¶§‡¶æ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "# ‡¶Æ‡¶°‡ßá‡¶≤‡ßá‡¶∞ ‡¶™‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶Æ‡¶ø‡¶ü‡¶æ‡¶∞ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶™‡ßç‡¶∞‡¶ø‡¶®‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mysHV8yjE7P6"
      },
      "source": [
        "‡¶§‡ßÅ‡¶≤‡¶®‡¶æ‡¶Æ‡ßÇ‡¶≤‡¶ï‡¶≠‡¶æ‡¶¨‡ßá, GPT2-Small ‡¶Æ‡¶°‡ßá‡¶≤‡ßá‡¶∞ ‡ßß‡ßß‡ß≠M (‡¶¨‡¶æ ‡ßß‡ß®‡ß™M) ‡¶™‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶Æ‡¶ø‡¶ü‡¶æ‡¶∞ ‡¶∞‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx-g4ndFubat"
      },
      "source": [
        "‡¶è‡¶ï‡ßç‡¶∏‡¶™‡ßá‡¶∞‡¶ø‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá, ‡¶™‡ßç‡¶∞‡¶ø-‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶ß‡¶æ‡¶™‡ßá ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpnodhC5ubat",
        "outputId": "77b04870-2352-4921-fbea-3ad7f62188ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's henvIeuW;JcijkeLWfUaUJW;VcE!Pf;ocFF&oNhq$eQLJOOEFWXgjNhhqv;Es\n",
            "iowD&ZqK&CgwN'Pq$mFHGjX.esumfonqUzgrN?pNVvN!Iebiqfs!EuOt3Zw?Bjx$oYk-wXmvevRibdVde!eJgRLKasNnge?DEYpK! 'scfoOl!Ebe$iol$-UpfXGKtewgLMsO!?fX?&D?;-$zBR.SudGdOo.&co\n",
            "zvzNqQriRR'QbHbs'QqXghiHWJwLUEZE&pNz\n",
            "T'Rk!ZgbN?tmE.uJaekBK?Oh&n&Um,LDqc'omcC&Z;xpZGipgRQeN$y?VDbOvsN,$IcNhepTHJeWkzKdrf?roHm?dfwFUpwMVg;ei&$RCXTyowaFZhjVBm$3g33cAuh,K?UlAGcX;p!JUlNvvbIHG.3inUc.HjMCsyhnpwAKylbSHT'pXh3UNfO:mreo'VrL'cpe-NC,ntZAziOpKcpTOE.hs:Ck&z'LGJgyb3?p!3fI,OjzFHE\n"
          ]
        }
      ],
      "source": [
        "text = \"Let's he\"  # ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü\n",
        "initial_context = torch.tensor(data_loader.encode(text), dtype=torch.long)\n",
        "# unsqueeze(0) ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶°‡¶æ‡¶á‡¶Æ‡ßá‡¶®‡¶∂‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶æ‡¶á‡¶ú=1)\n",
        "initial_context_unsqueeze = initial_context.unsqueeze(0)\n",
        "# ‚Üì ‡¶Æ‡ßÇ‡¶≤ ‡¶ï‡¶•‡¶æ ‡¶π‡¶≤‡ßã ‡¶è‡¶ü‡¶ø ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá ‡¶°‡¶ø‡¶≠‡¶æ‡¶á‡¶∏ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶õ‡ßá‡¶® (CPU ‡¶¨‡¶æ GPU)-‡¶§‡ßá ‡¶∏‡¶∞‡¶æ‡¶®‡ßã!\n",
        "initial_context_unsqueeze = initial_context_unsqueeze.to(config.device_type)\n",
        "\n",
        "# ‡¶â‡¶§‡ßç‡¶™‡¶æ‡¶¶‡¶® ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "generated_sequence_initial = model.generate(initial_context_unsqueeze, max_new_tokens=500)\n",
        "print(data_loader.decode(generated_sequence_initial[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYintz_Aubat"
      },
      "source": [
        "‡¶π‡ßÅ‡¶Æ, ‡¶è‡¶ü‡¶æ ‡¶§‡ßã ‡¶è‡¶ï‡¶ü‡¶æ ‡¶ï‡¶Æ‡ßç‡¶™‡¶ø‡¶â‡¶ü‡¶æ‡¶∞üíª, ‡¶§‡¶æ‡¶á ‡¶®‡¶æ?\n",
        "\n",
        "‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶ö‡¶≤ ‡¶∏‡ßá‡¶ü‡¶æ‡¶ï‡ßá ‡¶ü‡ßç‡¶∞‡ßá‡¶® ‡¶ï‡¶∞‡¶ø ‡¶Ü‡¶∞ ‡¶õ‡ßã‡¶ü ‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ‡¶∞ ‡¶Æ‡¶§‡ßã ‡¶¨‡¶°‡¶º ‡¶ï‡¶∞‡¶øüë∂!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK_3F336Eu6z"
      },
      "source": [
        "**‡¶∏‡¶¨‡¶∂‡ßá‡¶∑‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶™‡ßå‡¶Å‡¶õ‡ßá ‡¶ó‡ßá‡¶õ‡¶ø ‡¶∂‡ßá‡¶∑ ‡¶™‡¶∞‡ßç‡¶¨‡ßá‡•§ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶õ‡¶ø [emotional BGM¬π](https://youtu.be/GqmAe0QfkjU?feature=shared)‡•§<br>‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶π‡¶¨‡ßá ‡¶Ü‡¶®‡ßÅ‡¶Æ‡¶æ‡¶®‡¶ø‡¶ï ‡ß® ‡¶•‡ßá‡¶ï‡ßá ‡ß™ ‡¶Æ‡¶ø‡¶®‡¶ø‡¶ü‡•§ ‡¶ö‡¶≤‡ßÅ‡¶® ‡¶è‡¶á ‡¶Æ‡ßÅ‡¶π‡ßÇ‡¶∞‡ßç‡¶§‡ßá ‡¶Æ‡¶ó‡ßç‡¶® ‡¶π‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶á‡•§**\n",
        "\n",
        "---\n",
        "\n",
        "Content Reference:  \n",
        "¬π **DooPiano**, ‚ÄúBTS (Î∞©ÌÉÑÏÜåÎÖÑÎã®) ‚Äì Î¥ÑÎÇ† (Spring Day) Piano & String Orchestra Version,‚Äù YouTube, 3:41, published ~8.2‚ÄØyears ago (circa 2017). Accessed July‚ÄØ8‚ÄØ2025.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6t0rayVFh2U"
      },
      "source": [
        "**‡¶è‡¶ï‡¶ü‡ßÅ ‡¶π‡¶≤‡ßá‡¶ì BGM ‡¶∂‡ßÅ‡¶®‡¶§‡ßá ‡¶≠‡ßÅ‡¶≤‡¶¨‡ßá‡¶® ‡¶®‡¶æ! ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§‡¶≠‡¶æ‡¶¨‡ßá‡¶á ‡¶Æ‡¶® ‡¶õ‡ßÅ‡¶Å‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶¨‡ßá! ‡¶è‡¶¨‡¶æ‡¶∞, ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶∏‡ßá‡¶≤‡¶ü‡¶ø ‡¶ö‡¶æ‡¶≤‡¶ø‡¶Ø‡¶º‡ßá ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶®!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpagygD5TqHA",
        "outputId": "87c4c733-8f0d-45da-fe25-cd8b2fd6d5a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===TRAINING STARTED SUCCESSFULLY===\n",
            "Step 0: Train Loss 2.3080, Validation Loss 2.3095\n",
            "Step 100: Train Loss 2.2592, Validation Loss 2.2887\n",
            "Step 200: Train Loss 2.2122, Validation Loss 2.2228\n",
            "Step 300: Train Loss 2.1850, Validation Loss 2.1929\n",
            "Step 400: Train Loss 2.1433, Validation Loss 2.1610\n",
            "Step 500: Train Loss 2.0731, Validation Loss 2.1434\n",
            "Step 600: Train Loss 2.0713, Validation Loss 2.1265\n",
            "Step 700: Train Loss 2.0781, Validation Loss 2.0784\n",
            "Step 800: Train Loss 2.0399, Validation Loss 2.1171\n",
            "Step 900: Train Loss 1.9939, Validation Loss 2.0921\n",
            "Step 1000: Train Loss 2.0463, Validation Loss 2.0800\n",
            "Step 1100: Train Loss 2.0031, Validation Loss 2.0437\n",
            "Step 1200: Train Loss 1.9710, Validation Loss 2.0322\n",
            "Step 1300: Train Loss 1.8837, Validation Loss 2.0148\n",
            "Step 1400: Train Loss 1.9525, Validation Loss 2.0299\n",
            "Step 1500: Train Loss 1.9432, Validation Loss 2.0055\n",
            "Step 1600: Train Loss 1.9284, Validation Loss 1.9633\n",
            "Step 1700: Train Loss 1.9180, Validation Loss 1.9909\n",
            "Step 1800: Train Loss 1.8999, Validation Loss 1.9350\n",
            "Step 1900: Train Loss 1.8392, Validation Loss 1.9623\n",
            "Step 2000: Train Loss 1.8845, Validation Loss 1.9732\n",
            "Step 2100: Train Loss 1.8869, Validation Loss 1.9537\n",
            "Step 2200: Train Loss 1.8619, Validation Loss 1.9648\n",
            "Step 2300: Train Loss 1.8186, Validation Loss 1.9966\n",
            "Step 2400: Train Loss 1.8383, Validation Loss 1.9590\n",
            "Step 2500: Train Loss 1.8500, Validation Loss 1.9092\n",
            "Step 2600: Train Loss 1.8149, Validation Loss 1.8838\n",
            "Step 2700: Train Loss 1.8128, Validation Loss 1.9213\n",
            "Step 2800: Train Loss 1.8046, Validation Loss 1.9234\n",
            "Step 2900: Train Loss 1.8057, Validation Loss 1.9302\n",
            "Step 3000: Train Loss 1.7888, Validation Loss 1.8733\n",
            "Step 3100: Train Loss 1.7705, Validation Loss 1.9013\n",
            "Step 3200: Train Loss 1.7730, Validation Loss 1.9126\n",
            "Step 3300: Train Loss 1.8045, Validation Loss 1.9461\n",
            "Step 3400: Train Loss 1.7554, Validation Loss 1.9231\n",
            "Step 3500: Train Loss 1.7937, Validation Loss 1.8936\n",
            "Step 3600: Train Loss 1.7712, Validation Loss 1.8767\n",
            "Step 3700: Train Loss 1.7668, Validation Loss 1.8839\n",
            "Step 3800: Train Loss 1.7718, Validation Loss 1.8480\n",
            "Step 3900: Train Loss 1.7603, Validation Loss 1.8709\n",
            "Step 4000: Train Loss 1.7487, Validation Loss 1.8557\n",
            "Step 4100: Train Loss 1.7145, Validation Loss 1.8529\n",
            "Step 4200: Train Loss 1.7628, Validation Loss 1.8611\n",
            "Step 4300: Train Loss 1.6964, Validation Loss 1.8522\n",
            "Step 4400: Train Loss 1.7155, Validation Loss 1.8929\n",
            "Step 4500: Train Loss 1.7233, Validation Loss 1.8741\n",
            "Step 4600: Train Loss 1.7043, Validation Loss 1.8837\n",
            "Step 4700: Train Loss 1.6532, Validation Loss 1.8430\n",
            "Step 4800: Train Loss 1.6850, Validation Loss 1.7992\n",
            "Step 4900: Train Loss 1.7202, Validation Loss 1.8850\n",
            "Step 4999: Train Loss 1.7031, Validation Loss 1.9120\n",
            "Training DONE\n",
            "Model and optimizer state saved to bigram_language_model.pth\n"
          ]
        }
      ],
      "source": [
        "print(\"===‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶∏‡¶´‡¶≤‡¶≠‡¶æ‡¶¨‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá===\")\n",
        "\n",
        "# ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶¶‡¶ø‡¶®\n",
        "trainer = Trainer(model, optimizer, data_loader, config)\n",
        "trainer.train()\n",
        "\n",
        "# ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá\n",
        "save_path = \"bigram_language_model.pth\"\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict()\n",
        "}, save_path)\n",
        "\n",
        "print(\"‡¶™‡ßç‡¶∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶∏‡¶Æ‡ßç‡¶™‡¶®‡ßç‡¶® ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá\")\n",
        "print(f\"Model and optimizer state saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiEiQNKci0xq",
        "outputId": "76f971cc-7a84-4c47-c9a6-dac8152999fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Model Loaded Successfully!=====\n"
          ]
        }
      ],
      "source": [
        "# ---- ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶ø‡¶§ ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶° ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶è‡¶¨‡¶Ç ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶§‡ßà‡¶∞‡¶ø ‡¶π‡¶ö‡ßç‡¶õ‡ßá -----\n",
        "# ‡¶®‡¶§‡ßÅ‡¶® ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ì ‡¶Ö‡¶™‡¶ü‡¶ø‡¶Æ‡¶æ‡¶á‡¶ú‡¶æ‡¶∞ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶è‡¶ï‡¶á ‡¶∏‡ßá‡¶ü‡¶ø‡¶Ç‡¶∏ ‡¶ì ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶°‡ßá‡¶´‡¶ø‡¶®‡¶ø‡¶∂‡¶® ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®)\n",
        "loaded_model = BigramLanguageModel(vocab_size = data_loader.vocab_size, config = config).to(config.device_type)  # ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡ßÉ‡¶§ ‡¶°‡¶ø‡¶≠‡¶æ‡¶á‡¶∏ ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "loaded_optimizer = torch.optim.AdamW(loaded_model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "save_path = \"bigram_language_model.pth\"\n",
        "checkpoint = torch.load(save_path, map_location=config.device_type)\n",
        "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "loaded_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "print(\"===== ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡¶´‡¶≤‡¶≠‡¶æ‡¶¨‡ßá ‡¶≤‡ßã‡¶° ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá! =====\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Pj_bPCEPPS"
      },
      "source": [
        "‡¶Æ‡¶°‡ßá‡¶≤‡¶ï‡ßá evaluation ‡¶Æ‡ßã‡¶°‡ßá ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶∂‡¶®‡ßá‡¶∞ ‡¶Ü‡¶ó‡ßá Dropout ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá ‡¶¶‡¶ø‡¶®‡•§\n",
        "\n",
        "‡¶≠‡ßÅ‡¶≤‡ßá ‡¶ó‡ßá‡¶≤‡ßá Dropout ‡¶ö‡¶æ‡¶≤‡ßÅ ‡¶π‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶Ø‡¶º‡•§ ‡¶§‡¶ñ‡¶® ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™ ‡¶π‡¶¨‡ßá, ‡¶§‡¶æ‡¶á ‡¶∏‡¶æ‡¶¨‡¶ß‡¶æ‡¶® ‡¶•‡¶æ‡¶ï‡ßÅ‡¶®‡•§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yuLBig8EG91",
        "outputId": "83214a4c-14a2-4649-d21a-e1e6755d5a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Set to Evaluation mode, disabled Dropout. =====\n"
          ]
        }
      ],
      "source": [
        "loaded_model.eval()\n",
        "print(\"===== ‡¶á‡¶≠‡ßç‡¶Ø‡¶æ‡¶≤‡ßÅ‡¶Ø‡¶º‡ßá‡¶∂‡¶® ‡¶Æ‡ßã‡¶°‡ßá ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá, ‡¶°‡ßç‡¶∞‡¶™‡¶Ü‡¶â‡¶ü ‡¶®‡¶ø‡¶∑‡ßç‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡•§ =====\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaQb254DuA8X",
        "outputId": "b6f93c3a-e5ce-47b6-b2d3-d61613389e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoded_prompt\n",
            "Tensor Size: [8]\n",
            "tensor([\n",
            "         24.00,  43.00,  58.00,   5.00,  57.00,   1.00,  46.00,  43.00\n",
            "       ])\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Let's he\"  # ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü\n",
        "encoded_prompt = torch.tensor(data_loader.encode(prompt), dtype=torch.long)\n",
        "print_formatted_tensor(\"‡¶è‡¶®‡¶ï‡ßã‡¶° ‡¶ï‡¶∞‡¶æ ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü\", encoded_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QoDkdBPuC2Q",
        "outputId": "cf25d96f-7b3b-4fc3-bc7a-80252e47a5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoded_prompt_unsqueeze\n",
            "Tensor Size: [1, 8]\n",
            "tensor([\n",
            "         [ 24.00,  43.00,  58.00,   5.00,  57.00,   1.00,  46.00,  43.00]\n",
            "       ])\n"
          ]
        }
      ],
      "source": [
        "# unsqueeze(0) ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶æ‡¶á‡¶ú=1)\n",
        "encoded_prompt_unsqueeze = encoded_prompt.unsqueeze(0)\n",
        "print_formatted_tensor(\"‡¶è‡¶®‡¶ï‡ßã‡¶°‡ßá‡¶°_‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü_‡¶Ü‡¶®‡¶∏‡¶ï‡ßÅ‡¶á‡¶ú\", encoded_prompt_unsqueeze)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dUOQgT3uEHx"
      },
      "outputs": [],
      "source": [
        "# ‚Üì ‡¶Æ‡ßÇ‡¶≤ ‡¶ï‡¶•‡¶æ ‡¶π‡¶≤ ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü ‡¶ü‡ßá‡¶®‡¶∏‡¶∞‡¶ü‡¶ø ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá ‡¶°‡¶ø‡¶≠‡¶æ‡¶á‡¶∏ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶õ‡ßá‡¶® (CPU ‡¶¨‡¶æ GPU) ‡¶∏‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶∏‡¶∞‡¶ø‡¶Ø‡¶º‡ßá ‡¶®‡ßá‡¶ì‡¶Ø‡¶º‡¶æ!\n",
        "encoded_prompt_unsqueeze = encoded_prompt_unsqueeze.to(config.device_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdiKzDt6zXpP"
      },
      "source": [
        "```python\n",
        "Instance: loaded_model\n",
        "Method: generate\n",
        "Arguments: encoded_prompt_unsqueeze, max_new_tokens=1000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U58DsEfuF27",
        "outputId": "41bb755e-a8bc-4109-b385-79ede0010b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's he weath to begiver thing thou are perpisency the gertater sing\n",
            "To With beenes; no from to the chaul!\n",
            "\n",
            "JUTIO:\n",
            "Were this not the carence your in singrard hath lond\n",
            "Capus leet.\n",
            "\n",
            "BRUTUS:\n",
            "Thee bust to me to speaks or his it,\n",
            "\n",
            "Deseetock untertay laid I wand for shing\n",
            "that ittience, God nig for the from do it it.\n",
            "\n",
            "Pervore, I sethall thou breather,\n",
            "By tyre agent man some thou my servery plaid be the spoble.\n",
            "\n",
            "GLOUCESTER:\n",
            "Shallo, Say fauls I weick.\n",
            "\n",
            "DUCESTER MARGAREY:\n",
            "My noble thear, an, and at to he's guend\n",
            "For me full I say's be swould Gentleat haph till\n",
            "Nor And being years their rlancues\n",
            "The Last burssened to her be gry our sto stoot\n",
            "Ands that nurse steep\n",
            "Of aund will of her age man, tiSingment your boy's rings:\n",
            "Your my and again and well I would theur ady\n",
            "A samernon to do time'n sail thou lack your juty,\n",
            "No? I coundertife thou have thee other awarthrough a dne'd I preaty\n",
            "Waveichard him time if our good bowers highne:\n",
            "Thears.\n",
            "\n",
            "Thidds; and I' weal theseity. Bollow Richions:\n",
            "As City you?I heark,\n"
          ]
        }
      ],
      "source": [
        "# ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶® ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶®\n",
        "generated_sequence = loaded_model.generate(encoded_prompt_unsqueeze, max_new_tokens=1000) # TODO: ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£,\n",
        "print(data_loader.decode(generated_sequence[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcHLCQ6P4O-8"
      },
      "source": [
        "‡¶è‡¶¨‡¶æ‡¶∞ nanoGPT ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶ï‡¶Æ‡ßç‡¶™‡¶ø‡¶â‡¶ü‡¶æ‡¶∞üíª ‡¶•‡ßá‡¶ï‡ßá ‡¶è‡¶ï‡¶ü‡¶æ ‡¶õ‡ßã‡¶ü ‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ‡¶∞üë∂ ‡¶™‡¶∞‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡ßá ‡¶â‡¶†‡¶≤‡ßã‡•§\n",
        "\n",
        "‡¶è‡¶∞‡¶™‡¶∞, GPT2 ‡¶õ‡ßã‡¶ü ‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æüë∂ ‡¶•‡ßá‡¶ï‡ßá ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡¶ø‡¶ï ‡¶õ‡¶æ‡¶§‡ßç‡¶∞üßë-‡¶è‡¶∞ ‡¶¶‡¶ø‡¶ï‡ßá ‡¶™‡¶æ ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶¨‡ßá!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R52XY3hdxKUS"
      },
      "source": [
        "**Chapter 12: Trainer Class: Section 3: Training and Inference** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viJYZTXwxNhC"
      },
      "source": [
        "**Chapter 12: The Trainer Class** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1dLHoKgxQwm"
      },
      "source": [
        "**`nanoGPT`** <label><input type=\"checkbox\"> ‡¶∏‡¶Æ‡ßç‡¶™‡¶®‡ßç‡¶®</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykz9QCl8ubau"
      },
      "source": [
        "![„Çπ„ÇØ„É™„Éº„É≥„Ç∑„Éß„ÉÉ„Éà 2025-06-25 0.58.23.png](data:image/png;base64,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)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
