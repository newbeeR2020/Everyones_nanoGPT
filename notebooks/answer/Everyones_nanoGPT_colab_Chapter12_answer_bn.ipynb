{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj6PNj59iqJ8"
      },
      "source": [
        "# **Colab ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзАржжрзЗрж░ ржЬржирзНржп ржжрзНрж░рж╖рзНржЯржмрзНржп**\n",
        "\n",
        "# **ржПржЗ ржлрж╛ржЗрж▓рзЗ рж╕рж░рж╛рж╕рж░рж┐ рж▓рж┐ржЦржмрзЗржи ржирж╛тАФржЖржкржирж╛рж░ ржХрж╛ржЬ рж╣рж╛рж░рж┐ржпрж╝рзЗ ржпрзЗрждрзЗ ржкрж╛рж░рзЗ!**\n",
        "\n",
        "# **рж╢рзБрж░рзБ ржХрж░рж╛рж░ ржЖржЧрзЗ рж╕ржмрж╕ржоржпрж╝ ржПржХржЯрж┐ ржХржкрж┐ ржмрж╛ржирж╛ржиред**\n",
        "\n",
        "ржХржкрж┐ ржХрж┐ржнрж╛ржмрзЗ ржХрж░ржмрзЗржи\n",
        "\n",
        "1. ржЙржкрж░рзЗрж░ ржмрж╛ржо ржжрж┐ржХрзЗрж░ тАЬFileтАЭ-ржП ржХрзНрж▓рж┐ржХ ржХрж░рзБржиред  \n",
        "> *тАЬFileтАЭ ржмрж╛ \"Runtime\" ржорждрзЛ рж╣рзЗржбрж╛рж░ ржирж╛ ржжрзЗржЦрж▓рзЗ, ржЙржкрж░рзЗрж░ ржбрж╛ржи ржкрж╛рж╢рзЗ тАЬvтАЭ ржЪрж┐рж╣рзНржирзЗ ржХрзНрж▓рж┐ржХ ржХрж░рзЗ ржжрзЗржЦрзБржиред*\n",
        "\n",
        "2. \"Save a copy in Drive\" ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзБржиред\n",
        "\n",
        "3. ржХржкрж┐ржпрзБржХрзНржд ржлрж╛ржЗрж▓рзЗрж░ ржирж╛ржо ржкрж░рж┐ржмрж░рзНрждржи ржХрж░рзЗ ржжрж┐ржи тАЬYOURNAMEs_FileName.ipynbтАЭ рж╣рж┐рж╕рзЗржмрзЗред  \n",
        "> ржЙржжрж╛рж╣рж░ржг: ржЖржкржирж╛рж░ ржирж╛ржо ржпржжрж┐ Olivia рж╣ржпрж╝: Olivias_FileName.ipynb\n",
        "\n",
        "4. ржЖржкржирж╛рж░ runtime **CPU** рждрзЗ рж╕рзЗржЯ ржХрж░рзБржиред T4 GPU CPU ржПрж░ ржЪрзЗржпрж╝рзЗ ржЕржирзЗржХ ржмрзЗрж╢рж┐ рж╕рзЗрж╢ржи рж░рж┐рж╕рзЗржЯ ржХрж░рзЗред<br>  \n",
        "   рждрж╛ржЗ ржЯрзНрж░рзЗржирж┐ржВржпрж╝рзЗрж░ ржЬржирзНржп ржирж╛ рж▓рж╛ржЧрж▓рзЗ CPU runtime ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ржЗ ржнрж╛рж▓рзЛред<br>  \n",
        "   ржПржЗ [Video](https://youtu.be/XRmI-qRiFFw) ржжрзЗржЦрзБржиред<br>\n",
        "\n",
        "> ржпржжрж┐ ржорж╛ржЭржкржерзЗ runtime ржмржжрж▓рж╛ржи, рждрж╛рж╣рж▓рзЗ рж╢рзБрж░рзБ ржерзЗржХрзЗ рж╕ржм рж╕рзЗрж▓ ржЖржмрж╛рж░ ржЪрж╛рж▓рж╛рждрзЗ рж╣ржмрзЗред<br>  \n",
        "> рж╢рзБрж░рзБрждрзЗржЗ runtime ржарж┐ржХ ржХрж░рзЗ ржирж┐ржиред<br>  \n",
        "> *рж╕рзЗрж▓ ржЖржмрж╛рж░ ржЪрж╛рж▓рж╛ржирзЛрж░ ржЬржирзНржп: тАЬRuntimeтАЭ (ржЙржкрж░рзЗ ржмрж╛ржо) тЖТ тАЬRun beforeтАЭ ржХрзНрж▓рж┐ржХ ржХрж░рзБржиред*<br>\n",
        "\n",
        "---\n",
        "\n",
        "* ржЪрзЗржХ ржорж╛рж░рзНржХ (тЬЕ) рж╕ржВрж░ржХрзНрж╖ржг рж╣ржпрж╝ ржирж╛ред Chrome-ржПрж░ refresh ржмрж╛ржЯржирзЗ ржкрзЗржЬ рж░рж┐рж▓рзЛржб ржХрж░рж▓рзЗ рждрж╛рж░рж╛ ржЙржзрж╛ржУ рж╣ржпрж╝рзЗ ржпрж╛ржпрж╝ред<br>  \n",
        "  ржкрж░рзЗ ржЖржмрж╛рж░ ржЪрж╛рж▓рж┐ржпрж╝рзЗ ржпрзЗрждрзЗ ржЪрж╛ржЗрж▓рзЗ ржПржХржЯрж┐ ржЯрзЗржХрзНрж╕ржЯ рж╕рзЗрж▓ ржпрзЛржЧ ржХрж░рзЗ тАЬSO FAR DONEтАЭ рж▓рж┐ржЦрзЗ рж░рзЗржЦрзЗ ржжрж┐ржиред\n",
        "\n",
        "---\n",
        "\n",
        "* Colab-ржП **ржкрзНрж░рждрж┐ржЯрж┐ ржЖржЧрзЗрж░ ржЖржЙржЯржкрзБржЯ рзйрзж ржерзЗржХрзЗ рзпрзж ржорж┐ржирж┐ржЯрзЗ рж░рж┐рж╕рзЗржЯ рж╣ржпрж╝**ред<br>  \n",
        "  ржПржЬржирзНржп `~~ is not defined` ржзрж░ржирзЗрж░ ржнрзБрж▓ ржмрж╛рж░ ржмрж╛рж░ ржжрзЗржЦрж╛ ржжрзЗржпрж╝ред\n",
        "\n",
        "  ЁЯФБ `~~ is not defined` рждрзНрж░рзБржЯрж┐ ржкрзЗрж▓рзЗ ржХрж░ржгрзАржпрж╝  \n",
        "  1. ржкрзНрж░ржержорзЗ ржЖржкржирж╛рж░ ржнрзЗрж░рж┐ржпрж╝рзЗржмрж▓рзЗрж░ ржмрж╛ржирж╛ржи ржарж┐ржХ ржЖржЫрзЗ ржХрж┐ржирж╛ ржжрзЗржЦрзБржиред<br>  \n",
        "  2. ржмрж╛ржирж╛ржи ржарж┐ржХ рж╣рж▓рзЗржУ ржЕрж░рзНржерж╛рзО рж╕ржорж╕рзНржпрж╛ ржерж╛ржХрж▓рзЗ, **ржпрзЗ рж╕рзЗрж▓ржЯрж┐ ржЖржмрж╛рж░ ржЪрж╛рж▓рж╛рждрзЗ ржЪрж╛ржи рж╕рзЗржЯрж╛рждрзЗ ржХрзНрж▓рж┐ржХ ржХрж░рзБржи**ред<br>  \n",
        "  3. тАЬRuntimeтАЭ (ржЙржкрж░рзЗ ржмрж╛ржо) тЖТ тАЬRun beforeтАЭ ржХрзНрж▓рж┐ржХ ржХрж░рзБржиред<br>  \n",
        "     тЖТ ржПрждрзЗ **ржЖржЧрзЗрж░ рж╕ржм рж╕рзЗрж▓ ржЖржмрж╛рж░ ржЪрж╛рж▓рзБ рж╣ржмрзЗ**ред  \n",
        "  4. ржПржмрж╛рж░ рж╕рзЗрж▓ржЯрж┐ ржЖржмрж╛рж░ рж░рж╛ржи ржХрж░рзБржиред\n",
        "\n",
        "  рждржмрзБ рж╕ржорж╕рзНржпрж╛ ржерж╛ржХрж▓рзЗ, ржЖржЧрзЗрж░ рж╕рзЗрж▓ржЧрзБрж▓рзЛрждрзЗ ржЖржкржирж╛рж░ TODO ржЙрждрзНрждрж░ржЧрзБрж▓рзЛрждрзЗ ржнрзБрж▓ ржерж╛ржХрждрзЗ ржкрж╛рж░рзЗред<br>  \n",
        "  ржЙрждрзНрждрж░ржЧрзБрж▓рзЛ ржарж┐ржХ ржЖржЫрзЗ ржХрж┐ржирж╛ ржнрж╛рж▓рзЛ ржХрж░рзЗ ржжрзЗржЦрзБржиред<br>  \n",
        "  ржЕржержмрж╛ ChatGPT ржмрж╛ ржЕржирзНржп ржХрзЛржирзЛ ржХрзЛржбрж┐ржВ рж╕рж╣ржХрж╛рж░рзА ржерзЗржХрзЗ рж╕рж╛рж╣рж╛ржпрзНржп ржирж┐ржиред"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXZzMLzXiseX"
      },
      "source": [
        "# **Preparation**\n",
        "\n",
        "ржПржЗ ржЕржВрж╢рзЗ ржЖржЧрзЗ ржерзЗржХрзЗржЗ ржЕржзрзНржпрж╛ржпрж╝ржЧрзБрж▓рзЛрж░ ржЙржкрж╛ржжрж╛ржи рж▓рзЛржб ржХрж░рж╛ рж╣ржмрзЗред<br>\n",
        "ржХрзЛржб ржЪрж╛рж▓рж╛ржи, ржкржбрж╝рж╛рж░ ржжрж░ржХрж╛рж░ ржирзЗржЗред<br>\n",
        "ржЪрж┐ржирзНрждрж╛ ржЫрж╛ржбрж╝рж╛ рж╕рж╛ржоржирзЗ ржПржЧрж┐ржпрж╝рзЗ ржпрж╛ржиред<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s04g6yFiuHE",
        "outputId": "a62bb238-1185-4194-d97f-8cbdcdd1f733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-07-08 11:25:56--  https://raw.githubusercontent.com/HayatoHongo/nanoGPT_todo/main/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: тАШinput.txtтАЩ\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-07-08 11:25:56 (31.2 MB/s) - тАШinput.txtтАЩ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ржлрж╛ржЗрж▓ ржбрж╛ржЙржирж▓рзЛржб ржХрж░рзБржи\n",
        "!wget https://raw.githubusercontent.com/HayatoHongo/Everyones_nanoGPT/main/input.txt -O input.txt\n",
        "# ржЖржкржирж┐ ржпрзЗ input.text ржлрж╛ржЗрж▓ржЯрж┐ ржбрж╛ржЙржирж▓рзЛржб ржХрж░рзЗржЫрзЗржи рждрж╛ utf-8 ржлрж░ржорзНржпрж╛ржЯрзЗ рж▓рзЛржб ржХрж░рзБржиред\n",
        "with open(\"input.txt\", 'r', encoding = 'utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# ржЯрзЗржирж╕рж░ рж╕рзБржирзНржжрж░ржнрж╛ржмрзЗ ржкрзНрж░ржжрж░рзНрж╢ржирзЗрж░ ржЬржирзНржп ржПржХржЯрж┐ ржлрж╛ржВрж╢ржи (ржкржбрж╝рждрзЗ ржирж╛ ржЪрж╛ржЗрж▓рзЗ ржмрж╛ржж ржжрж┐рждрзЗ ржкрж╛рж░рзЗржи)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def print_formatted_tensor(*args, width=6, decimals=2):\n",
        "    \"\"\"\n",
        "    A function that neatly formats and displays a PyTorch Tensor, and also prints its size.\n",
        "\n",
        "    Example usage:\n",
        "        print_formatted_tensor(\"name\", tensor)\n",
        "        print_formatted_tensor(tensor)\n",
        "\n",
        "    Args:\n",
        "        *args: If given 1 argument, it is treated as a tensor.\n",
        "               If given 2 arguments, the first is treated as the name, the second as the tensor.\n",
        "        width (int): Display width for each number (default: 6)\n",
        "        decimals (int): Number of decimal places to show (default: 2)\n",
        "    \"\"\"\n",
        "\n",
        "    # Determine tensor and name from arguments\n",
        "    if not args:\n",
        "        raise ValueError(\"At least one argument is required.\")\n",
        "    if isinstance(args[0], str):\n",
        "        if len(args) < 2:\n",
        "            raise ValueError(\"Tensor is not specified.\")\n",
        "        name, tensor = args[0], args[1]\n",
        "    else:\n",
        "        name, tensor = None, args[0]\n",
        "\n",
        "    # Convert Tensor to List\n",
        "    tensor_list = tensor.detach().cpu().tolist()\n",
        "\n",
        "    def format_list(lst, indent):\n",
        "        \"\"\"Formatting a recursively nested list and returning a string\"\"\"\n",
        "        # If the contents are lists, then re-return\n",
        "        if isinstance(lst, list) and lst and isinstance(lst[0], list):\n",
        "            inner = \",\\n\".join(\" \" * indent + format_list(sub, indent + 2) for sub in lst)\n",
        "            return \"[\\n\" + inner + \"\\n\" + \" \" * (indent - 2) + \"]\"\n",
        "        # For numerical lists\n",
        "        return \"[\" + \", \".join(f\"{v:{width}.{decimals}f}\" for v in lst) + \"]\"\n",
        "\n",
        "    # Formatted string (bar brackets on outermost frames are removed)\n",
        "    formatted = format_list(tensor_list, indent=9)\n",
        "    inner_formatted = formatted[1:-1].strip()\n",
        "\n",
        "    # Result output\n",
        "    if name:\n",
        "        print(name)\n",
        "    print(f\"Tensor Size: {list(tensor.size())}\")\n",
        "    print(\"tensor([\")\n",
        "    print(\" \" * 9 + inner_formatted)\n",
        "    print(\" \" * 7 + \"])\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh_2Ls8tn2rk"
      },
      "source": [
        "# Chapter 12 Trainer Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEl9A_wk33Pa"
      },
      "source": [
        "### Section 1: Class Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnILkem04RSW"
      },
      "source": [
        "ЁЯФШ **Options**: ржерж╛ржХрждрзЗ ржкрж╛рж░рзЗ ржЖржкржирж╛рж░ ржжрж░ржХрж╛рж░рзЗрж░ ржмрж╛ржЗрж░рзЗ ржЕрждрж┐рж░рж┐ржХрзНржд ржЕржкрж╢ржиред  \n",
        "\n",
        "`self.model`уАА`self.optimizer`уАА`self.data_loader`уАА`self.config`уАА`split_data`уАА`get_batch`уАА`'train'`, `'val'`уАА`input_batch`уАА`target_batch`уАА`logits`уАА`self.config.total_training_steps`уАА`self.config.evaluation_loops`  \n",
        "`loss`уАА`backward()`уАА`self.train_step()`уАА`self.evaluate()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRi90bRasayV"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, data_loader, config):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.data_loader = data_loader\n",
        "        self.config = config\n",
        "\n",
        "    def train_step(self):\n",
        "        # ржкрзНрж░рж╢рж┐ржХрзНрж╖ржгрзЗрж░ ржЬржирзНржп ржПржХржЯрж┐ ржмрзНржпрж╛ржЪ ржирж┐ржиред\n",
        "        input_batch, target_batch = self.data_loader.get_batch('train')\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # ржоржбрзЗрж▓рзЗрж░ ржлрж░ржУржпрж╝рж╛рж░рзНржб ржкрж╛рж╕ ржПржмржВ рж▓рж╕ рж╣рж┐рж╕рж╛ржм\n",
        "        logits, loss = self.model(input_batch, target_batch)\n",
        "        loss.backward()  # ржмрзНржпрж╛ржХржкрзНрж░рзЛржкрж╛ржЧрзЗрж╢ржи (рждрзНрж░рзБржЯрж┐ ржмрзНржпрж╛ржХржкрзНрж░рзЛржкрж╛ржЧрзЗрж╢ржи)\n",
        "        self.optimizer.step()  # ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░ ржЖржкржбрзЗржЯ ржХрж░рзБржи\n",
        "\n",
        "        return loss.item() # рж╣рж╛рж░рж╛ржирзЗрж░ ржорж╛ржи ржлрзЗрж░ржд ржжрзЗржпрж╝\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()  # ржорзВрж▓рзНржпрж╛рзЯржи ржорзЛржбрзЗ рж╕рзЗржЯ ржХрж░рзБржи\n",
        "        losses = {\"train\": [], \"val\": []} # ржкрзНрж░рж╢рж┐ржХрзНрж╖ржг ржУ ржпрж╛ржЪрж╛ржЗржХрж░ржг рждржерзНржпрзЗрж░ ржЙржкрж░ ржХрзНрж╖рждрж┐ ржЧржгржирж╛ ржХрж░рзБржи\n",
        "        with torch.no_grad():\n",
        "            for split in ['train', 'val']:\n",
        "                for _ in range(self.config.evaluation_loops):\n",
        "                    input_batch, target_batch = self.data_loader.get_batch(split)\n",
        "                    _, loss = self.model(input_batch, target_batch)\n",
        "                    losses[split].append(loss.item())\n",
        "        self.model.train()  # ржкрзНрж░рж╢рж┐ржХрзНрж╖ржг ржорзЛржбрзЗ ржлрж┐рж░рзЗ ржпрж╛ржи\n",
        "\n",
        "        # ржкрзНрж░рждрж┐ржЯрж┐ рж╕рзНржкрзНрж▓рж┐ржЯрзЗрж░ (train, val) ржЧржбрж╝ ржХрзНрж╖рждрж┐ рж╣рж┐рж╕рж╛ржм ржХрж░рзБржи\n",
        "        return {split: sum(values) / len(values) for split, values in losses.items()}\n",
        "\n",
        "    def train(self):\n",
        "        # config ржП ржирж┐рж░рзНржзрж╛рж░рж┐ржд рж╕ржВржЦрзНржпржХ ржмрж╛рж░ train_step ржЪрж╛рж▓рж╛ржиред\n",
        "        for step in range(self.config.total_training_steps):\n",
        "\n",
        "            # ржкрзНрж░рждрж┐ рззрзжрзж ржЗржЯрж╛рж░рзЗрж╢ржирзЗ ржЕржержмрж╛ рж╢рзБржзрзБ рж╢рзЗрж╖ ржзрж╛ржкрзЗ ржорзВрж▓рзНржпрж╛ржпрж╝ржи ржХрж░рзБржиред\n",
        "            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\n",
        "                eval_loss = self.evaluate()\n",
        "                print(f\"Step {step}: Train Loss {eval_loss['train']:.4f}, Validation Loss {eval_loss['val']:.4f}\")\n",
        "\n",
        "            # ржкрзНрж░рж╢рж┐ржХрзНрж╖ржгрзЗрж░ ржПржХржЯрж┐ ржзрж╛ржк (ржкрзНрж░рждрж┐ржмрж╛рж░ ржЖржкржирж┐ ржпрзЗ ржорзВрж▓ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржЯрж┐ ржХрж░рзЗржи)\n",
        "            train_loss = self.train_step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "mi8-y1ak4VOS",
        "outputId": "ec0f1c70-6f55-4cf2-fb9f-e5b56297691b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nclass Trainer:\\n    def __init__(self, model, optimizer, data_loader, config):\\n        self.model = model\\n        self.optimizer = optimizer\\n        self.data_loader = data_loader\\n        self.config = config\\n\\n    def train_step(self):\\n        # Get a batch for training.\\n        input_batch, target_batch = ___________._______(_____)\\n        self.optimizer.zero_grad()\\n\\n        # Model forward pass and loss calculation\\n        logits, loss = _______(_________, __________)\\n        _____.__________  # Backpropagation (Error backpropagation)\\n        self.optimizer.step()  # Update parameters\\n\\n        return loss.item() # Returns the value of the loss\\n\\n    def evaluate(self):\\n        self.model.eval()  # Set to evaluation mode\\n        losses = {\"train\": [], \"val\": []} # Calculate losses on both training and validation data\\n        with torch.no_grad():\\n            for split in [\\'train\\', \\'val\\']:\\n                for _ in range(self.config.evaluation_loops):\\n                    input_batch, target_batch = self.data_loader.get_batch(split)\\n                    _, loss = self.model(input_batch, target_batch)\\n                    losses[split].append(loss.item())\\n        self.model.train()  # Return to training mode\\n\\n        # Calculate the average losses for each split (train, val)\\n        return {split: sum(values) / len(values) for split, values in losses.items()}\\n\\n    def train(self):\\n        # Run train_step the number of times specified in config.\\n        for step in range(_________________________):\\n\\n            # Evaluate every 100 iterations or just at the final step.\\n            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\\n                eval_loss = self.evaluate()\\n                print(f\"Step {step}: Train Loss {eval_loss[\\'train\\']:.4f}, Validation Loss {eval_loss[\\'val\\']:.4f}\")\\n\\n            # One step of training (the main process that you do every time)\\n            train_loss = _____________\\n'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, data_loader, config):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.data_loader = data_loader\n",
        "        self.config = config\n",
        "\n",
        "    def train_step(self):\n",
        "        # ржЯрзНрж░рзЗржирж┐ржВржпрж╝рзЗрж░ ржЬржирзНржп ржПржХржЯрж┐ ржмрзНржпрж╛ржЪ ржирж┐ржиред\n",
        "        input_batch, target_batch = ___________._______(_____)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # ржоржбрзЗрж▓ ржлрж░рзЛржпрж╝рж╛рж░рзНржб ржкрж╛рж╕ ржПржмржВ рж▓рж╕ рж╣рж┐рж╕рж╛ржм\n",
        "        logits, loss = _______(_________, __________)\n",
        "        _____.__________  # ржмрзНржпрж╛ржХржкрзНрж░ржкрж╛ржЧрзЗрж╢ржи (рждрзНрж░рзБржЯрж┐ ржмрзНржпрж╛ржХржкрзНрж░ржкрж╛ржЧрзЗрж╢ржи)\n",
        "        self.optimizer.step()  # ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░ ржЖржкржбрзЗржЯ ржХрж░рзБржи\n",
        "\n",
        "        return loss.item() # рж▓рж╕рзЗрж░ ржорж╛ржи ржлрзЗрж░ржд ржжрзЗржпрж╝\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()  # ржорзВрж▓рзНржпрж╛рзЯржи ржорзЛржбрзЗ рж╕рзЗржЯ ржХрж░рзБржи\n",
        "        losses = {\"train\": [], \"val\": []} # ржкрзНрж░рж╢рж┐ржХрзНрж╖ржг ржУ ржпрж╛ржЪрж╛ржЗржХрж░ржг ржбрзЗржЯрж╛ржпрж╝ ржХрзНрж╖рждрж┐ рж╣рж┐рж╕рж╛ржм ржХрж░рзБржи\n",
        "        with torch.no_grad():\n",
        "            for split in ['train', 'val']:\n",
        "                for _ in range(self.config.evaluation_loops):\n",
        "                    input_batch, target_batch = self.data_loader.get_batch(split)\n",
        "                    _, loss = self.model(input_batch, target_batch)\n",
        "                    losses[split].append(loss.item())\n",
        "        self.model.train()  # ржкрзНрж░рж╢рж┐ржХрзНрж╖ржг ржорзЛржбрзЗ ржлрж┐рж░рзБржи\n",
        "\n",
        "        # ржкрзНрж░рждрж┐ржЯрж┐ рж╕рзНржкрзНрж▓рж┐ржЯрзЗрж░ (train, val) ржЧржбрж╝ ржХрзНрж╖рждрж┐ рж╣рж┐рж╕рж╛ржм ржХрж░рзБржи\n",
        "        return {split: sum(values) / len(values) for split, values in losses.items()}\n",
        "\n",
        "    def train(self):\n",
        "        # config-ржП ржирж┐рж░рзНржжрж┐рж╖рзНржЯ рж╕ржВржЦрзНржпржХ train_step ржЪрж╛рж▓рж╛ржиред\n",
        "        for step in range(_________________________):\n",
        "\n",
        "            # ржкрзНрж░рждрж┐ рззрзжрзж ржЗржЯрж╛рж░рзЗрж╢ржирзЗ ржмрж╛ рж╢рзБржзрзБржорж╛рждрзНрж░ рж╢рзЗрж╖ ржзрж╛ржкрзЗ ржорзВрж▓рзНржпрж╛ржпрж╝ржи ржХрж░рзБржиред\n",
        "            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\n",
        "                eval_loss = self.evaluate()\n",
        "                print(f\"Step {step}: Train Loss {eval_loss['train']:.4f}, Validation Loss {eval_loss['val']:.4f}\")\n",
        "\n",
        "            # ржкрзНрж░рж╢рж┐ржХрзНрж╖ржгрзЗрж░ ржПржХржЯрж┐ ржзрж╛ржк (ржкрзНрж░рждрж┐ржмрж╛рж░ ржпрзЗ ржорзВрж▓ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржЯрж┐ ржХрж░рзЗржи)\n",
        "            train_loss = _____________\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KUW7ceEA4ek"
      },
      "source": [
        "<details>\n",
        "<summary>ржЙрждрзНрждрж░ ржжрзЗржЦрж╛рждрзЗ/рж▓рзБржХрж╛рждрзЗ ржПржЦрж╛ржирзЗ ржХрзНрж▓рж┐ржХ ржХрж░рзБржи</summary>\n",
        "\n",
        "```python\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, data_loader, config):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.data_loader = data_loader\n",
        "        self.config = config\n",
        "\n",
        "    def train_step(self):\n",
        "        # ржЯрзНрж░рзЗржирж┐ржВржпрж╝рзЗрж░ ржЬржирзНржп ржПржХржЯрж┐ ржмрзНржпрж╛ржЪ ржирж┐ржиред\n",
        "        input_batch, target_batch = self.data_loader.get_batch('train')\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # ржоржбрзЗрж▓рзЗрж░ ржлрж░рзЛржпрж╝рж╛рж░рзНржб ржкрж╛рж╕ ржПржмржВ рж▓рж╕ рж╣рж┐рж╕рж╛ржм\n",
        "        logits, loss = self.model(input_batch, target_batch)\n",
        "        loss.backward()  # ржмрзНржпрж╛ржХржкрзНрж░рзЛржкрж╛ржЧрзЗрж╢ржи (рждрзНрж░рзБржЯрж┐ ржлрж┐рж░рзЗ ржпрж╛ржУржпрж╝рж╛)\n",
        "        self.optimizer.step()  # ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░ ржЖржкржбрзЗржЯ\n",
        "\n",
        "        return loss.item() # рж▓рж╕ ржПрж░ ржорж╛ржи рж░рж┐ржЯрж╛рж░рзНржи ржХрж░рзЗ\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()  # ржорзВрж▓рзНржпрж╛ржпрж╝ржи ржорзЛржбрзЗ рж╕рзЗржЯ ржХрж░рзБржи\n",
        "        losses = {\"train\": [], \"val\": []} # ржЯрзНрж░рзЗржирж┐ржВ ржУ ржнрзНржпрж╛рж▓рж┐ржбрзЗрж╢ржи ржЙржнржпрж╝ ржбрзЗржЯрж╛ржпрж╝ рж▓рж╕ рж╣рж┐рж╕рж╛ржм ржХрж░рзБржи\n",
        "        with torch.no_grad():\n",
        "            for split in ['train', 'val']:\n",
        "                for _ in range(self.config.evaluation_loops):\n",
        "                    input_batch, target_batch = self.data_loader.get_batch(split)\n",
        "                    _, loss = self.model(input_batch, target_batch)\n",
        "                    losses[split].append(loss.item())\n",
        "        self.model.train()  # ржЖржмрж╛рж░ ржЯрзНрж░рзЗржирж┐ржВ ржорзЛржбрзЗ ржлрж┐рж░рзБржи\n",
        "\n",
        "        # ржкрзНрж░рждрж┐ржЯрж┐ ржнрж╛ржЧрзЗрж░ ржЧржбрж╝ рж▓рж╕ рж╣рж┐рж╕рж╛ржм ржХрж░рзБржи (train, val)\n",
        "        return {split: sum(values) / len(values) for split, values in losses.items()}\n",
        "\n",
        "    def train(self):\n",
        "        # config-ржП ржжрзЗржпрж╝рж╛ рж╕ржВржЦрзНржпрж╛рж░ ржоржд train_step ржЪрж╛рж▓рж╛ржиред\n",
        "        for step in range(self.config.total_training_steps):\n",
        "\n",
        "            # ржкрзНрж░рждрж┐ рззрзжрзж ржзрж╛ржк ржкрж░ ржкрж░ ржмрж╛ рж╢рзЗрж╖ ржзрж╛ржкрзЗ ржорзВрж▓рзНржпрж╛ржпрж╝ржи ржХрж░рзБржиред\n",
        "            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\n",
        "                eval_loss = self.evaluate()\n",
        "                print(f\"Step {step}: Train Loss {eval_loss['train']:.4f}, Validation Loss {eval_loss['val']:.4f}\")\n",
        "\n",
        "            # ржЯрзНрж░рзЗржирж┐ржВржпрж╝рзЗрж░ ржПржХржЯрж┐ ржзрж╛ржк (ржкрзНрж░рждрж┐ ржмрж╛рж░ ржпрж╛ ржХрж░ржмрзЗржи)\n",
        "            train_loss = self.train_step()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPN1h-k_xejG"
      },
      "source": [
        "**Chapter 11: Trainer Class: Section 1: Class Definition** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU53fOfBPA_s"
      },
      "source": [
        "### Section 2: Class Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NcZr_SN-Ufm"
      },
      "source": [
        "Chapter 1 ржерзЗржХрзЗ Chapter 11 ржкрж░рзНржпржирзНржд рж╕ржм ржХрзНрж▓рж╛рж╕ ржкрзЗрж╕рзНржЯ ржХрж░рзБржиред<br>\n",
        "**DeterministicDropout ржХрзЗ nn.Dropout ржжрж┐рзЯрзЗ рж░рж┐ржкрзНрж▓рзЗрж╕ ржХрж░рзБржиред**\n",
        "\n",
        "[Watch the video!](https://youtu.be/j2ErzvlslKA)  \n",
        "- ржХрзЛржирзЛ ржЕржбрж┐ржУ ржирзЗржЗ  \n",
        "- рзк ржорж┐ржирж┐ржЯ  \n",
        "\n",
        "ржнрж┐ржбрж┐ржУржЯрж┐рждрзЗ ржлрж╛ржЗрж▓рзЗрж░ ржирж╛ржо answer_colab, ржХрж┐ржирзНрждрзБ рж╕рзЗржЯрж╛ ржорж╛ржерж╛ржпрж╝ рж░рж╛ржЦржмрзЗржи ржирж╛ред  \n",
        "\n",
        "```python\n",
        "AttentionHead: dropout = nn.Dropout(config.dropout_rate)\n",
        "MultiHeadAttention: dropout = nn.Dropout(config.dropout_rate)\n",
        "FeedForward:  nn.Dropout(config.dropout_rate)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnLnj31rPTLC"
      },
      "outputs": [],
      "source": [
        "class DataLoader:\n",
        "    def __init__(self, text, config):\n",
        "        self.config = config  # ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи ржЕржмржЬрзЗржХрзНржЯ\n",
        "        chars = sorted(list(set(text)))  # ржЕржиржирзНржп ржЕржХрзНрж╖рж░ рж╕рж╛ржЬрж╛ржирзЛ рж╣ржЪрзНржЫрзЗ\n",
        "        self.ctoi = {char: index for index, char in enumerate(chars)}\n",
        "        self.itoc = {index: char for index, char in enumerate(chars)}\n",
        "        self.vocab_size = len(chars)\n",
        "\n",
        "        # ржПржиржХрзЛржб ржХрж░рзБржи ржПржмржВ ржЯрзЗржирж╕рж░рзЗ рж░рзВржкрж╛ржирзНрждрж░ ржХрж░рзБржиред\n",
        "        # ржПржЗ `__init__` ржорзЗржержбрзЗрж░ ржмрж╛ржЗрж░рзЗ ржЕржирзНржп ржорзЗржержб ржмрж╛ ржЖрж░рзНржЧрзБржорзЗржирзНржЯ ржХрж▓ ржХрж░рждрзЗ `self.` ржкрзНрж░ржпрж╝рзЛржЬржиред\n",
        "        self.data = torch.tensor(self.encode(text), dtype=torch.long)\n",
        "\n",
        "        # ржкрзНрж░рж╢рж┐ржХрзНрж╖ржг/ржпрж╛ржЪрж╛ржЗржХрж░ржг ржбрзЗржЯрж╛ржпрж╝ ржнрж╛ржЧ ржХрж░рзБржиред\n",
        "        # `self.data` ржбрж┐ржлрж▓рзНржЯ рж╣рж┐рж╕рзЗржмрзЗ ржмрзНржпржмрж╣рзГржд рж╣ржпрж╝ ржпржжрж┐ ржХрзЛржирзЛ ржЖрж░рзНржЧрзБржорзЗржирзНржЯ ржирж╛ ржжрзЗржУржпрж╝рж╛ рж╣ржпрж╝ред\n",
        "        self.train_data, self.val_data = self.split_data()\n",
        "\n",
        "    def encode(self, text):\n",
        "        # ржПржХржЯрж┐ рж╕рзНржЯрзНрж░рж┐ржВржХрзЗ ржЗржиржбрзЗржХрзНрж╕ ржХрж▓рж╛ржорзЗ рж░рзВржкрж╛ржирзНрждрж░ ржХрж░рзЗред ржЕржирзНржпрж╛ржирзНржп ржорзЗржержб ржмрж╛ ржЖрж░рзНржЧрзБржорзЗржирзНржЯ ржХрж▓ ржХрж░рждрзЗ `self.` ржкрзНрж░ржпрж╝рзЛржЬржиред\n",
        "        return [self.ctoi[c] for c in text]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        return ''.join([self.itoc[i] for i in indices])\n",
        "\n",
        "    def split_data(self):\n",
        "        split_index = int(0.9 * len(self.data))  # 90% ржбрзЗржЯрж╛ ржЯрзНрж░рзЗржирж┐ржВржпрж╝рзЗрж░ ржЬржирзНржп ржнрж╛ржЧ ржХрж░рж╛рж░ ржкржпрж╝рзЗржирзНржЯред\n",
        "        return self.data[:split_index], self.data[split_index:]\n",
        "\n",
        "    def get_batch(self, split):\n",
        "        data = self.train_data if split == 'train' else self.val_data\n",
        "        start_indices = torch.randint(len(data) - self.config.input_sequence_length, (self.config.batch_size,)) # ржЙрзОржкржирзНржи ржХрж░рзБржи ржПржХрзНрж╕ржЯрзНрж░рзНржпрж╛ржХрзНржЯ рж╢рзБрж░рзБ рж╕рзВржЪржХ\n",
        "\n",
        "        input_sequences = torch.stack([\n",
        "            data[start_index:start_index + self.config.input_sequence_length]\n",
        "            for start_index in start_indices\n",
        "        ])\n",
        "        target_sequences = torch.stack([\n",
        "            data[start_index + 1:start_index + self.config.input_sequence_length + 1]\n",
        "            for start_index in start_indices\n",
        "        ])\n",
        "        return input_sequences.to(self.config.device_type), target_sequences.to(self.config.device_type)\n",
        "\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        # vocabulary ржиржорзНржмрж░ x embedding ржорж╛рждрзНрж░рж╛рж░ ржЬржирзНржп ржПржХржЯрж┐ ржПржоржмрзЗржбрзЗржб ржЯрзЗржмрж┐рж▓ рж╕ржВржЬрзНржЮрж╛ржпрж╝рж┐ржд ржХрж░рзБржи\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def embed(self, input_indices):\n",
        "        # ржЗржиржкрзБржЯ ржЗржиржбрзЗржХрзНрж╕рзЗрж░ рж╕рж╛ржерзЗ рж╕ржорзНржкрж░рзНржХрж┐ржд ржПржоржмрзЗржбрзЗржб ржнрзЗржХрзНржЯрж░ ржкрж╛ржи\n",
        "        return self.token_embedding_table.forward(input_indices)\n",
        "\n",
        "class PositionEmbedding(nn.Module):\n",
        "    def __init__(self, input_sequence_length = 8, embedding_dim = 8):\n",
        "        super().__init__()\n",
        "        # ржЕржмрж╕рзНржерж╛ржи ржПржоржмрзЗржбрж┐ржВ рж╕рзНрждрж░\n",
        "        self.position_embedding_layer = nn.Embedding(input_sequence_length, embedding_dim)\n",
        "\n",
        "    def forward(self, input_indices):\n",
        "        # ржЗржиржкрзБржЯ ржЯрзЗржирж╕рж░ input_indices ржПрж░ ржЖржХрзГрждрж┐: [ржмрзНржпрж╛ржЪ рж╕рж╛ржЗржЬ, рж╕рж┐ржХрзЛржпрж╝рзЗржирзНрж╕ ржжрзИрж░рзНржШрзНржп].\n",
        "        sequence_length = input_indices.shape[1]\n",
        "\n",
        "        # ржХрзНрж░ржорзЗрж░ ржжрзИрж░рзНржШрзНржп ржЕржирзБржпрж╛ржпрж╝рзА ржЕржмрж╕рзНржерж╛ржи рж╕рзВржЪржХ рждрзИрж░рж┐ ржХрж░рзБржи (ржпрзЗржоржи [0, 1, 2, ..., sequence_length-1])\n",
        "        position_indices = torch.arange(sequence_length, device=input_indices.device)\n",
        "\n",
        "        # ржЕржмрж╕рзНржерж╛ржи рж╕рзВржЪржХрзЗрж░ ржЬржирзНржп ржПржорзНржмрзЗржбрзЗржб ржнрзЗржХрзНржЯрж░ ржирж┐ржи\n",
        "        position_embeddings = self.position_embedding_layer.forward(position_indices)\n",
        "\n",
        "        return position_embeddings\n",
        "\n",
        "class EmbeddingModule(nn.Module):\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        # ржкрзНрж░рждрж┐ржЯрж┐ ржЯрзЛржХрзЗржирзЗрж░ ржЬржирзНржп ржПржоржмрзЗржбрзЗржб рж▓рзЗржпрж╝рж╛рж░\n",
        "        self.token_embedding_layer = TokenEmbedding(vocab_size = vocab_size, embedding_dim = config.embedding_dim)  # рж╢ржмрзНржж ржПржорзНржмрзЗржбрж┐ржВ рж╕рзНрждрж░\n",
        "        self.position_embedding_layer = PositionEmbedding(input_sequence_length = config.input_sequence_length, embedding_dim = config.embedding_dim)  # ржЕржмрж╕рзНржерж╛ржи рждржерзНржп ржПржорзНржмрзЗржб ржХрж░рзБржи\n",
        "\n",
        "    def forward(self, input_indices):\n",
        "        # ржЯрзЛржХрзЗржи ржПржоржмрзЗржбрж┐ржВ ржирж┐ржи\n",
        "        token_embeddings = self.token_embedding_layer.embed(input_indices)\n",
        "\n",
        "        # ржЕржмрж╕рзНржерж╛ржи ржПржоржмрзЗржбрж┐ржВ ржирж┐ржи\n",
        "        position_embeddings = self.position_embedding_layer.forward(input_indices)\n",
        "\n",
        "        # ржЯрзЛржХрзЗржи ржПржоржмрзЗржбрж┐ржВ ржПржмржВ ржЕржмрж╕рзНржерж╛ржи ржПржоржмрзЗржбрж┐ржВ ржпрзЛржЧ ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ\n",
        "        embeddings = position_embeddings + token_embeddings\n",
        "        return embeddings\n",
        "\n",
        "class LayerNorm(nn.Module):  # ржПржЦрж╛ржирзЗ nn.Module ржерзЗржХрзЗ ржЙрждрзНрждрж░рж╛ржзрж┐ржХрж╛рж░ ржЧрзНрж░рж╣ржг ржХрж░рзБржи\n",
        "    def __init__(self, token_length, eps=1e-5, norm_dim=-1):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.norm_dim = norm_dim\n",
        "\n",
        "        # gamma ржУ beta ржХрзЗ nn.Parameter рж╣рж┐рж╕рзЗржмрзЗ ржирж┐ржмржирзНржзржи ржХрж░рзБржи ржпрж╛рждрзЗ CPU ржУ CUDA ржЙржнржпрж╝рзЗржЗ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ ржпрж╛ржпрж╝ред\n",
        "        self.gamma = nn.Parameter(torch.ones(token_length))\n",
        "        self.beta = nn.Parameter(torch.zeros(token_length))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=self.norm_dim, keepdim=True)\n",
        "        var = torch.var(x, dim=self.norm_dim, keepdim=True, unbiased=False)\n",
        "        hat = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        output =  self.gamma * hat + self.beta\n",
        "        return output\n",
        "\n",
        "\n",
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, head_size, config):\n",
        "        super().__init__()\n",
        "        self.key_fc= nn.Linear(config.embedding_dim, head_size, bias=False)\n",
        "        self.query_fc = nn.Linear(config.embedding_dim, head_size, bias=False)\n",
        "        self.value_fc = nn.Linear(config.embedding_dim, head_size, bias=False)\n",
        "\n",
        "        # ржорж╛рж╕рзНржХ ржирж┐ржЪрзБ рждрзНрж░рж┐ржнрзБржЬрж╛ржХрзГрждрж┐рж░ ржорзНржпрж╛ржЯрзНрж░рж┐ржХрзНрж╕ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ рждрзИрж░рж┐ ржХрж░рж╛ рж╣ржпрж╝ (self-attention-ржПрж░ ржХрж╛рж░ржгрж┐ржХрждрж╛ ржмржЬрж╛ржпрж╝ рж░рзЗржЦрзЗ)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.input_sequence_length, config.input_sequence_length)))\n",
        "\n",
        "        # ржбрзНрж░ржкржЖржЙржЯ (ржирж┐рж░рзНржзрж╛рж░рж┐ржд рж╕ржВрж╕рзНржХрж░ржг ржЖрж▓рж╛ржжрж╛ржнрж╛ржмрзЗ рж╕ржВржЬрзНржЮрж╛ржпрж╝рж┐ржд)\n",
        "        self.dropout = nn.Dropout(config.dropout_rate)\n",
        "\n",
        "        self.head_size = head_size\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        B, T, C = input_tensor.shape  # ржмрзНржпрж╛ржЪ, ржЯрзЛржХрзЗржи ржжрзИрж░рзНржШрзНржп, ржПржорзНржмрзЗржбрж┐ржВ ржЪрзНржпрж╛ржирзЗрж▓\n",
        "\n",
        "        Key = self.key_fc.forward(input_tensor)     # (ржмрж┐, ржЯрж┐, рж╣рзЗржб_рж╕рж╛ржЗржЬ)\n",
        "        Query = self.query_fc.forward(input_tensor)   # (ржмрж┐, ржЯрж┐, рж╣рзЗржб_рж╕рж╛ржЗржЬ)\n",
        "        Value = self.value_fc.forward(input_tensor)   # (ржмрж┐, ржЯрж┐, рж╣рзЗржб_рж╕рж╛ржЗржЬ)\n",
        "\n",
        "        # ржЕрзНржпрж╛ржЯрзЗржирж╢ржи рж╕рзНржХрзЛрж░ ржЧржгржирж╛ ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ (QK^T) / sqrt(embedding_dim)\n",
        "        attention_weights_before_mask = Query @ Key.transpose(-2, -1) * self.head_size**(-0.5)\n",
        "\n",
        "        # ржорж╛рж╕рзНржХ ржкрзНрж░ржпрж╝рзЛржЧ рж╣ржпрж╝рзЗржЫрзЗ\n",
        "        mask = torch.triu(torch.ones(T, T), diagonal=1).to(input_tensor.device)\n",
        "        masked_attention_weights = attention_weights_before_mask.masked_fill(mask == 1, float('-inf'))\n",
        "\n",
        "        # рж╕ржлржЯржорзНржпрж╛ржХрзНрж╕ тЖТ ржбрзНрж░ржкржЖржЙржЯ тЖТ ржУржЬржиржпрзБржХрзНржд ржпрзЛржЧржлрж▓\n",
        "        attention_weights = F.softmax(masked_attention_weights, dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "\n",
        "        out = attention_weights @ Value  # (ржмрж┐, ржЯрж┐, рж╣рзЗржб_рж╕рж╛ржЗржЬ)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.embedding_dim = config.embedding_dim\n",
        "        self.head_size = int(self.embedding_dim / self.num_attention_heads)\n",
        "\n",
        "        # ModuleList ржжрж┐ржпрж╝рзЗ ржПржХрж╛ржзрж┐ржХ рж╣рзЗржб ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржХрж░рзБржи\n",
        "        self.attention_heads = nn.ModuleList([\n",
        "            AttentionHead(self.head_size, config)\n",
        "            for _ in range(self.num_attention_heads)\n",
        "        ])\n",
        "\n",
        "        # ржкрзНрж░рждрж┐ржЯрж┐ рж╣рзЗржбрзЗрж░ ржЖржЙржЯржкрзБржЯ ржорж┐рж╢рзНрж░ржгрзЗрж░ ржЬржирзНржп рж▓рж┐ржирж┐ржпрж╝рж╛рж░ рж▓рзЗржпрж╝рж╛рж░\n",
        "        self.output_projection = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
        "\n",
        "        # ржЖржЙржЯржкрзБржЯрзЗрж░ ржЬржирзНржп ржбрзНрж░ржкржЖржЙржЯ\n",
        "        self.dropout = nn.Dropout(config.dropout_rate)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        # ржкрзНрж░рждрзНржпрзЗржХ рж╣рзЗржб ржерзЗржХрзЗ ржЖржЙржЯржкрзБржЯ ржирж┐ржи\n",
        "        # (B, T, head_size) ржПрж░ рждрж╛рж▓рж┐ржХрж╛\n",
        "        head_outputs_list = [head.forward(input_tensor) for head in self.attention_heads]\n",
        "\n",
        "        # рж╕ржм рж╣рзЗржбрзЗрж░ ржЖржЙржЯржкрзБржЯ ржПржХрждрзНрж░рж┐ржд ржХрж░рзБржи тЖТ (B, T, embedding_dim)\n",
        "        concatenated = torch.cat(head_outputs_list, dim=-1)\n",
        "\n",
        "        # ржЖржЙржЯржкрзБржЯржХрзЗ рж▓рж┐ржирж┐ржпрж╝рж╛рж░ ржЯрзНрж░рж╛ржирзНрж╕ржлрж░ржорзЗрж╢ржирзЗрж░ рж╕рж╛ржерзЗ ржорзЗрж╢рж╛ржирзЛ\n",
        "        projected = self.output_projection.forward(concatenated)\n",
        "\n",
        "        # ржЪрзВржбрж╝рж╛ржирзНржд ржЖржЙржЯржкрзБржЯрзЗ ржбрзНрж░ржкржЖржЙржЯ ржкрзНрж░ржпрж╝рзЛржЧ ржХрж░рзБржи\n",
        "        output = self.dropout.forward(projected)\n",
        "\n",
        "        return output\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(config.embedding_dim, config.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.hidden_dim, config.embedding_dim),\n",
        "            nn.Dropout(config.dropout_rate),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        return self.net(input_tensor)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # ржкрзНрж░рждрж┐ржЯрж┐ LayerNorm ржЕржмржЬрзЗржХрзНржЯ рждрж╛рж░ ржирж┐ржЬрж╕рзНржм рж╕рзНржХрзЗрж▓рж┐ржВ ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░ beta ржПржмржВ gamma рж╕ржВрж░ржХрзНрж╖ржг ржХрж░рзЗред\n",
        "        self.layer_norm1 = nn.LayerNorm(config.embedding_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(config.embedding_dim)\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(config=config)\n",
        "        self.feed_forward = FeedForward(config=config)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        # forward ржорзЗржержб ржмрж╛ржж ржжрзЗржУржпрж╝рж╛ рж╣ржпрж╝рзЗржЫрзЗред\n",
        "        normed_input = self.layer_norm1(input_tensor) # ржЗржиржкрзБржЯрзЗ Layer Norm ржкрзНрж░ржпрж╝рзЛржЧ ржХрж░рзБржи\n",
        "        attention_output = self.multihead_attention(normed_input) # ржорж╛рж▓рзНржЯрж┐-рж╣рзЗржб ржЕрзНржпрж╛ржЯрзЗржирж╢ржи ржкрзНрж░ржпрж╝рзЛржЧ ржХрж░рзБржи\n",
        "        residual_attention = attention_output + input_tensor # \"before! layernorm1 ржпрзЛржЧ ржХрж░рзБржи\n",
        "        normed_attention = self.layer_norm2(residual_attention) # рж░рзЗрж╕рж┐ржбрзБржпрж╝рж╛рж▓ ржЖржЙржЯржкрзБржЯрзЗ ржЖржмрж╛рж░ LayerNorm ржкрзНрж░ржпрж╝рзЛржЧ ржХрж░рзБржи\n",
        "        feedforward_output = self.feed_forward(normed_attention) # ржлрж┐ржбржлрж░рзЛржпрж╝рж╛рж░рзНржб ржирзЗржЯржУржпрж╝рж╛рж░рзНржХ (FFN) ржкрзНрж░ржпрж╝рзЛржЧ ржХрж░рзБржи\n",
        "        final_output = feedforward_output + residual_attention # \"before\" layernorm2 ржпрзЛржЧ ржХрж░рзБржи!\n",
        "\n",
        "        return final_output\n",
        "\n",
        "class VocabularyLogits(nn.Module):\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        # рж▓рзЗржпрж╝рж╛рж░ ржирж░ржорж╛рж▓рж╛ржЗржЬрзЗрж╢ржи\n",
        "        self.output_norm = nn.LayerNorm(config.embedding_dim)\n",
        "        # рж╢ржмрзНржжржнрж╛ржгрзНржбрж╛рж░рзЗрж░ ржЖржХрж╛рж░рзЗ ржкрзНрж░ржХрзНрж╖рзЗржкржг\n",
        "        self.vocab_projection = nn.Linear(config.embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, transformer_block_output):\n",
        "        # Transformer ржмрзНрж▓ржХ ржерзЗржХрзЗ ржкрзНрж░рж╛ржкрзНржд ржЖржЙржЯржкрзБржЯрзЗ Layer normalization ржкрзНрж░ржпрж╝рзЛржЧ ржХрж░рзБржиред\n",
        "        normalized_output = self.output_norm.forward(transformer_block_output)  # (ржмрж┐, ржЯрж┐, рж╕рж┐)\n",
        "\n",
        "        # рж╕рзНржХрзЛрж░ржЧрзБрж▓рзЛржХрзЗ ржПржХржЯрж┐ рж▓рж┐ржирж┐ржпрж╝рж╛рж░ рж▓рзЗржпрж╝рж╛рж░ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ рж╢ржмрзНржжржнрж╛ржгрзНржбрж╛рж░рзЗрж░ ржЖржХрж╛рж░рзЗрж░ ржорж╛рждрзНрж░рж╛ржпрж╝ ржкрзНрж░ржХрзНрж╖рзЗржкржг ржХрж░рзЗред\n",
        "        vocab_logits = self.vocab_projection.forward(normalized_output)  # (ржмрж┐, ржЯрж┐, ржнрж┐)\n",
        "\n",
        "        return vocab_logits\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        self.config = config  # ржПржЯрж┐ ржЬрзЗржирж╛рж░рзЗржЯ ржХрж░рж╛рж░ рж╕ржоржпрж╝ржУ ржмрзНржпржмрж╣рзГржд рж╣ржпрж╝, рждрж╛ржЗ рж░рж╛ржЦржмрзЗржиред\n",
        "        self.embedding = EmbeddingModule(vocab_size, config=config)\n",
        "        self.blocks = nn.Sequential(*[TransformerBlock(config=config) for _ in range(config.layer_count)])\n",
        "        self.vocab_projection = VocabularyLogits(vocab_size=vocab_size, config=config)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # ржЯрзЗржХрзНрж╕ржЯ рждрзИрж░рж┐ ржХрж░рзБржи\n",
        "    def generate(self, input_indices, max_new_tokens):\n",
        "        # ржирж┐рж░рзНржжрж┐рж╖рзНржЯ рж╕ржВржЦрзНржпржХ ржЯрзЛржХрзЗржи `max_new_tokens` рждрзИрж░рж┐ ржХрж░рзБржи\n",
        "        for _ in range(max_new_tokens):\n",
        "            input_conditioned = input_indices[:, -self.config.input_sequence_length:] # ржЗржиржкрзБржЯ ржХрзНрж▓рж┐ржк ржХрж░рзБржи\n",
        "\n",
        "            # ржлрж░ржУржпрж╝рж╛рж░рзНржб ржкрж╛рж╕ `(likelihood, loss)` ржлрзЗрж░ржд ржжрзЗржпрж╝тАФрж╢рзБржзрзБржорж╛рждрзНрж░ `likelihood` ржХрзЗ `logits` рж╣рж┐рж╕рзЗржмрзЗ рж╕ржВрж░ржХрзНрж╖ржг ржХрж░рзБржиред\n",
        "            logits, _ = self.forward(input_conditioned, target_indices=None)\n",
        "            last_logits = logits[:, -1, :] # рж╢рзЗрж╖ ржЯрзЛржХрзЗржи ржЕржмрж╕рзНржерж╛ржирзЗрж░ ржЬржирзНржп рж▓ржЧрж┐ржЯ ржмрзЗрж░ ржХрж░рзБржи\n",
        "            probs = F.softmax(last_logits, dim=-1) # Softmax ржжрж┐ржпрж╝рзЗ рж╕ржорзНржнрж╛ржмржирж╛ рж╣рж┐рж╕рж╛ржм ржХрж░рзБржи\n",
        "\n",
        "            # ржкрж░ржмрж░рзНрждрзА ржЯрзЛржХрзЗржи ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзБржи\n",
        "            next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # ржирждрзБржи ржЯрзЛржХрзЗржиржЧрзБрж▓рзЛ ржПржХрждрзНрж░рж┐ржд ржХрж░рзБржи, `input_indices` ржЖржкржбрзЗржЯ ржХрж░рзБржиред\n",
        "            input_indices = torch.cat((input_indices, next_token), dim=1)\n",
        "\n",
        "        # ржорзВрж▓ `input_indices` ржПржмржВ `max_new_tokens` ржпрзЛржЧржлрж▓ ржжрзИрж░рзНржШрзНржпрзЗрж░ рж╢рзЗрж╖ `input_indices` ржлрзЗрж░ржд ржжрзЗржпрж╝ред\n",
        "        return input_indices\n",
        "\n",
        "    # рж╕ржорзНржнрж╛ржмржирж╛ ржПржмржВ ржХрзНрж╖рждрж┐ рж╣рж┐рж╕рж╛ржм ржХрж░рзБржи\n",
        "    def forward(self, input_indices, target_indices):\n",
        "        embeddings = self.embedding(input_indices)\n",
        "        blocks_output = self.blocks(embeddings)\n",
        "        logits = self.vocab_projection(blocks_output)\n",
        "\n",
        "        # ржЗржиржлрж╛рж░рзЗржирзНрж╕рзЗ ржХрзЛржирзЛ ржЯрж╛рж░рзНржЧрзЗржЯ ржерж╛ржХрзЗ ржирж╛, рждрж╛ржЗ рж▓рж╕ `None` рж╣ржпрж╝ред\n",
        "        # тАФрж╢рзБржзрзБржорж╛рждрзНрж░ рж╕ржорзНржнрж╛ржмржирж╛ (logits) ржлрзЗрж░ржд ржжрзЗржУржпрж╝рж╛ рж╣ржпрж╝ред\n",
        "        if target_indices is None:\n",
        "            return logits, None\n",
        "\n",
        "        batch_size, token_len, vocab_size = logits.shape\n",
        "        logits = logits.view(batch_size * token_len, vocab_size)\n",
        "        targets = target_indices.view(batch_size * token_len)\n",
        "        loss = self.criterion(logits, targets)\n",
        "\n",
        "        return logits, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0vcUT2kwwR5"
      },
      "source": [
        "**DeterministicDropout-ржПрж░ ржЬрж╛рзЯржЧрж╛рзЯ nn.Dropout ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи**\n",
        "```python\n",
        "AttentionHead: dropout = nn.Dropout(config.dropout_rate)\n",
        "MultiHeadAttention: dropout = nn.Dropout(config.dropout_rate)\n",
        "FeedForward:  nn.Dropout(config.dropout_rate)\n",
        "```\n",
        "<label><input type=\"checkbox\"> Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAqEd0cywV56"
      },
      "source": [
        "**Chapter 12: Trainer Class: Section 2: ржХрзНрж▓рж╛рж╕ рж╕рж╛рж░рж╕ржВржХрзНрж╖рзЗржк** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IGG8rZJT9fx"
      },
      "source": [
        "### Section 3: Training and Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pdT24q93vOX"
      },
      "source": [
        "ржПржЦржи ржкрж░рзНржпржирзНржд, embedding dimension ржЫрж┐рж▓ 8, ржжрзБржЯрж┐ attention heads рж╕рж╣, ржПржмржВ FeedForward Network-ржП 16-dim hidden layers ржЫрж┐рж▓ред<br>\n",
        "ржПржЯрж╛ ржнрж╛рж▓рзЛ ржкрзНрж░ржХрж╛рж╢рзЗрж░ ржЬржирзНржп ржЦрзБржм рж╕рзАржорж┐рждред<br>\n",
        "ржПржЦржи, embedding dimension 64 рж╕рзЗржЯ ржХрж░рзБржи, 4 attention heads рж╕рж╣ ржПржмржВ FeedForward Network-ржП 256-dim hidden layers рж░рж╛ржЦрзБржиред"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ooeKTSmYOdn",
        "outputId": "505d4f44-f337-48eb-dde3-e5e4198a9b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Each setting for the ModelConfig class:\n",
            "Batch size: 16\n",
            "Input sequence length: 32\n",
            "Total training steps: 5000\n",
            "Evaluation frequency (in steps): 100\n",
            "Learning rate: 0.001\n",
            "Device in use: cuda\n",
            "Number of evaluation loops: 10\n",
            "Embedding vector dimension: 64\n",
            "Hidden layer dimension of the feedforward network: 256\n",
            "Number of attention heads: 4\n",
            "Number of model layers: 4\n",
            "Dropout rate: 0.1\n",
            "Random seed value: 1337\n"
          ]
        }
      ],
      "source": [
        "# ржоржбрзЗрж▓ рж╕рзЗржЯрж┐ржВрж╕ рж╕ржВрж░ржХрзНрж╖ржгржХрж╛рж░рзА ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи ржХрзНрж▓рж╛рж╕\n",
        "class ModelConfig:\n",
        "    batch_size = 16  # ржПржХржмрж╛рж░рзЗ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржЬрж╛ржд ржХрж░рж╛рж░ ржбрзЗржЯрж╛рж░ ржкрж░рж┐ржорж╛ржг (ржмрзНржпрж╛ржЪ рж╕рж╛ржЗржЬ)\n",
        "    input_sequence_length = 32  # ржЗржиржкрзБржЯ ржбрзЗржЯрж╛рж░ ржжрзИрж░рзНржШрзНржп (рж╕рж┐ржХрзБржпрж╝рзЗржирзНрж╕ ржжрзИрж░рзНржШрзНржп)\n",
        "    total_training_steps = 5000  # рж╕рж░рзНржмрзЛржЪрзНржЪ ржкрзНрж░рж╢рж┐ржХрзНрж╖ржгрзЗрж░ рж╕ржВржЦрзНржпрж╛ (ржзрж╛ржкрзЗрж░ рж╕ржВржЦрзНржпрж╛)\n",
        "    evaluation_frequency = 100  # ржоржбрзЗрж▓ ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржорзВрж▓рзНржпрж╛ржпрж╝ржирзЗрж░ ржлрзНрж░рж┐ржХрзЛржпрж╝рзЗржирзНрж╕рж┐\n",
        "    learning_rate = 0.001  # рж╢рж┐ржХрзНрж╖ржг рж╣рж╛рж░\n",
        "    device_type = 'cuda' if torch.cuda.is_available() else 'cpu'  # ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржбрж┐ржнрж╛ржЗрж╕ (GPU ржмрж╛ CPU)\n",
        "    evaluation_loops = 10  # ржорзВрж▓рзНржпрж╛ржпрж╝ржирзЗрж░ рж╕ржоржпрж╝ ржкрзБржирж░рж╛ржмрзГрждрзНрждрж┐рж░ рж╕ржВржЦрзНржпрж╛\n",
        "    embedding_dim = 64  # ржПржорзНржмрзЗржбрзЗржб рж▓рзЗржпрж╝рж╛рж░рзЗрж░ ржЖржХрж╛рж░ (ржлрж┐ржЪрж╛рж░ ржнрзЗржХрзНржЯрж░рзЗрж░ ржорж╛рждрзНрж░рж╛рж░ рж╕ржВржЦрзНржпрж╛)\n",
        "    hidden_dim = 256\n",
        "    num_attention_heads = 4  # ржирзЛржЯ ржорзЗржХрж╛ржирж┐ржЬржо рж╣рзЗржб ржиржорзНржмрж░\n",
        "    layer_count = 4  # ржоржбрзЗрж▓рзЗрж░ рж╕рзНрждрж░рзЗрж░ рж╕ржВржЦрзНржпрж╛\n",
        "    dropout_rate = 0.1  # ржбрзНрж░ржкржЖржЙржЯ рж╕ржорзНржнрж╛ржмржирж╛\n",
        "    random_seed_value = 1337  # ржкрзБржирж░рзБрждрзНржкрж╛ржжржирзЗрж░ ржЬржирзНржп рж░рзНржпрж╛ржирзНржбржо ржиржорзНржмрж░ рж╕рзАржбрж╕ржорзВрж╣\n",
        "\n",
        "# ржЖржкржирж╛рж░ рж╕рзЗржЯрж┐ржВрж╕ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи\n",
        "config = ModelConfig()\n",
        "\n",
        "print(\"ModelConfig ржХрзНрж▓рж╛рж╕рзЗрж░ ржкрзНрж░рждрж┐ржЯрж┐ рж╕рзЗржЯрж┐ржВ:\")\n",
        "print(f\"Batch size: {config.batch_size}\")\n",
        "print(f\"Input sequence length: {config.input_sequence_length}\")\n",
        "print(f\"Total training steps: {config.total_training_steps}\")\n",
        "print(f\"Evaluation frequency (in steps): {config.evaluation_frequency}\")\n",
        "print(f\"Learning rate: {config.learning_rate}\")\n",
        "print(f\"Device in use: {config.device_type}\")\n",
        "print(f\"Number of evaluation loops: {config.evaluation_loops}\")\n",
        "print(f\"Embedding vector dimension: {config.embedding_dim}\")\n",
        "print(f\"Hidden layer dimension of the feedforward network: {config.hidden_dim}\")\n",
        "print(f\"Number of attention heads: {config.num_attention_heads}\")\n",
        "print(f\"Number of model layers: {config.layer_count}\")\n",
        "print(f\"Dropout rate: {config.dropout_rate}\")\n",
        "print(f\"Random seed value: {config.random_seed_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwvOpyQPm5Jl"
      },
      "source": [
        "**`Check Point`**\n",
        "<label><input type=\"checkbox\"> ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзБржи Config ржХрзНрж▓рж╛рж╕рзЗрж░ ржкрзНрж░рждрж┐ржЯрж┐ рж╕рзЗржЯрж┐ржВ рж╕ржарж┐ржХржнрж╛ржмрзЗ ржжрзЗржЦрж╛ржЪрзНржЫрзЗ<br></label>\n",
        "- ржмрзНржпрж╛ржЪ рж╕рж╛ржЗржЬ: 16<br>\n",
        "- ржмрзНрж▓ржХ рж╕рж╛ржЗржЬ: 32<br>\n",
        "- рж╕рж░рзНржмрзЛржЪрзНржЪ ржЗржиржЯрж╛рж░рзЗрж╢ржи: 5000<br>\n",
        "- ржорзВрж▓рзНржпрж╛ржпрж╝ржи ржЗржирзНржЯрж╛рж░ржнрзНржпрж╛рж▓: 100<br>\n",
        "- рж▓рж╛рж░рзНржирж┐ржВ рж░рзЗржЯ: 0.001<br>\n",
        "- ржЗржЙржЬржб ржбрж┐ржнрж╛ржЗрж╕: cuda ржмрж╛ cpu<br>\n",
        "- ржорзВрж▓рзНржпрж╛ржпрж╝ржи ржЗржиржЯрж╛рж░рзЗрж╢ржирзЗрж░ рж╕ржВржЦрзНржпрж╛: 10<br>\n",
        "- ржПржорзНржмрзЗржбрж┐ржВ рж▓рзЗржпрж╝рж╛рж░рзЗрж░ ржорж╛рждрзНрж░рж╛: 64<br>\n",
        "- ржлрж┐ржбржлрж░рзЛржпрж╝рж╛рж░рзНржб рж╣рж┐ржбрзЗржи ржорж╛рждрзНрж░рж╛: 256<br>\n",
        "- ржЕрзНржпрж╛ржЯрзЗржирж╢ржи рж╣рзЗржбрзЗрж░ рж╕ржВржЦрзНржпрж╛: 4<br>\n",
        "- ржоржбрзЗрж▓ рж▓рзЗржпрж╝рж╛рж░рзЗрж░ рж╕ржВржЦрзНржпрж╛: 4<br>\n",
        "- ржбрзНрж░ржкржЖржЙржЯ рж░рзЗржЯ: 0.1<br>\n",
        "- рж╕рзАржб ржнрзНржпрж╛рж▓рзБ: 1337<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EctA8L49Tsc0",
        "outputId": "d7dfe830-e4bb-4f40-8b15-8cda7e56de12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x782b68401490>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи рж▓рзЛржб ржХрж░рзБржи ржПржмржВ рж╕рж┐ржб рж╕рзЗржЯ ржХрж░рзБржи\n",
        "config = ModelConfig()\n",
        "torch.manual_seed(config.random_seed_value)  # ржкрзБржирж░рзБрждрзНржкрж╛ржжржи ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рждрзЗ рж░тАНрзНржпрж╛ржирзНржбржо ржиржорзНржмрж░ рж╕рзАржб рж╕рзЗржЯ ржХрж░рзБржи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXBa9z1ogsUw"
      },
      "outputs": [],
      "source": [
        "# ржбрзЗржЯрж╛ рж▓рзЛржб ржХрж░рзБржи\n",
        "with open(\"input.txt\", 'r', encoding = 'utf-8') as f:\n",
        "    text_data = f.read()\n",
        "data_loader = DataLoader(text_data, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtyVxmwiTotc",
        "outputId": "c124075e-6a3d-413a-f0f9-ef56415b2dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.209729 M parameters\n"
          ]
        }
      ],
      "source": [
        "# ржоржбрзЗрж▓ ржУ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрж╛рж░ рж╢рзБрж░рзБ ржХрж░рзБржи\n",
        "model = BigramLanguageModel(vocab_size = data_loader.vocab_size, config = config).to(config.device_type)  # ржЖржкржирж┐ ржпрзЗ ржбрж┐ржнрж╛ржЗрж╕ржЯрж┐ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗржи рждрж╛ ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржХрж░рзБржи\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "# ржоржбрзЗрж▓рзЗрж░ ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░ рж╕ржВржЦрзНржпрж╛ ржкрзНрж░рж┐ржирзНржЯ ржХрж░рзБржи\n",
        "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mysHV8yjE7P6"
      },
      "source": [
        "рждрзБрж▓ржирж╛ржорзВрж▓ржХржнрж╛ржмрзЗ, GPT2-Small ржоржбрзЗрж▓рзЗрж░ рззрззрзнM (ржмрж╛ рззрзирзкM) ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░ рж░ржпрж╝рзЗржЫрзЗред"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx-g4ndFubat"
      },
      "source": [
        "ржПржХрзНрж╕ржкрзЗрж░рж┐ржорзЗржирзНржЯ рж╣рж┐рж╕рзЗржмрзЗ, ржкрзНрж░рж┐-ржЯрзНрж░рзЗржирж┐ржВ ржзрж╛ржкрзЗ ржЬрзЗржирж╛рж░рзЗрж╢ржи ржХрж░рж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржиред"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpnodhC5ubat",
        "outputId": "77b04870-2352-4921-fbea-3ad7f62188ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's henvIeuW;JcijkeLWfUaUJW;VcE!Pf;ocFF&oNhq$eQLJOOEFWXgjNhhqv;Es\n",
            "iowD&ZqK&CgwN'Pq$mFHGjX.esumfonqUzgrN?pNVvN!Iebiqfs!EuOt3Zw?Bjx$oYk-wXmvevRibdVde!eJgRLKasNnge?DEYpK! 'scfoOl!Ebe$iol$-UpfXGKtewgLMsO!?fX?&D?;-$zBR.SudGdOo.&co\n",
            "zvzNqQriRR'QbHbs'QqXghiHWJwLUEZE&pNz\n",
            "T'Rk!ZgbN?tmE.uJaekBK?Oh&n&Um,LDqc'omcC&Z;xpZGipgRQeN$y?VDbOvsN,$IcNhepTHJeWkzKdrf?roHm?dfwFUpwMVg;ei&$RCXTyowaFZhjVBm$3g33cAuh,K?UlAGcX;p!JUlNvvbIHG.3inUc.HjMCsyhnpwAKylbSHT'pXh3UNfO:mreo'VrL'cpe-NC,ntZAziOpKcpTOE.hs:Ck&z'LGJgyb3?p!3fI,OjzFHE\n"
          ]
        }
      ],
      "source": [
        "text = \"Let's he\"  # ржкрзНрж░ржорзНржкржЯ\n",
        "initial_context = torch.tensor(data_loader.encode(text), dtype=torch.long)\n",
        "# unsqueeze(0) ржжрж┐ржпрж╝рзЗ ржмрзНржпрж╛ржЪ ржбрж╛ржЗржорзЗржирж╢ржи ржпрзЛржЧ ржХрж░рзБржи (ржмрзНржпрж╛ржЪ рж╕рж╛ржЗржЬ=1)\n",
        "initial_context_unsqueeze = initial_context.unsqueeze(0)\n",
        "# тЖУ ржорзВрж▓ ржХржерж╛ рж╣рж▓рзЛ ржПржЯрж┐ ржЖржкржирж┐ ржпрзЗ ржбрж┐ржнрж╛ржЗрж╕ ржмрзНржпржмрж╣рж╛рж░ ржХрж░ржЫрзЗржи (CPU ржмрж╛ GPU)-рждрзЗ рж╕рж░рж╛ржирзЛ!\n",
        "initial_context_unsqueeze = initial_context_unsqueeze.to(config.device_type)\n",
        "\n",
        "# ржЙрждрзНржкрж╛ржжржи рж╢рзБрж░рзБ ржХрж░рзБржи\n",
        "generated_sequence_initial = model.generate(initial_context_unsqueeze, max_new_tokens=500)\n",
        "print(data_loader.decode(generated_sequence_initial[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYintz_Aubat"
      },
      "source": [
        "рж╣рзБржо, ржПржЯрж╛ рждрзЛ ржПржХржЯрж╛ ржХржорзНржкрж┐ржЙржЯрж╛рж░ЁЯТ╗, рждрж╛ржЗ ржирж╛?\n",
        "\n",
        "ржарж┐ржХ ржЖржЫрзЗ, рждрж╛рж╣рж▓рзЗ ржЪрж▓ рж╕рзЗржЯрж╛ржХрзЗ ржЯрзНрж░рзЗржи ржХрж░рж┐ ржЖрж░ ржЫрзЛржЯ ржмрж╛ржЪрзНржЪрж╛рж░ ржорждрзЛ ржмржбрж╝ ржХрж░рж┐ЁЯС╢!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK_3F336Eu6z"
      },
      "source": [
        "**рж╕ржмрж╢рзЗрж╖рзЗ ржЖржорж░рж╛ ржкрзМржБржЫрзЗ ржЧрзЗржЫрж┐ рж╢рзЗрж╖ ржкрж░рзНржмрзЗред рж╢рзБрж░рзБ ржХрж░ржЫрж┐ [emotional BGM┬╣](https://youtu.be/GqmAe0QfkjU?feature=shared)ред<br>ржЯрзНрж░рзЗржирж┐ржВ рж╣ржмрзЗ ржЖржирзБржорж╛ржирж┐ржХ рзи ржерзЗржХрзЗ рзк ржорж┐ржирж┐ржЯред ржЪрж▓рзБржи ржПржЗ ржорзБрж╣рзВрж░рзНрждрзЗ ржоржЧрзНржи рж╣ржпрж╝рзЗ ржпрж╛ржЗред**\n",
        "\n",
        "---\n",
        "\n",
        "Content Reference:  \n",
        "┬╣ **DooPiano**, тАЬBTS (ы░йэГДьЖМыЕДыЛи) тАУ ы┤ДыВа (Spring Day) Piano & String Orchestra Version,тАЭ YouTube, 3:41, published ~8.2тАпyears ago (circa 2017). Accessed JulyтАп8тАп2025.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6t0rayVFh2U"
      },
      "source": [
        "**ржПржХржЯрзБ рж╣рж▓рзЗржУ BGM рж╢рзБржирждрзЗ ржнрзБрж▓ржмрзЗржи ржирж╛! ржирж┐рж╢рзНржЪрж┐рждржнрж╛ржмрзЗржЗ ржоржи ржЫрзБржБржпрж╝рзЗ ржпрж╛ржмрзЗ! ржПржмрж╛рж░, ржирж┐ржЪрзЗрж░ рж╕рзЗрж▓ржЯрж┐ ржЪрж╛рж▓рж┐ржпрж╝рзЗ ржЯрзНрж░рзЗржирж┐ржВ рж╢рзБрж░рзБ ржХрж░рзБржи!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpagygD5TqHA",
        "outputId": "87c4c733-8f0d-45da-fe25-cd8b2fd6d5a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===TRAINING STARTED SUCCESSFULLY===\n",
            "Step 0: Train Loss 2.3080, Validation Loss 2.3095\n",
            "Step 100: Train Loss 2.2592, Validation Loss 2.2887\n",
            "Step 200: Train Loss 2.2122, Validation Loss 2.2228\n",
            "Step 300: Train Loss 2.1850, Validation Loss 2.1929\n",
            "Step 400: Train Loss 2.1433, Validation Loss 2.1610\n",
            "Step 500: Train Loss 2.0731, Validation Loss 2.1434\n",
            "Step 600: Train Loss 2.0713, Validation Loss 2.1265\n",
            "Step 700: Train Loss 2.0781, Validation Loss 2.0784\n",
            "Step 800: Train Loss 2.0399, Validation Loss 2.1171\n",
            "Step 900: Train Loss 1.9939, Validation Loss 2.0921\n",
            "Step 1000: Train Loss 2.0463, Validation Loss 2.0800\n",
            "Step 1100: Train Loss 2.0031, Validation Loss 2.0437\n",
            "Step 1200: Train Loss 1.9710, Validation Loss 2.0322\n",
            "Step 1300: Train Loss 1.8837, Validation Loss 2.0148\n",
            "Step 1400: Train Loss 1.9525, Validation Loss 2.0299\n",
            "Step 1500: Train Loss 1.9432, Validation Loss 2.0055\n",
            "Step 1600: Train Loss 1.9284, Validation Loss 1.9633\n",
            "Step 1700: Train Loss 1.9180, Validation Loss 1.9909\n",
            "Step 1800: Train Loss 1.8999, Validation Loss 1.9350\n",
            "Step 1900: Train Loss 1.8392, Validation Loss 1.9623\n",
            "Step 2000: Train Loss 1.8845, Validation Loss 1.9732\n",
            "Step 2100: Train Loss 1.8869, Validation Loss 1.9537\n",
            "Step 2200: Train Loss 1.8619, Validation Loss 1.9648\n",
            "Step 2300: Train Loss 1.8186, Validation Loss 1.9966\n",
            "Step 2400: Train Loss 1.8383, Validation Loss 1.9590\n",
            "Step 2500: Train Loss 1.8500, Validation Loss 1.9092\n",
            "Step 2600: Train Loss 1.8149, Validation Loss 1.8838\n",
            "Step 2700: Train Loss 1.8128, Validation Loss 1.9213\n",
            "Step 2800: Train Loss 1.8046, Validation Loss 1.9234\n",
            "Step 2900: Train Loss 1.8057, Validation Loss 1.9302\n",
            "Step 3000: Train Loss 1.7888, Validation Loss 1.8733\n",
            "Step 3100: Train Loss 1.7705, Validation Loss 1.9013\n",
            "Step 3200: Train Loss 1.7730, Validation Loss 1.9126\n",
            "Step 3300: Train Loss 1.8045, Validation Loss 1.9461\n",
            "Step 3400: Train Loss 1.7554, Validation Loss 1.9231\n",
            "Step 3500: Train Loss 1.7937, Validation Loss 1.8936\n",
            "Step 3600: Train Loss 1.7712, Validation Loss 1.8767\n",
            "Step 3700: Train Loss 1.7668, Validation Loss 1.8839\n",
            "Step 3800: Train Loss 1.7718, Validation Loss 1.8480\n",
            "Step 3900: Train Loss 1.7603, Validation Loss 1.8709\n",
            "Step 4000: Train Loss 1.7487, Validation Loss 1.8557\n",
            "Step 4100: Train Loss 1.7145, Validation Loss 1.8529\n",
            "Step 4200: Train Loss 1.7628, Validation Loss 1.8611\n",
            "Step 4300: Train Loss 1.6964, Validation Loss 1.8522\n",
            "Step 4400: Train Loss 1.7155, Validation Loss 1.8929\n",
            "Step 4500: Train Loss 1.7233, Validation Loss 1.8741\n",
            "Step 4600: Train Loss 1.7043, Validation Loss 1.8837\n",
            "Step 4700: Train Loss 1.6532, Validation Loss 1.8430\n",
            "Step 4800: Train Loss 1.6850, Validation Loss 1.7992\n",
            "Step 4900: Train Loss 1.7202, Validation Loss 1.8850\n",
            "Step 4999: Train Loss 1.7031, Validation Loss 1.9120\n",
            "Training DONE\n",
            "Model and optimizer state saved to bigram_language_model.pth\n"
          ]
        }
      ],
      "source": [
        "print(\"===ржкрзНрж░рж╢рж┐ржХрзНрж╖ржг рж╕ржлрж▓ржнрж╛ржмрзЗ рж╢рзБрж░рзБ рж╣ржпрж╝рзЗржЫрзЗ===\")\n",
        "\n",
        "# ржоржбрзЗрж▓ ржкрзНрж░рж╢рж┐ржХрзНрж╖ржг ржжрж┐ржи\n",
        "trainer = Trainer(model, optimizer, data_loader, config)\n",
        "trainer.train()\n",
        "\n",
        "# ржоржбрзЗрж▓ рж╕ржВрж░ржХрзНрж╖ржг ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ\n",
        "save_path = \"bigram_language_model.pth\"\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict()\n",
        "}, save_path)\n",
        "\n",
        "print(\"ржкрзНрж░рж╢рж┐ржХрзНрж╖ржг рж╕ржорзНржкржирзНржи рж╣ржпрж╝рзЗржЫрзЗ\")\n",
        "print(f\"Model and optimizer state saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiEiQNKci0xq",
        "outputId": "76f971cc-7a84-4c47-c9a6-dac8152999fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Model Loaded Successfully!=====\n"
          ]
        }
      ],
      "source": [
        "# ---- рж╕ржВрж░ржХрзНрж╖рж┐ржд ржоржбрзЗрж▓ рж▓рзЛржб рж╣ржЪрзНржЫрзЗ ржПржмржВ ржЯрзЗржХрзНрж╕ржЯ рждрзИрж░рж┐ рж╣ржЪрзНржЫрзЗ -----\n",
        "# ржирждрзБржи ржоржбрзЗрж▓ ржУ ржЕржкржЯрж┐ржорж╛ржЗржЬрж╛рж░ рж╢рзБрж░рзБ ржХрж░рзБржи (ржПржХржЗ рж╕рзЗржЯрж┐ржВрж╕ ржУ ржХрзНрж▓рж╛рж╕ ржбрзЗржлрж┐ржирж┐рж╢ржи ржкрзНрж░ржпрж╝рзЛржЬржи)\n",
        "loaded_model = BigramLanguageModel(vocab_size = data_loader.vocab_size, config = config).to(config.device_type)  # ржЖржкржирж╛рж░ ржмрзНржпржмрж╣рзГржд ржбрж┐ржнрж╛ржЗрж╕ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рзБржи\n",
        "loaded_optimizer = torch.optim.AdamW(loaded_model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "save_path = \"bigram_language_model.pth\"\n",
        "checkpoint = torch.load(save_path, map_location=config.device_type)\n",
        "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "loaded_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "print(\"===== ржоржбрзЗрж▓ рж╕ржлрж▓ржнрж╛ржмрзЗ рж▓рзЛржб рж╣ржпрж╝рзЗржЫрзЗ! =====\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Pj_bPCEPPS"
      },
      "source": [
        "ржоржбрзЗрж▓ржХрзЗ evaluation ржорзЛржбрзЗ рж╕рзЗржЯ ржХрж░рзБржиред ржЬрзЗржирж╛рж░рзЗрж╢ржирзЗрж░ ржЖржЧрзЗ Dropout ржмржирзНржз ржХрж░рзЗ ржжрж┐ржиред\n",
        "\n",
        "ржнрзБрж▓рзЗ ржЧрзЗрж▓рзЗ Dropout ржЪрж╛рж▓рзБ рж╣ржпрж╝рзЗ ржпрж╛ржпрж╝ред рждржЦржи ржЖржЙржЯржкрзБржЯ ржЦрж╛рж░рж╛ржк рж╣ржмрзЗ, рждрж╛ржЗ рж╕рж╛ржмржзрж╛ржи ржерж╛ржХрзБржиред"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yuLBig8EG91",
        "outputId": "83214a4c-14a2-4649-d21a-e1e6755d5a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Set to Evaluation mode, disabled Dropout. =====\n"
          ]
        }
      ],
      "source": [
        "loaded_model.eval()\n",
        "print(\"===== ржЗржнрзНржпрж╛рж▓рзБржпрж╝рзЗрж╢ржи ржорзЛржбрзЗ рж╕рзЗржЯ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ, ржбрзНрж░ржкржЖржЙржЯ ржирж┐рж╖рзНржХрзНрж░рж┐ржпрж╝ред =====\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaQb254DuA8X",
        "outputId": "b6f93c3a-e5ce-47b6-b2d3-d61613389e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoded_prompt\n",
            "Tensor Size: [8]\n",
            "tensor([\n",
            "         24.00,  43.00,  58.00,   5.00,  57.00,   1.00,  46.00,  43.00\n",
            "       ])\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Let's he\"  # ржкрзНрж░ржорзНржкржЯ\n",
        "encoded_prompt = torch.tensor(data_loader.encode(prompt), dtype=torch.long)\n",
        "print_formatted_tensor(\"ржПржиржХрзЛржб ржХрж░рж╛ ржкрзНрж░ржорзНржкржЯ\", encoded_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QoDkdBPuC2Q",
        "outputId": "cf25d96f-7b3b-4fc3-bc7a-80252e47a5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoded_prompt_unsqueeze\n",
            "Tensor Size: [1, 8]\n",
            "tensor([\n",
            "         [ 24.00,  43.00,  58.00,   5.00,  57.00,   1.00,  46.00,  43.00]\n",
            "       ])\n"
          ]
        }
      ],
      "source": [
        "# unsqueeze(0) ржжрж┐ржпрж╝рзЗ ржмрзНржпрж╛ржЪ ржорж╛рждрзНрж░рж╛ ржпрзЛржЧ ржХрж░рзБржи (ржмрзНржпрж╛ржЪ рж╕рж╛ржЗржЬ=1)\n",
        "encoded_prompt_unsqueeze = encoded_prompt.unsqueeze(0)\n",
        "print_formatted_tensor(\"ржПржиржХрзЛржбрзЗржб_ржкрзНрж░ржорзНржкржЯ_ржЖржирж╕ржХрзБржЗржЬ\", encoded_prompt_unsqueeze)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dUOQgT3uEHx"
      },
      "outputs": [],
      "source": [
        "# тЖУ ржорзВрж▓ ржХржерж╛ рж╣рж▓ ржкрзНрж░ржорзНржкржЯ ржЯрзЗржирж╕рж░ржЯрж┐ ржЖржкржирж┐ ржпрзЗ ржбрж┐ржнрж╛ржЗрж╕ ржмрзНржпржмрж╣рж╛рж░ ржХрж░ржЫрзЗржи (CPU ржмрж╛ GPU) рж╕рзЗржЦрж╛ржирзЗ рж╕рж░рж┐ржпрж╝рзЗ ржирзЗржУржпрж╝рж╛!\n",
        "encoded_prompt_unsqueeze = encoded_prompt_unsqueeze.to(config.device_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdiKzDt6zXpP"
      },
      "source": [
        "```python\n",
        "Instance: loaded_model\n",
        "Method: generate\n",
        "Arguments: encoded_prompt_unsqueeze, max_new_tokens=1000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U58DsEfuF27",
        "outputId": "41bb755e-a8bc-4109-b385-79ede0010b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's he weath to begiver thing thou are perpisency the gertater sing\n",
            "To With beenes; no from to the chaul!\n",
            "\n",
            "JUTIO:\n",
            "Were this not the carence your in singrard hath lond\n",
            "Capus leet.\n",
            "\n",
            "BRUTUS:\n",
            "Thee bust to me to speaks or his it,\n",
            "\n",
            "Deseetock untertay laid I wand for shing\n",
            "that ittience, God nig for the from do it it.\n",
            "\n",
            "Pervore, I sethall thou breather,\n",
            "By tyre agent man some thou my servery plaid be the spoble.\n",
            "\n",
            "GLOUCESTER:\n",
            "Shallo, Say fauls I weick.\n",
            "\n",
            "DUCESTER MARGAREY:\n",
            "My noble thear, an, and at to he's guend\n",
            "For me full I say's be swould Gentleat haph till\n",
            "Nor And being years their rlancues\n",
            "The Last burssened to her be gry our sto stoot\n",
            "Ands that nurse steep\n",
            "Of aund will of her age man, tiSingment your boy's rings:\n",
            "Your my and again and well I would theur ady\n",
            "A samernon to do time'n sail thou lack your juty,\n",
            "No? I coundertife thou have thee other awarthrough a dne'd I preaty\n",
            "Waveichard him time if our good bowers highne:\n",
            "Thears.\n",
            "\n",
            "Thidds; and I' weal theseity. Bollow Richions:\n",
            "As City you?I heark,\n"
          ]
        }
      ],
      "source": [
        "# ржЙрзОржкрж╛ржжржи рж╢рзБрж░рзБ ржХрж░рзБржи\n",
        "generated_sequence = loaded_model.generate(encoded_prompt_unsqueeze, max_new_tokens=1000) # TODO: ржЙржжрж╛рж╣рж░ржг,\n",
        "print(data_loader.decode(generated_sequence[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcHLCQ6P4O-8"
      },
      "source": [
        "ржПржмрж╛рж░ nanoGPT ржжрж┐ржпрж╝рзЗ ржХржорзНржкрж┐ржЙржЯрж╛рж░ЁЯТ╗ ржерзЗржХрзЗ ржПржХржЯрж╛ ржЫрзЛржЯ ржмрж╛ржЪрзНржЪрж╛рж░ЁЯС╢ ржкрж░рзНржпрж╛ржпрж╝рзЗ ржЙржарж▓рзЛред\n",
        "\n",
        "ржПрж░ржкрж░, GPT2 ржЫрзЛржЯ ржмрж╛ржЪрзНржЪрж╛ЁЯС╢ ржерзЗржХрзЗ ржорж╛ржзрзНржпржорж┐ржХ ржЫрж╛рждрзНрж░ЁЯзС-ржПрж░ ржжрж┐ржХрзЗ ржкрж╛ ржмрж╛ржбрж╝рж╛ржмрзЗ!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R52XY3hdxKUS"
      },
      "source": [
        "**Chapter 12: Trainer Class: Section 3: Training and Inference** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viJYZTXwxNhC"
      },
      "source": [
        "**Chapter 12: The Trainer Class** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1dLHoKgxQwm"
      },
      "source": [
        "**`nanoGPT`** <label><input type=\"checkbox\"> рж╕ржорзНржкржирзНржи</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykz9QCl8ubau"
      },
      "source": [
        "![уВ╣уВпуГкуГ╝уГ│уВ╖уГзуГГуГИ 2025-06-25 0.58.23.png](data:image/png;base64,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)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
