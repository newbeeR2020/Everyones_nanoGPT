{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Colabãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æ³¨æ„**\n",
        "\n",
        "# **ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ç›´æ¥æ›¸ãè¾¼ã¾ãªã„ã§ãã ã•ã„â€”ä½œæ¥­ãŒæ¶ˆãˆã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ï¼**\n",
        "\n",
        "# **å¿…ãšä½œæ¥­å‰ã«ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚**\n",
        "\n",
        "ã‚³ãƒ”ãƒ¼ã®ä½œã‚Šæ–¹\n",
        "\n",
        "1. å·¦ä¸Šã®ã€ŒFileã€ã‚’ã‚¯ãƒªãƒƒã‚¯  \n",
        "> *ã€ŒFileã€ã‚„ã€ŒRuntimeã€ãªã©ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãŒè¦‹ãˆãªã„ã¨ãã¯ã€å³ä¸Šã®â€œvâ€ãƒãƒ¼ã‚¯ã‚’æŠ¼ã—ã¦è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚*\n",
        "\n",
        "2. ã€ŒSave a copy in Driveã€ã‚’é¸ã¶  \n",
        "\n",
        "3. ã‚³ãƒ”ãƒ¼ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã€ŒYOURNAMEs_FileName.ipynbã€ã«å¤‰æ›´ã™ã‚‹  \n",
        "> ä¾‹ï¼šåå‰ãŒOliviaãªã‚‰ â†’ Olivias_FileName.ipynb  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "* ãƒã‚§ãƒƒã‚¯ãƒãƒ¼ã‚¯ï¼ˆâœ…ï¼‰ã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã€‚Chromeã®ãƒªãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã§ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã™ã‚‹ã¨æ¶ˆãˆã¾ã™ã€‚<br>  \n",
        "é€”ä¸­ã§æ­¢ã‚ã‚‹ã¨ãã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‚»ãƒ«ã‚’è¿½åŠ ã—ã¦ã€ŒSO FAR DONEã€ãªã©æ›¸ã„ã¦ãŠã„ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "* Colabã§ã¯**30åˆ†ã€œ90åˆ†ã”ã¨ã«ä»¥å‰ã®å‡ºåŠ›çµæœãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™**ã€‚<br>  \n",
        "ãã®ãŸã‚ã€`~~ is not defined`ã®ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ãŒ**ã™ã”ãã‚ˆãèµ·ã“ã‚Šã¾ã™**ã€‚\n",
        "\n",
        "ğŸ” `~~ is not defined`ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã‚‰ã©ã†ã™ã‚‹ï¼Ÿ\n",
        "\n",
        "1. ã¾ãšå¤‰æ•°åã®ã‚¹ãƒšãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚<br>  \n",
        "2. ã‚¹ãƒšãƒ«ãŒæ­£ã—ã„ã®ã«ã¾ã ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ãªã‚‰ã€**ãã®ã‚»ãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠ**ã—ã¦ãã ã•ã„ã€‚<br>  \n",
        "3. å·¦ä¸Šã®ã€ŒRuntimeã€â†’ã€ŒRun beforeã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã€‚<br>  \n",
        "â†’ ã“ã‚Œã§**ãã‚Œã¾ã§ã®ã™ã¹ã¦ã®ã‚»ãƒ«ãŒå†å®Ÿè¡Œã•ã‚Œã¾ã™**ã€‚  \n",
        "4. å†åº¦ã€ãã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã‚‚ã—ã“ã‚Œã§ã‚‚ã‚¨ãƒ©ãƒ¼ãŒç›´ã‚‰ãªã‘ã‚Œã°ã€<br>  \n",
        "å‰ã®ã‚»ãƒ«ã®TODOã®ç­”ãˆã«åŸºæœ¬çš„ãªãƒŸã‚¹ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚<br>  \n",
        "æ­£ã—ã„ã‹ã©ã†ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚<br>  \n",
        "ã¾ãŸã¯ChatGPTã‚„ä»–ã®ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã«åŠ©ã‘ã‚’æ±‚ã‚ã¾ã—ã‚‡ã†ã€‚"
      ],
      "metadata": {
        "id": "Cj6PNj59iqJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparation**\n",
        "\n",
        "ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯å‰ã®Chapterã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€ã ã‘ã§ã™ã€‚<br>\n",
        "ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘ã§OKã€‚èª­ã¾ãªãã¦ã‚‚å¤§ä¸ˆå¤«ã§ã™ã€‚<br>\n",
        "æ°—è»½ã«å…ˆã¸é€²ã‚“ã§ãã ã•ã„ã€‚<br>"
      ],
      "metadata": {
        "id": "BXZzMLzXiseX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\n",
        "!wget https://raw.githubusercontent.com/HayatoHongo/Everyones_nanoGPT/main/input.txt -O input.txt\n",
        "# utf-8ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸinput.textãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚\n",
        "with open(\"input.txt\", 'r', encoding = 'utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# ãƒ†ãƒ³ã‚½ãƒ«ã‚’è¦‹ã‚„ã™ãè¡¨ç¤ºã™ã‚‹é–¢æ•°ï¼ˆä»»æ„ï¼‰\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def print_formatted_tensor(*args, width=6, decimals=2):\n",
        "    \"\"\"\n    ",
        "    A function that neatly formats and displays a PyTorch Tensor, and also prints its size.\n",
        "\n",
        "    Example usage:\n",
        "        print_formatted_tensor(\"åå‰\", tensor)\n",
        "        print_formatted_tensor(tensor)\n",
        "\n",
        "    Args:\n",
        "        *args: If given 1 argument, it is treated as a tensor.\n",
        "               If given 2 arguments, the first is treated as the name, the second as the tensor.\n",
        "        width (int): Display width for each number (default: 6)\n",
        "        decimals (int): Number of decimal places to show (default: 2)\n",
        "    \"\"\"\n    ",
        "\n",
        "    # å¼•æ•°ã‹ã‚‰ãƒ†ãƒ³ã‚½ãƒ«ã¨åå‰ã‚’åˆ¤å®šã™ã‚‹\n",
        "    if not args:\n",
        "        raise ValueError(\"At least one argument is required.\")\n",
        "    if isinstance(args[0], str):\n",
        "        if len(args) < 2:\n",
        "            raise ValueError(\"Tensor is not specified.\")\n",
        "        name, tensor = args[0], args[1]\n",
        "    else:\n",
        "        name, tensor = None, args[0]\n",
        "\n",
        "    # Tensorã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹\n",
        "    tensor_list = tensor.detach().cpu().tolist()\n",
        "\n",
        "    def format_list(lst, indent):\n",
        "        \"\"\"å†å¸°çš„ãƒã‚¹ãƒˆãƒªã‚¹ãƒˆã®æ•´å½¢ã¨æ–‡å­—åˆ—è¿”å´\"\"\"\n",
        "        # å†…å®¹ãŒãƒªã‚¹ãƒˆãªã‚‰å†åº¦è¿”ã™\n",
        "        if isinstance(lst, list) and lst and isinstance(lst[0], list):\n",
        "            inner = \",\\n\".join(\" \" * indent + format_list(sub, indent + 2) for sub in lst)\n",
        "            return \"[\\n\" + inner + \"\\n\" + \" \" * (indent - 2) + \"]\"\n",
        "        # ç•ªå·ä»˜ããƒªã‚¹ãƒˆç”¨\n",
        "        return \"[\" + \", \".join(f\"{v:{width}.{decimals}f}\" for v in lst) + \"]\"\n",
        "\n",
        "    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿æ–‡å­—åˆ—ï¼ˆæœ€å¤–æ ã®ä¸­æ‹¬å¼§ã¯é™¤ãï¼‰\n",
        "    formatted = format_list(tensor_list, indent=9)\n",
        "    inner_formatted = formatted[1:-1].strip()\n",
        "\n",
        "    # çµæœå‡ºåŠ›\n",
        "    if name:\n",
        "        print(name)\n",
        "    print(f\"Tensor Size: {list(tensor.size())}\")\n",
        "    print(\"ãƒ†ãƒ³ã‚½ãƒ«([\")\n",
        "    print(\"\" * 9 + inner_formatted)\n",
        "    print(\"\" * 7 + \"])\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s04g6yFiuHE",
        "outputId": "a62bb238-1185-4194-d97f-8cbdcdd1f733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-08 11:25:56--  https://raw.githubusercontent.com/HayatoHongo/nanoGPT_todo/main/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: â€˜input.txtâ€™\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-07-08 11:25:56 (31.2 MB/s) - â€˜input.txtâ€™ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh_2Ls8tn2rk"
      },
      "source": [
        "# **Chapter 12 Trainer ã‚¯ãƒ©ã‚¹**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEl9A_wk33Pa"
      },
      "source": [
        "### **Section 1: ã‚¯ãƒ©ã‚¹å®šç¾©**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnILkem04RSW"
      },
      "source": [
        "ğŸ”˜ **Options**: ä¸è¦ãªè¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n",
        "\n",
        "`self.model`ã€€`self.optimizer`ã€€`self.data_loader`ã€€`self.config`ã€€`split_data`ã€€`get_batch`ã€€`'train'`, `'val'`ã€€`input_batch`ã€€`target_batch`ã€€`logits`ã€€`self.config.total_training_steps`ã€€`self.config.evaluation_loops`  \n",
        "`loss`ã€€`backward()`ã€€`self.train_step()`ã€€`self.evaluate()`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, data_loader, config):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.data_loader = data_loader\n",
        "        self.config = config\n",
        "\n",
        "    def train_step(self):\n",
        "        # è¨“ç·´ç”¨ãƒãƒƒãƒã‚’å–å¾—ã™ã‚‹ã€‚\n",
        "        input_batch, target_batch = self.data_loader.get_batch('train')\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # ãƒ¢ãƒ‡ãƒ«ã®é †ä¼æ’­ã¨æå¤±è¨ˆç®—\n",
        "        logits, loss = self.model(input_batch, target_batch)\n",
        "        loss.backward()  # èª¤å·®é€†ä¼æ’­æ³•\n",
        "        self.optimizer.step()  # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹\n",
        "\n",
        "        return loss.item() # æå¤±ã®å€¤ã‚’è¿”ã™\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®šã™ã‚‹\n",
        "        losses = {\"train\": [], \"val\": []} # è¨“ç·´ã¨æ¤œè¨¼ã®æå¤±ã‚’è¨ˆç®—ã™ã‚‹\n",
        "        with torch.no_grad():\n",
        "            for split in ['train', 'val']:\n",
        "                for _ in range(self.config.evaluation_loops):\n",
        "                    input_batch, target_batch = self.data_loader.get_batch(split)\n",
        "                    _, loss = self.model(input_batch, target_batch)\n",
        "                    losses[split].append(loss.item())\n",
        "        self.model.train()  # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã«æˆ»ã‚‹\n",
        "\n",
        "        # å„åˆ†å‰²ï¼ˆtrain, valï¼‰ã®å¹³å‡æå¤±ã‚’è¨ˆç®—ã™ã‚‹\n",
        "        return {split: sum(values) / len(values) for split, values in losses.items()}\n",
        "\n",
        "    def train(self):\n",
        "        # configã§æŒ‡å®šã•ã‚ŒãŸå›æ•°ã ã‘train_stepã‚’å®Ÿè¡Œã™ã‚‹ã€‚\n",
        "        for step in range(self.config.total_training_steps):\n",
        "\n",
        "            # 100å›ã”ã¨ã€ã¾ãŸã¯æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿è©•ä¾¡ã™ã‚‹ã€‚\n",
        "            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\n",
        "                eval_loss = self.evaluate()\n",
        "                print(f\"Step {step}: Train Loss {eval_loss['train']:.4f}, Validation Loss {eval_loss['val']:.4f}\")\n",
        "\n",
        "            # 1å›ã®å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆæ¯å›è¡Œã†ä¸»ãªå‡¦ç†ï¼‰\n",
        "            train_loss = self.train_step()"
      ],
      "metadata": {
        "id": "sRi90bRasayV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi8-y1ak4VOS",
        "outputId": "ec0f1c70-6f55-4cf2-fb9f-e5b56297691b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass Trainer:\\n    def __init__(self, model, optimizer, data_loader, config):\\n        self.model = model\\n        self.optimizer = optimizer\\n        self.data_loader = data_loader\\n        self.config = config\\n\\n    def train_step(self):\\n        # Get a batch for training.\\n        input_batch, target_batch = ___________._______(_____)\\n        self.optimizer.zero_grad()\\n\\n        # Model forward pass and loss calculation\\n        logits, loss = _______(_________, __________)\\n        _____.__________  # Backpropagation (Error backpropagation)\\n        self.optimizer.step()  # Update parameters\\n\\n        return loss.item() # Returns the value of the loss\\n\\n    def evaluate(self):\\n        self.model.eval()  # Set to evaluation mode\\n        losses = {\"train\": [], \"val\": []} # Calculate losses on both training and validation data\\n        with torch.no_grad():\\n            for split in [\\'train\\', \\'val\\']:\\n                for _ in range(self.config.evaluation_loops):\\n                    input_batch, target_batch = self.data_loader.get_batch(split)\\n                    _, loss = self.model(input_batch, target_batch)\\n                    losses[split].append(loss.item())\\n        self.model.train()  # Return to training mode\\n\\n        # Calculate the average losses for each split (train, val)\\n        return {split: sum(values) / len(values) for split, values in losses.items()}\\n\\n    def train(self):\\n        # Run train_step the number of times specified in config.\\n        for step in range(_________________________):\\n\\n            # Evaluate every 100 iterations or just at the final step.\\n            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\\n                eval_loss = self.evaluate()\\n                print(f\"Step {step}: Train Loss {eval_loss[\\'train\\']:.4f}, Validation Loss {eval_loss[\\'val\\']:.4f}\")\\n\\n            # One step of training (the main process that you do every time)\\n            train_loss = _____________\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\"\"\"\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, data_loader, config):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.data_loader = data_loader\n",
        "        self.config = config\n",
        "\n",
        "    def train_step(self):\n",
        "        # è¨“ç·´ç”¨ã®ãƒãƒƒãƒã‚’å–å¾—ã™ã‚‹ã€‚\n",
        "        input_batch, target_batch = ___________._______(_____)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # ãƒ¢ãƒ‡ãƒ«ã®é †ä¼æ’­ã¨æå¤±è¨ˆç®—\n",
        "        logits, loss = _______(_________, __________)\n",
        "        _____.__________  # é€†ä¼æ’­ï¼ˆèª¤å·®é€†ä¼æ’­ï¼‰\n",
        "        self.optimizer.step()  # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹\n",
        "\n",
        "        return loss.item() # æå¤±ã®å€¤ã‚’è¿”ã™\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®šã™ã‚‹\n",
        "        losses = {\"train\": [], \"val\": []} # å­¦ç¿’ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®æå¤±ã‚’è¨ˆç®—ã™ã‚‹\n",
        "        with torch.no_grad():\n",
        "            for split in ['train', 'val']:\n",
        "                for _ in range(self.config.evaluation_loops):\n",
        "                    input_batch, target_batch = self.data_loader.get_batch(split)\n",
        "                    _, loss = self.model(input_batch, target_batch)\n",
        "                    losses[split].append(loss.item())\n",
        "        self.model.train()  # å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã«æˆ»ã‚‹\n",
        "\n",
        "        # å„åˆ†å‰²(train, val)ã®å¹³å‡æå¤±ã‚’è¨ˆç®—ã™ã‚‹\n",
        "        return {split: sum(values) / len(values) for split, values in losses.items()}\n",
        "\n",
        "    def train(self):\n",
        "        # configã§æŒ‡å®šã•ã‚ŒãŸå›æ•°ã ã‘train_stepã‚’å®Ÿè¡Œã™ã‚‹ã€‚\n",
        "        for step in range(_________________________):\n",
        "\n",
        "            # 100å›ã”ã¨ã¾ãŸã¯æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—ã§è©•ä¾¡ã™ã‚‹ã€‚\n",
        "            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\n",
        "                eval_loss = self.evaluate()\n",
        "                print(f\"Step {step}: Train Loss {eval_loss['train']:.4f}, Validation Loss {eval_loss['val']:.4f}\")\n",
        "\n",
        "            # 1ã‚¹ãƒ†ãƒƒãƒ—ã®å­¦ç¿’ï¼ˆæ¯å›è¡Œã†ä¸»è¦å‡¦ç†ï¼‰\n",
        "            train_loss = _____________\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç­”ãˆã‚’è¡¨ç¤º/éè¡¨ç¤º</summary>\n",
        "\n",
        "```python\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, data_loader, config):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.data_loader = data_loader\n",
        "        self.config = config\n",
        "\n",
        "    def train_step(self):\n",
        "        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒãƒƒãƒã‚’å–å¾—ã€‚\n",
        "        input_batch, target_batch = self.data_loader.get_batch('train')\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # ãƒ¢ãƒ‡ãƒ«ã®é †ä¼æ’­ã¨æå¤±è¨ˆç®—\n",
        "        logits, loss = self.model(input_batch, target_batch)\n",
        "        loss.backward()  # èª¤å·®é€†ä¼æ’­\n",
        "        self.optimizer.step()  # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°\n",
        "\n",
        "        return loss.item() # æå¤±ã®å€¤ã‚’è¿”ã™\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ\n",
        "        losses = {\"train\": [], \"val\": []} # å­¦ç¿’ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ä¸¡æ–¹ã®æå¤±ã‚’è¨ˆç®—\n",
        "        with torch.no_grad():\n",
        "            for split in ['train', 'val']:\n",
        "                for _ in range(self.config.evaluation_loops):\n",
        "                    input_batch, target_batch = self.data_loader.get_batch(split)\n",
        "                    _, loss = self.model(input_batch, target_batch)\n",
        "                    losses[split].append(loss.item())\n",
        "        self.model.train()  # å†ã³å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã¸æˆ»ã™\n",
        "\n",
        "        # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆtrain, valï¼‰ã§ã®æå¤±ã®å¹³å‡ã‚’è¨ˆç®—ã—ã¦è¿”ã™\n",
        "        return {split: sum(values) / len(values) for split, values in losses.items()}\n",
        "\n",
        "    def train(self):\n",
        "        # configã§æŒ‡å®šã•ã‚ŒãŸå›æ•°ã ã‘train_stepã‚’å®Ÿè¡Œã€‚\n",
        "        for step in range(self.config.total_training_steps):\n",
        "\n",
        "            # 100ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã€ã¾ãŸã¯æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿è©•ä¾¡ã‚’è¡Œã†ã€‚\n",
        "            if step % self.config.evaluation_frequency == 0 or step == self.config.total_training_steps - 1:\n",
        "                eval_loss = self.evaluate()\n",
        "                print(f\"Step {step}: Train Loss {eval_loss['train']:.4f}, Validation Loss {eval_loss['val']:.4f}\")\n",
        "\n",
        "            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®1ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆæ¯å›è¡Œã†ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼‰\n",
        "            train_loss = self.train_step()\n",
        "```"
      ],
      "metadata": {
        "id": "7KUW7ceEA4ek"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPN1h-k_xejG"
      },
      "source": [
        "**Chapter 11: Trainer Class: Section 1: ã‚¯ãƒ©ã‚¹å®šç¾©** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU53fOfBPA_s"
      },
      "source": [
        "### **Section 2: ã‚¯ãƒ©ã‚¹æ¦‚è¦**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NcZr_SN-Ufm"
      },
      "source": [
        "Chapter 1ã‹ã‚‰Chapter 11ã¾ã§ã®ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¹ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚<br>\n",
        "**DeterministicDropoutã¯nn.Dropoutã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚**\n",
        "\n",
        "[Watch the video!](https://youtu.be/j2ErzvlslKA)\n",
        "- éŸ³å£°ãªã—\n",
        "- 4åˆ†\n",
        "\n",
        "å‹•ç”»å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã¯answer_colabã§ã™ãŒã€æ°—ã«ã—ãªã„ã§ãã ã•ã„ã€‚\n",
        "\n",
        "```python\n",
        "AttentionHead: dropout = nn.Dropout(config.dropout_rate)\n",
        "MultiHeadAttention: dropout = nn.Dropout(config.dropout_rate)\n",
        "FeedForward:  nn.Dropout(config.dropout_rate)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnLnj31rPTLC"
      },
      "outputs": [],
      "source": [
        "class DataLoader:\n",
        "    def __init__(self, text, config):\n",
        "        self.config = config  # è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
        "        chars = sorted(list(set(text)))  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ–‡å­—ã‚’ã‚½ãƒ¼ãƒˆã™ã‚‹\n",
        "        self.ctoi = {char: index for index, char in enumerate(chars)}\n",
        "        self.itoc = {index: char for index, char in enumerate(chars)}\n",
        "        self.vocab_size = len(chars)\n",
        "\n",
        "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã™ã‚‹ã€‚\n",
        "        # `__init__`å¤–ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚„å¼•æ•°ã‚’å‘¼ã¶ã«ã¯`self.`ãŒå¿…è¦ã§ã™ã€‚\n",
        "        self.data = torch.tensor(self.encode(text), dtype=torch.long)\n",
        "\n",
        "        # è¨“ç·´ç”¨ã¨æ¤œè¨¼ç”¨ã«åˆ†å‰²ã™ã‚‹ã€‚\n",
        "        # å¼•æ•°ãŒæŒ‡å®šã•ã‚Œãªãã¦ã‚‚self.dataãŒä½¿ã‚ã‚Œã¾ã™ã€‚\n",
        "        self.train_data, self.val_data = self.split_data()\n",
        "\n",
        "    def encode(self, text):\n",
        "        # æ–‡å­—åˆ—ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ã«å¤‰æ›ã—ã¾ã™ã€‚self.ã§ä»–ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚„å¼•æ•°ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚\n",
        "        return [self.ctoi[c] for c in text]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        return ''.join([self.itoc[i] for i in indices])\n",
        "\n",
        "    def split_data(self):\n",
        "        split_index = int(0.9 * len(self.data))  # ãƒ‡ãƒ¼ã‚¿ã®90%ã‚’è¨“ç·´ç”¨ã«åˆ†å‰²ã™ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‚\n",
        "        return self.data[:split_index], self.data[split_index:]\n",
        "\n",
        "    def get_batch(self, split):\n",
        "        data = self.train_data if split == 'train' else self.val_data\n",
        "        start_indices = torch.randint(len(data) - self.config.input_sequence_length, (self.config.batch_size,)) # æŠ½å‡ºé–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆã™ã‚‹\n",
        "\n",
        "        input_sequences = torch.stack([\n",
        "            data[start_index:start_index + self.config.input_sequence_length]\n",
        "            for start_index in start_indices\n",
        "        ])\n",
        "        target_sequences = torch.stack([\n",
        "            data[start_index + 1:start_index + self.config.input_sequence_length + 1]\n",
        "            for start_index in start_indices\n",
        "        ])\n",
        "        return input_sequences.to(self.config.device_type), target_sequences.to(self.config.device_type)\n",
        "\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        # èªå½™æ•°xåŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã®åŸ‹ã‚è¾¼ã¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å®šç¾©ã™ã‚‹\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def embed(self, input_indices):\n",
        "        # å…¥åŠ›ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾å¿œã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—ã™ã‚‹\n",
        "        return self.token_embedding_table.forward(input_indices)\n",
        "\n",
        "class PositionEmbedding(nn.Module):\n",
        "    def __init__(self, input_sequence_length = 8, embedding_dim = 8):\n",
        "        super().__init__()\n",
        "        # ä½ç½®åŸ‹ã‚è¾¼ã¿å±¤\n",
        "        self.position_embedding_layer = nn.Embedding(input_sequence_length, embedding_dim)\n",
        "\n",
        "    def forward(self, input_indices):\n",
        "        # å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ« input_indices ã®å½¢çŠ¶ï¼š[ãƒãƒƒãƒã‚µã‚¤ã‚ºã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·]ã€‚\n",
        "        sequence_length = input_indices.shape[1]\n",
        "\n",
        "        # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã«å¿œã˜ãŸä½ç½®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã™ã‚‹ï¼ˆä¾‹ï¼š[0, 1, 2, ..., sequence_length-1]ï¼‰\n",
        "        position_indices = torch.arange(sequence_length, device=input_indices.device)\n",
        "\n",
        "        # ä½ç½®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—ã™ã‚‹\n",
        "        position_embeddings = self.position_embedding_layer.forward(position_indices)\n",
        "\n",
        "        return position_embeddings\n",
        "\n",
        "class EmbeddingModule(nn.Module):\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        # å„ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿å±¤\n",
        "        self.token_embedding_layer = TokenEmbedding(vocab_size = vocab_size, embedding_dim = config.embedding_dim)  # å˜èªåŸ‹ã‚è¾¼ã¿å±¤\n",
        "        self.position_embedding_layer = PositionEmbedding(input_sequence_length = config.input_sequence_length, embedding_dim = config.embedding_dim)  # ä½ç½®æƒ…å ±ã‚’åŸ‹ã‚è¾¼ã‚€\n",
        "\n",
        "    def forward(self, input_indices):\n",
        "        # ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—\n",
        "        token_embeddings = self.token_embedding_layer.embed(input_indices)\n",
        "\n",
        "        # ä½ç½®åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—ã™ã‚‹\n",
        "        position_embeddings = self.position_embedding_layer.forward(input_indices)\n",
        "\n",
        "        # ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã¨ä½ç½®åŸ‹ã‚è¾¼ã¿ã‚’è¿½åŠ ã™ã‚‹\n",
        "        embeddings = position_embeddings + token_embeddings\n",
        "        return embeddings\n",
        "\n",
        "class LayerNorm(nn.Module):  # ã“ã“ã§nn.Moduleã‚’ç¶™æ‰¿ã™ã‚‹\n",
        "    def __init__(self, token_length, eps=1e-5, norm_dim=-1):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.norm_dim = norm_dim\n",
        "\n",
        "        # gamma ã¨ beta ã‚’ nn.Parameter ã¨ã—ã¦ç™»éŒ²ã—ã€CPU ã¨ CUDA ã®ä¸¡æ–¹ã§ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹\n",
        "        self.gamma = nn.Parameter(torch.ones(token_length))\n",
        "        self.beta = nn.Parameter(torch.zeros(token_length))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=self.norm_dim, keepdim=True)\n",
        "        var = torch.var(x, dim=self.norm_dim, keepdim=True, unbiased=False)\n",
        "        hat = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        output =  self.gamma * hat + self.beta\n",
        "        return output\n",
        "\n",
        "\n",
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, head_size, config):\n",
        "        super().__init__()\n",
        "        self.key_fc= nn.Linear(config.embedding_dim, head_size, bias=False)\n",
        "        self.query_fc = nn.Linear(config.embedding_dim, head_size, bias=False)\n",
        "        self.value_fc = nn.Linear(config.embedding_dim, head_size, bias=False)\n",
        "\n",
        "        # ãƒã‚¹ã‚¯ã¯ä¸‹ä¸‰è§’è¡Œåˆ—ã§ä½œæˆã•ã‚Œã¾ã™ï¼ˆè‡ªå·±æ³¨æ„ã®å› æœæ€§ã‚’ä¿æŒï¼‰\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.input_sequence_length, config.input_sequence_length)))\n",
        "\n",
        "        # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼ˆæ±ºå®šç‰ˆã¯åˆ¥å®šç¾©ï¼‰\n",
        "        self.dropout = nn.Dropout(config.dropout_rate)\n",
        "\n",
        "        self.head_size = head_size\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        B, T, C = input_tensor.shape  # ãƒãƒƒãƒã€ãƒˆãƒ¼ã‚¯ãƒ³é•·ã€åŸ‹ã‚è¾¼ã¿ãƒãƒ£ãƒãƒ«\n",
        "\n",
        "        Key = self.key_fc.forward(input_tensor)     # (B, T, head_size)\n",
        "        Query = self.query_fc.forward(input_tensor)   # (B, T, head_size)\n",
        "        Value = self.value_fc.forward(input_tensor)   # (B, T, head_size)\n",
        "\n",
        "        # Attentionã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ä¸­ (QK^T) / sqrt(embedding_dim)\n",
        "        attention_weights_before_mask = Query @ Key.transpose(-2, -1) * self.head_size**(-0.5)\n",
        "\n",
        "        # ãƒã‚¹ã‚¯é©ç”¨æ¸ˆã¿\n",
        "        mask = torch.triu(torch.ones(T, T), diagonal=1).to(input_tensor.device)\n",
        "        masked_attention_weights = attention_weights_before_mask.masked_fill(mask == 1, float('-inf'))\n",
        "\n",
        "        # ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ â†’ ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ â†’ é‡ã¿ä»˜ãå’Œ\n",
        "        attention_weights = F.softmax(masked_attention_weights, dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "\n",
        "        out = attention_weights @ Value  # (B, T, head_size)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.embedding_dim = config.embedding_dim\n",
        "        self.head_size = int(self.embedding_dim / self.num_attention_heads)\n",
        "\n",
        "        # ModuleListã§è¤‡æ•°ã®ãƒ˜ãƒƒãƒ‰ã‚’ç®¡ç†ã™ã‚‹\n",
        "        self.attention_heads = nn.ModuleList([\n",
        "            AttentionHead(self.head_size, config)\n",
        "            for _ in range(self.num_attention_heads)\n",
        "        ])\n",
        "\n",
        "        # å„ãƒ˜ãƒƒãƒ‰ã®å‡ºåŠ›ã‚’æ··åˆã™ã‚‹ç·šå½¢å±¤\n",
        "        self.output_projection = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
        "\n",
        "        # å‡ºåŠ›ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ\n",
        "        self.dropout = nn.Dropout(config.dropout_rate)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        # å„ãƒ˜ãƒƒãƒ‰ã®å‡ºåŠ›ã‚’å–å¾—ã™ã‚‹\n",
        "        # (B, T, head_size)ã®ãƒªã‚¹ãƒˆ\n",
        "        head_outputs_list = [head.forward(input_tensor) for head in self.attention_heads]\n",
        "\n",
        "        # å…¨ã¦ã®ãƒ˜ãƒƒãƒ‰ã®å‡ºåŠ›ã‚’é€£çµ â†’ (B, T, embedding_dim)\n",
        "        concatenated = torch.cat(head_outputs_list, dim=-1)\n",
        "\n",
        "        # ç·šå½¢å¤‰æ›ã§ã®å‡ºåŠ›æ··åˆ\n",
        "        projected = self.output_projection.forward(concatenated)\n",
        "\n",
        "        # æœ€çµ‚å‡ºåŠ›ã«ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’é©ç”¨ã™ã‚‹\n",
        "        output = self.dropout.forward(projected)\n",
        "\n",
        "        return output\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(config.embedding_dim, config.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.hidden_dim, config.embedding_dim),\n",
        "            nn.Dropout(config.dropout_rate),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        return self.net(input_tensor)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # å„LayerNormã¯ç‹¬è‡ªã®betaã¨gammaã‚’ä¿æŒã—ã¾ã™ã€‚\n",
        "        self.layer_norm1 = nn.LayerNorm(config.embedding_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(config.embedding_dim)\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(config=config)\n",
        "        self.feed_forward = FeedForward(config=config)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        # forwardãƒ¡ã‚½ãƒƒãƒ‰ã¯çœç•¥ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
        "        normed_input = self.layer_norm1(input_tensor) # å…¥åŠ›ã«ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒãƒ«ãƒ ã‚’é©ç”¨ã™ã‚‹\n",
        "        attention_output = self.multihead_attention(normed_input) # ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’é©ç”¨ã™ã‚‹\n",
        "        residual_attention = attention_output + input_tensor # \"before! layernorm1\"ã‚’è¿½åŠ \n",
        "        normed_attention = self.layer_norm2(residual_attention) # æ®‹å·®å‡ºåŠ›ã«å†åº¦LayerNormã‚’é©ç”¨ã™ã‚‹\n",
        "        feedforward_output = self.feed_forward(normed_attention) # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’é©ç”¨ã™ã‚‹\n",
        "        final_output = feedforward_output + residual_attention # \"before\" layernorm2 ã‚’è¿½åŠ ã™ã‚‹ï¼\n",
        "\n",
        "        return final_output\n",
        "\n",
        "class VocabularyLogits(nn.Module):\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        # ãƒ¬ã‚¤ãƒ¤ãƒ¼æ­£è¦åŒ–\n",
        "        self.output_norm = nn.LayerNorm(config.embedding_dim)\n",
        "        # èªå½™æ•°ã®å°„å½±\n",
        "        self.vocab_projection = nn.Linear(config.embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, transformer_block_output):\n",
        "        # Transformerãƒ–ãƒ­ãƒƒã‚¯ã®å‡ºåŠ›ã«Layer normalizationã‚’é©ç”¨ã™ã‚‹ã€‚\n",
        "        normalized_output = self.output_norm.forward(transformer_block_output)  # (B, T, C)\n",
        "\n",
        "        # ç·šå½¢å±¤ã§ã‚¹ã‚³ã‚¢ã‚’èªå½™æ•°æ¬¡å…ƒã«å¤‰æ›ã™ã‚‹ã€‚\n",
        "        vocab_logits = self.vocab_projection.forward(normalized_output)  # (B, T, V)\n",
        "\n",
        "        return vocab_logits\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        self.config = config  # ç”Ÿæˆæ™‚ã«ã‚‚ä½¿ã†ã®ã§ä¿æŒã—ã¦ãã ã•ã„ã€‚\n",
        "        self.embedding = EmbeddingModule(vocab_size, config=config)\n",
        "        self.blocks = nn.Sequential(*[TransformerBlock(config=config) for _ in range(config.layer_count)])\n",
        "        self.vocab_projection = VocabularyLogits(vocab_size=vocab_size, config=config)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹\n",
        "    def generate(self, input_indices, max_new_tokens):\n",
        "        # æŒ‡å®šã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°max_new_tokensã®ã¿ç”Ÿæˆã™ã‚‹\n",
        "        for _ in range(max_new_tokens):\n",
        "            input_conditioned = input_indices[:, -self.config.input_sequence_length:] # å…¥åŠ›ã‚’åˆ‡ã‚Šå–ã‚‹\n",
        "\n",
        "            # é †ä¼æ’­ã¯ `(likelihood, loss)` ã‚’è¿”ã™â€”`likelihood` ã®ã¿ã‚’ `logits` ã¨ã—ã¦ä¿æŒã™ã‚‹ã€‚\n",
        "            logits, _ = self.forward(input_conditioned, target_indices=None)\n",
        "            last_logits = logits[:, -1, :] # æœ€å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ­ã‚¸ãƒƒãƒˆã‚’æŠ½å‡ºã™ã‚‹\n",
        "            probs = F.softmax(last_logits, dim=-1) # Softmaxã§å°¤åº¦ã‚’ç¢ºç‡ã«å¤‰æ›ã™ã‚‹\n",
        "\n",
        "            # æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹\n",
        "            next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # æ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’çµ±åˆã—ã€input_indicesã‚’æ›´æ–°ã™ã‚‹ã€‚\n",
        "            input_indices = torch.cat((input_indices, next_token), dim=1)\n",
        "\n",
        "        # æœ€çµ‚çš„ãª`input_indices`ã‚’è¿”ã™ã€‚é•·ã•ã¯å…ƒã®`input_indices`ï¼‹`max_new_tokens`\n",
        "        return input_indices\n",
        "\n",
        "    # å°¤åº¦ã¨æå¤±ã‚’è¨ˆç®—ã™ã‚‹\n",
        "    def forward(self, input_indices, target_indices):\n",
        "        embeddings = self.embedding(input_indices)\n",
        "        blocks_output = self.blocks(embeddings)\n",
        "        logits = self.vocab_projection(blocks_output)\n",
        "\n",
        "        # æ¨è«–æ™‚ã¯ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒãªã„ãŸã‚ã€lossã¯Noneã§ã™\n",
        "        # â€”ç¢ºç‡ï¼ˆãƒ­ã‚¸ãƒƒãƒˆï¼‰ã®ã¿è¿”ã•ã‚Œã¾ã™ã€‚\n",
        "        if target_indices is None:\n",
        "            return logits, None\n",
        "\n",
        "        batch_size, token_len, vocab_size = logits.shape\n",
        "        logits = logits.view(batch_size * token_len, vocab_size)\n",
        "        targets = target_indices.view(batch_size * token_len)\n",
        "        loss = self.criterion(logits, targets)\n",
        "\n",
        "        return logits, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0vcUT2kwwR5"
      },
      "source": [
        "**DeterministicDropoutã‚’nn.Dropoutã«ç½®ãæ›ãˆã‚‹**\n",
        "```python\n",
        "AttentionHead: dropout = nn.Dropout(config.dropout_rate)\n",
        "MultiHeadAttention: dropout = nn.Dropout(config.dropout_rate)\n",
        "FeedForward:  nn.Dropout(config.dropout_rate)\n",
        "```\n",
        "<label><input type=\"checkbox\"> Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAqEd0cywV56"
      },
      "source": [
        "**`Chapter 12: Trainer Class: Section 2: ã‚¯ãƒ©ã‚¹æ¦‚è¦`** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IGG8rZJT9fx"
      },
      "source": [
        "### **Section 3: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pdT24q93vOX"
      },
      "source": [
        "ã“ã‚Œã¾ã§ã¯åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒãŒ8ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ‰ãŒ2ã¤ã€FeedForwardãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®éš ã‚Œå±¤ãŒ16æ¬¡å…ƒã§ã—ãŸã€‚<br>\n",
        "ã“ã‚Œã¯è¡¨ç¾åŠ›ã¨ã—ã¦ã¯ã‚ã¾ã‚Šã«é™ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚<br>\n",
        "ä»Šåº¦ã¯åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã‚’64ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ‰ã‚’4ã¤ã€FeedForwardãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®éš ã‚Œå±¤ã‚’256æ¬¡å…ƒã«è¨­å®šã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ooeKTSmYOdn",
        "outputId": "505d4f44-f337-48eb-dde3-e5e4198a9b7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Each setting for the ModelConfig class:\n",
            "Batch size: 16\n",
            "Input sequence length: 32\n",
            "Total training steps: 5000\n",
            "Evaluation frequency (in steps): 100\n",
            "Learning rate: 0.001\n",
            "Device in use: cuda\n",
            "Number of evaluation loops: 10\n",
            "Embedding vector dimension: 64\n",
            "Hidden layer dimension of the feedforward network: 256\n",
            "Number of attention heads: 4\n",
            "Number of model layers: 4\n",
            "Dropout rate: 0.1\n",
            "Random seed value: 1337\n"
          ]
        }
      ],
      "source": [
        "# ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ä¿å­˜ã™ã‚‹è¨­å®šã‚¯ãƒ©ã‚¹\n",
        "class ModelConfig:\n",
        "    batch_size = 16  # ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿æ•°ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚ºï¼‰\n",
        "    input_sequence_length = 32  # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®é•·ã•ï¼ˆç³»åˆ—é•·ï¼‰\n",
        "    total_training_steps = 5000  # æœ€å¤§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å›æ•°ï¼ˆã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼‰\n",
        "    evaluation_frequency = 100  # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è©•ä¾¡ã®é »åº¦\n",
        "    learning_rate = 0.001  # å­¦ç¿’ç‡\n",
        "    device_type = 'cuda' if torch.cuda.is_available() else 'cpu'  # ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ï¼ˆGPUã¾ãŸã¯CPUï¼‰\n",
        "    evaluation_loops = 10  # è©•ä¾¡ä¸­ã®ç¹°ã‚Šè¿”ã—å›æ•°\n",
        "    embedding_dim = 64  # åŸ‹ã‚è¾¼ã¿å±¤ã‚µã‚¤ã‚ºï¼ˆç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°ï¼‰\n",
        "    hidden_dim = 256\n",
        "    num_attention_heads = 4  # ãƒãƒ¼ãƒˆæ©Ÿæ§‹ãƒ˜ãƒƒãƒ‰ç•ªå·\n",
        "    layer_count = 4  # ãƒ¢ãƒ‡ãƒ«ã®å±¤æ•°\n",
        "    dropout_rate = 0.1  # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç¢ºç‡\n",
        "    random_seed_value = 1337  # å†ç¾æ€§ã®ãŸã‚ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰\n",
        "\n",
        "# è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„\n",
        "config = ModelConfig()\n",
        "\n",
        "print(\"ModelConfigã‚¯ãƒ©ã‚¹ã®å„è¨­å®š:\")\n",
        "print(f\"Batch size: {config.batch_size}\")\n",
        "print(f\"Input sequence length: {config.input_sequence_length}\")\n",
        "print(f\"Total training steps: {config.total_training_steps}\")\n",
        "print(f\"Evaluation frequency (in steps): {config.evaluation_frequency}\")\n",
        "print(f\"Learning rate: {config.learning_rate}\")\n",
        "print(f\"Device in use: {config.device_type}\")\n",
        "print(f\"Number of evaluation loops: {config.evaluation_loops}\")\n",
        "print(f\"Embedding vector dimension: {config.embedding_dim}\")\n",
        "print(f\"Hidden layer dimension of the feedforward network: {config.hidden_dim}\")\n",
        "print(f\"Number of attention heads: {config.num_attention_heads}\")\n",
        "print(f\"Number of model layers: {config.layer_count}\")\n",
        "print(f\"Dropout rate: {config.dropout_rate}\")\n",
        "print(f\"Random seed value: {config.random_seed_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwvOpyQPm5Jl"
      },
      "source": [
        "**`Check Point`**  \n",
        "<label><input type=\"checkbox\"> Configã‚¯ãƒ©ã‚¹ã®è¨­å®šãŒæ­£ã—ãè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã‚ˆã†<br></label>  \n",
        "- ãƒãƒƒãƒã‚µã‚¤ã‚º: 16<br>  \n",
        "- ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º: 32<br>  \n",
        "- æœ€å¤§ç¹°ã‚Šè¿”ã—å›æ•°: 5000<br>  \n",
        "- è©•ä¾¡é–“éš”: 100<br>  \n",
        "- å­¦ç¿’ç‡: 0.001<br>  \n",
        "- ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: cuda ã¾ãŸã¯ cpu<br>  \n",
        "- è©•ä¾¡æ™‚ã®ç¹°ã‚Šè¿”ã—å›æ•°: 10<br>  \n",
        "- åŸ‹ã‚è¾¼ã¿å±¤ã®æ¬¡å…ƒæ•°: 64<br>  \n",
        "- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ã®éš ã‚Œæ¬¡å…ƒæ•°: 256<br>  \n",
        "- ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ‰æ•°: 4<br>  \n",
        "- ãƒ¢ãƒ‡ãƒ«ã®å±¤æ•°: 4<br>  \n",
        "- ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡: 0.1<br>  \n",
        "- ã‚·ãƒ¼ãƒ‰å€¤: 1337<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EctA8L49Tsc0",
        "outputId": "d7dfe830-e4bb-4f40-8b15-8cda7e56de12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x782b68401490>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# è¨­å®šã‚’èª­ã¿è¾¼ã¿ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šã™ã‚‹\n",
        "config = ModelConfig()\n",
        "torch.manual_seed(config.random_seed_value)  # å†ç¾æ€§ç¢ºä¿ã®ãŸã‚ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXBa9z1ogsUw"
      },
      "outputs": [],
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€\n",
        "with open(\"input.txt\", 'r', encoding = 'utf-8') as f:\n",
        "    text_data = f.read()\n",
        "data_loader = DataLoader(text_data, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtyVxmwiTotc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c124075e-6a3d-413a-f0f9-ef56415b2dd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209729 M parameters\n"
          ]
        }
      ],
      "source": [
        "# ãƒ¢ãƒ‡ãƒ«ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’åˆæœŸåŒ–ã™ã‚‹\n",
        "model = BigramLanguageModel(vocab_size = data_loader.vocab_size, config = config).to(config.device_type)  # ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’è¡¨ç¤ºã™ã‚‹\n",
        "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "æ¯”è¼ƒã™ã‚‹ã¨ã€GPT2-Smallãƒ¢ãƒ‡ãƒ«ã¯1å„„1700ä¸‡ï¼ˆã¾ãŸã¯1å„„2400ä¸‡ï¼‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã„ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "mysHV8yjE7P6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx-g4ndFubat"
      },
      "source": [
        "ãƒ†ã‚¹ãƒˆã¨ã—ã¦ã€äº‹å‰å­¦ç¿’ã®æ®µéšã§ç”Ÿæˆã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpnodhC5ubat",
        "outputId": "77b04870-2352-4921-fbea-3ad7f62188ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's henvIeuW;JcijkeLWfUaUJW;VcE!Pf;ocFF&oNhq$eQLJOOEFWXgjNhhqv;Es\n",
            "iowD&ZqK&CgwN'Pq$mFHGjX.esumfonqUzgrN?pNVvN!Iebiqfs!EuOt3Zw?Bjx$oYk-wXmvevRibdVde!eJgRLKasNnge?DEYpK! 'scfoOl!Ebe$iol$-UpfXGKtewgLMsO!?fX?&D?;-$zBR.SudGdOo.&co\n",
            "zvzNqQriRR'QbHbs'QqXghiHWJwLUEZE&pNz\n",
            "T'Rk!ZgbN?tmE.uJaekBK?Oh&n&Um,LDqc'omcC&Z;xpZGipgRQeN$y?VDbOvsN,$IcNhepTHJeWkzKdrf?roHm?dfwFUpwMVg;ei&$RCXTyowaFZhjVBm$3g33cAuh,K?UlAGcX;p!JUlNvvbIHG.3inUc.HjMCsyhnpwAKylbSHT'pXh3UNfO:mreo'VrL'cpe-NC,ntZAziOpKcpTOE.hs:Ck&z'LGJgyb3?p!3fI,OjzFHE\n"
          ]
        }
      ],
      "source": [
        "text = \"Let's he\"  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
        "initial_context = torch.tensor(data_loader.encode(text), dtype=torch.long)\n",
        "# unsqueeze(0)ã§ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º1ï¼‰\n",
        "initial_context_unsqueeze = initial_context.unsqueeze(0)\n",
        "# â†“ ãƒã‚¤ãƒ³ãƒˆã¯ä½¿ç”¨ä¸­ã®ãƒ‡ãƒã‚¤ã‚¹ã«ç§»ã™ã“ã¨ï¼ˆCPUã‹GPUï¼‰ï¼\n",
        "initial_context_unsqueeze = initial_context_unsqueeze.to(config.device_type)\n",
        "\n",
        "# ç”Ÿæˆã‚’é–‹å§‹ã™ã‚‹\n",
        "generated_sequence_initial = model.generate(initial_context_unsqueeze, max_new_tokens=500)\n",
        "print(data_loader.decode(generated_sequence_initial[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYintz_Aubat"
      },
      "source": [
        "ã†ãƒ¼ã‚“ã€ã“ã‚Œã¯ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ğŸ’»ã ã­ï¼Ÿ\n",
        "\n",
        "ãã‚Œãªã‚‰ã€ã•ã‚è¨“ç·´ã—ã¦èµ¤ã¡ã‚ƒã‚“ğŸ‘¶ã«è‚²ã¦ã‚ˆã†ï¼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK_3F336Eu6z"
      },
      "source": [
        "**ã¤ã„ã«æœ€å¾Œã®ãƒ‘ãƒ¼ãƒˆã«ãŸã©ã‚Šç€ãã¾ã—ãŸã€‚[æ„Ÿå‹•ã®BGMÂ¹](https://youtu.be/GqmAe0QfkjU?feature=shared)ã‚¹ã‚¿ãƒ¼ãƒˆï¼<br>ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã ã„ãŸã„2ã€œ4åˆ†ã‹ã‹ã‚Šã¾ã™ã€‚ä»Šã“ã®ç¬é–“ã‚’ã˜ã£ãã‚Šå‘³ã‚ã„ã¾ã—ã‚‡ã†ã€‚**\n",
        "\n",
        "---\n",
        "\n",
        "å‚è€ƒã‚³ãƒ³ãƒ†ãƒ³ãƒ„:  \n",
        "Â¹ **DooPiano**, ã€ŒBTS (ë°©íƒ„ì†Œë…„ë‹¨) â€“ ë´„ë‚  (Spring Day) ãƒ”ã‚¢ãƒï¼†ã‚¹ãƒˆãƒªãƒ³ã‚°ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€ã€YouTubeã€3:41ã€ç´„8.2å¹´å‰å…¬é–‹ï¼ˆ2017å¹´é ƒï¼‰ã€‚2025å¹´7æœˆ8æ—¥ã‚¢ã‚¯ã‚»ã‚¹ã€‚\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6t0rayVFh2U"
      },
      "source": [
        "**ãœã²BGMã‚’è´ã„ã¦ãã ã•ã„ï¼å¿ƒãŒå‹•ãã“ã¨é–“é•ã„ãªã—ï¼ã•ã‚ã€ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å§‹ã‚ã¾ã—ã‚‡ã†ï¼**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpagygD5TqHA",
        "outputId": "87c4c733-8f0d-45da-fe25-cd8b2fd6d5a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===TRAINING STARTED SUCCESSFULLY===\n",
            "Step 0: Train Loss 2.3080, Validation Loss 2.3095\n",
            "Step 100: Train Loss 2.2592, Validation Loss 2.2887\n",
            "Step 200: Train Loss 2.2122, Validation Loss 2.2228\n",
            "Step 300: Train Loss 2.1850, Validation Loss 2.1929\n",
            "Step 400: Train Loss 2.1433, Validation Loss 2.1610\n",
            "Step 500: Train Loss 2.0731, Validation Loss 2.1434\n",
            "Step 600: Train Loss 2.0713, Validation Loss 2.1265\n",
            "Step 700: Train Loss 2.0781, Validation Loss 2.0784\n",
            "Step 800: Train Loss 2.0399, Validation Loss 2.1171\n",
            "Step 900: Train Loss 1.9939, Validation Loss 2.0921\n",
            "Step 1000: Train Loss 2.0463, Validation Loss 2.0800\n",
            "Step 1100: Train Loss 2.0031, Validation Loss 2.0437\n",
            "Step 1200: Train Loss 1.9710, Validation Loss 2.0322\n",
            "Step 1300: Train Loss 1.8837, Validation Loss 2.0148\n",
            "Step 1400: Train Loss 1.9525, Validation Loss 2.0299\n",
            "Step 1500: Train Loss 1.9432, Validation Loss 2.0055\n",
            "Step 1600: Train Loss 1.9284, Validation Loss 1.9633\n",
            "Step 1700: Train Loss 1.9180, Validation Loss 1.9909\n",
            "Step 1800: Train Loss 1.8999, Validation Loss 1.9350\n",
            "Step 1900: Train Loss 1.8392, Validation Loss 1.9623\n",
            "Step 2000: Train Loss 1.8845, Validation Loss 1.9732\n",
            "Step 2100: Train Loss 1.8869, Validation Loss 1.9537\n",
            "Step 2200: Train Loss 1.8619, Validation Loss 1.9648\n",
            "Step 2300: Train Loss 1.8186, Validation Loss 1.9966\n",
            "Step 2400: Train Loss 1.8383, Validation Loss 1.9590\n",
            "Step 2500: Train Loss 1.8500, Validation Loss 1.9092\n",
            "Step 2600: Train Loss 1.8149, Validation Loss 1.8838\n",
            "Step 2700: Train Loss 1.8128, Validation Loss 1.9213\n",
            "Step 2800: Train Loss 1.8046, Validation Loss 1.9234\n",
            "Step 2900: Train Loss 1.8057, Validation Loss 1.9302\n",
            "Step 3000: Train Loss 1.7888, Validation Loss 1.8733\n",
            "Step 3100: Train Loss 1.7705, Validation Loss 1.9013\n",
            "Step 3200: Train Loss 1.7730, Validation Loss 1.9126\n",
            "Step 3300: Train Loss 1.8045, Validation Loss 1.9461\n",
            "Step 3400: Train Loss 1.7554, Validation Loss 1.9231\n",
            "Step 3500: Train Loss 1.7937, Validation Loss 1.8936\n",
            "Step 3600: Train Loss 1.7712, Validation Loss 1.8767\n",
            "Step 3700: Train Loss 1.7668, Validation Loss 1.8839\n",
            "Step 3800: Train Loss 1.7718, Validation Loss 1.8480\n",
            "Step 3900: Train Loss 1.7603, Validation Loss 1.8709\n",
            "Step 4000: Train Loss 1.7487, Validation Loss 1.8557\n",
            "Step 4100: Train Loss 1.7145, Validation Loss 1.8529\n",
            "Step 4200: Train Loss 1.7628, Validation Loss 1.8611\n",
            "Step 4300: Train Loss 1.6964, Validation Loss 1.8522\n",
            "Step 4400: Train Loss 1.7155, Validation Loss 1.8929\n",
            "Step 4500: Train Loss 1.7233, Validation Loss 1.8741\n",
            "Step 4600: Train Loss 1.7043, Validation Loss 1.8837\n",
            "Step 4700: Train Loss 1.6532, Validation Loss 1.8430\n",
            "Step 4800: Train Loss 1.6850, Validation Loss 1.7992\n",
            "Step 4900: Train Loss 1.7202, Validation Loss 1.8850\n",
            "Step 4999: Train Loss 1.7031, Validation Loss 1.9120\n",
            "Training DONE\n",
            "Model and optimizer state saved to bigram_language_model.pth\n"
          ]
        }
      ],
      "source": [
        "print(\"===ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæ­£å¸¸ã«é–‹å§‹ã•ã‚Œã¾ã—ãŸ===\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹\n",
        "trainer = Trainer(model, optimizer, data_loader, config)\n",
        "trainer.train()\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ä¸­\n",
        "save_path = \"bigram_language_model.pth\"\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict()\n",
        "}, save_path)\n",
        "\n",
        "print(\"å­¦ç¿’å®Œäº†\")\n",
        "print(f\"Model and optimizer state saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiEiQNKci0xq",
        "outputId": "76f971cc-7a84-4c47-c9a6-dac8152999fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Model Loaded Successfully!=====\n"
          ]
        }
      ],
      "source": [
        "# ---- ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ -----\n",
        "# æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’åˆæœŸåŒ–ï¼ˆåŒã˜è¨­å®šã¨ã‚¯ãƒ©ã‚¹å®šç¾©ãŒå¿…è¦ï¼‰\n",
        "loaded_model = BigramLanguageModel(vocab_size = data_loader.vocab_size, config = config).to(config.device_type)  # ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„\n",
        "loaded_optimizer = torch.optim.AdamW(loaded_model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "save_path = \"bigram_language_model.pth\"\n",
        "checkpoint = torch.load(save_path, map_location=config.device_type)\n",
        "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "loaded_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "print(\"=====ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸï¼=====\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®šã—ã¾ã™ã€‚ç”Ÿæˆå‰ã«Dropoutã‚’ç„¡åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "å¿˜ã‚Œã‚‹ã¨DropoutãŒã‚ªãƒ³ã«ãªã‚Šã€å‡ºåŠ›ãŒã²ã©ããªã‚‹ã®ã§æ³¨æ„ã—ã¾ã—ã‚‡ã†ã€‚"
      ],
      "metadata": {
        "id": "y2Pj_bPCEPPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.eval()\n",
        "print(\"===== è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®šã€Dropoutç„¡åŠ¹ã€‚ =====\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yuLBig8EG91",
        "outputId": "83214a4c-14a2-4649-d21a-e1e6755d5a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Set to Evaluation mode, disabled Dropout. =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaQb254DuA8X",
        "outputId": "b6f93c3a-e5ce-47b6-b2d3-d61613389e32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded_prompt\n",
            "Tensor Size: [8]\n",
            "tensor([\n",
            "         24.00,  43.00,  58.00,   5.00,  57.00,   1.00,  46.00,  43.00\n",
            "       ])\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Let's he\"  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
        "encoded_prompt = torch.tensor(data_loader.encode(prompt), dtype=torch.long)\n",
        "print_formatted_tensor(\"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\", encoded_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QoDkdBPuC2Q",
        "outputId": "cf25d96f-7b3b-4fc3-bc7a-80252e47a5d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded_prompt_unsqueeze\n",
            "Tensor Size: [1, 8]\n",
            "tensor([\n",
            "         [ 24.00,  43.00,  58.00,   5.00,  57.00,   1.00,  46.00,  43.00]\n",
            "       ])\n"
          ]
        }
      ],
      "source": [
        "# unsqueeze(0)ã§ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º1ï¼‰\n",
        "encoded_prompt_unsqueeze = encoded_prompt.unsqueeze(0)\n",
        "print_formatted_tensor(\"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ¬¡å…ƒè¿½åŠ \", encoded_prompt_unsqueeze)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dUOQgT3uEHx"
      },
      "outputs": [],
      "source": [
        "# â†“ ã“ã“ã§é‡è¦ãªã®ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½¿ç”¨ä¸­ã®ãƒ‡ãƒã‚¤ã‚¹ï¼ˆCPUã¾ãŸã¯GPUï¼‰ã«ç§»å‹•ã™ã‚‹ã“ã¨ã§ã™ï¼\n",
        "encoded_prompt_unsqueeze = encoded_prompt_unsqueeze.to(config.device_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdiKzDt6zXpP"
      },
      "source": [
        "```python\n",
        "ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹: loaded_model\n",
        "ãƒ¡ã‚½ãƒƒãƒ‰: generate\n",
        "å¼•æ•°: encoded_prompt_unsqueeze, max_new_tokens=1000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U58DsEfuF27",
        "outputId": "41bb755e-a8bc-4109-b385-79ede0010b35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's he weath to begiver thing thou are perpisency the gertater sing\n",
            "To With beenes; no from to the chaul!\n",
            "\n",
            "JUTIO:\n",
            "Were this not the carence your in singrard hath lond\n",
            "Capus leet.\n",
            "\n",
            "BRUTUS:\n",
            "Thee bust to me to speaks or his it,\n",
            "\n",
            "Deseetock untertay laid I wand for shing\n",
            "that ittience, God nig for the from do it it.\n",
            "\n",
            "Pervore, I sethall thou breather,\n",
            "By tyre agent man some thou my servery plaid be the spoble.\n",
            "\n",
            "GLOUCESTER:\n",
            "Shallo, Say fauls I weick.\n",
            "\n",
            "DUCESTER MARGAREY:\n",
            "My noble thear, an, and at to he's guend\n",
            "For me full I say's be swould Gentleat haph till\n",
            "Nor And being years their rlancues\n",
            "The Last burssened to her be gry our sto stoot\n",
            "Ands that nurse steep\n",
            "Of aund will of her age man, tiSingment your boy's rings:\n",
            "Your my and again and well I would theur ady\n",
            "A samernon to do time'n sail thou lack your juty,\n",
            "No? I coundertife thou have thee other awarthrough a dne'd I preaty\n",
            "Waveichard him time if our good bowers highne:\n",
            "Thears.\n",
            "\n",
            "Thidds; and I' weal theseity. Bollow Richions:\n",
            "As City you?I heark,\n"
          ]
        }
      ],
      "source": [
        "# ç”Ÿæˆã‚’é–‹å§‹\n",
        "generated_sequence = loaded_model.generate(encoded_prompt_unsqueeze, max_new_tokens=1000) # TODO: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€\n",
        "print(data_loader.decode(generated_sequence[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcHLCQ6P4O-8"
      },
      "source": [
        "èµ¤ã¡ã‚ƒã‚“ğŸ‘¶ãƒ¬ãƒ™ãƒ«ã¾ã§é€²ã‚“ã ï¼Ÿ\n",
        "\n",
        "ä»Šå›ã¯nanoGPTã§ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ğŸ’»ã‹ã‚‰èµ¤ã¡ã‚ƒã‚“ğŸ‘¶ã¸ã‚¹ãƒ†ãƒƒãƒ—ã‚¢ãƒƒãƒ—ã€‚\n",
        "\n",
        "æ¬¡ã¯GPT2ãŒèµ¤ã¡ã‚ƒã‚“ğŸ‘¶ã‹ã‚‰ä¸­å­¦ç”ŸğŸ§‘ã¸æˆé•·ã™ã‚‹ãï¼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R52XY3hdxKUS"
      },
      "source": [
        "**Chapter 12: Trainer Class: Section 3: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viJYZTXwxNhC"
      },
      "source": [
        "**`Chapter 12: The Trainer Class`** <label><input type=\"checkbox\"> Mark as Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1dLHoKgxQwm"
      },
      "source": [
        "**`nanoGPT`** <label><input type=\"checkbox\"> Done</label>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykz9QCl8ubau"
      },
      "source": [
        "![ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-06-25 0.58.23.png](data:image/png;base64,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)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}